//
// Generated by LLVM NVPTX Back-End
//

.version 7.5
.target sm_80
.address_size 64

	// .globl	sum_kernel_2_0d1d2
.extern .shared .align 1 .b8 global_smem[];

.visible .entry sum_kernel_2_0d1d2(
	.param .u64 sum_kernel_2_0d1d2_param_0,
	.param .u64 sum_kernel_2_0d1d2_param_1,
	.param .u32 sum_kernel_2_0d1d2_param_2
)
.maxntid 128, 1, 1
{
	.reg .pred 	%p<6>;
	.reg .b32 	%r<20>;
	.reg .b64 	%rd<33>;

	ld.param.u64 	%rd8, [sum_kernel_2_0d1d2_param_0];
	ld.param.u64 	%rd7, [sum_kernel_2_0d1d2_param_1];
	mov.u32 	%r15, %tid.x;
	and.b32  	%r16, %r15, 31;
	ld.param.u32 	%r17, [sum_kernel_2_0d1d2_param_2];
	and.b32  	%r18, %r15, 7;
	mul.wide.u32 	%rd9, %r18, 8;
	add.s64 	%rd2, %rd8, %rd9;
	setp.lt.s32 	%p1, %r18, %r17;
	mov.u64 	%rd3, 0;
	@%p1 ld.global.b64 { %rd1 }, [ %rd2 + 0 ];
	@!%p1 mov.u64 %rd1, %rd3;
	shr.u64 	%rd10, %rd1, 32;
	cvt.u32.u64 	%r4, %rd10;
	cvt.u32.u64 	%r2, %rd1;
	setp.eq.s32 	%p3, %r16, 0;
	shfl.sync.bfly.b32 %r1, %r2, 0x4, 0x1f, 0xffffffff;
	shfl.sync.bfly.b32 %r3, %r4, 0x4, 0x1f, 0xffffffff;
	cvt.u64.u32 	%rd11, %r1;
	cvt.u64.u32 	%rd12, %r3;
	shl.b64 	%rd13, %rd12, 32;
	or.b64  	%rd14, %rd11, %rd13;
	add.s64 	%rd15, %rd1, %rd14;
	shr.u64 	%rd16, %rd15, 32;
	cvt.u32.u64 	%r8, %rd16;
	cvt.u32.u64 	%r6, %rd15;
	shfl.sync.bfly.b32 %r5, %r6, 0x2, 0x1f, 0xffffffff;
	shfl.sync.bfly.b32 %r7, %r8, 0x2, 0x1f, 0xffffffff;
	cvt.u64.u32 	%rd17, %r5;
	cvt.u64.u32 	%rd18, %r7;
	shl.b64 	%rd19, %rd18, 32;
	or.b64  	%rd20, %rd17, %rd19;
	add.s64 	%rd21, %rd15, %rd20;
	shr.u64 	%rd22, %rd21, 32;
	cvt.u32.u64 	%r12, %rd22;
	cvt.u32.u64 	%r10, %rd21;
	shfl.sync.bfly.b32 %r9, %r10, 0x1, 0x1f, 0xffffffff;
	shfl.sync.bfly.b32 %r11, %r12, 0x1, 0x1f, 0xffffffff;
	cvt.u64.u32 	%rd23, %r9;
	cvt.u64.u32 	%rd24, %r11;
	shl.b64 	%rd25, %rd24, 32;
	or.b64  	%rd26, %rd23, %rd25;
	add.s64 	%rd4, %rd21, %rd26;
	mov.u32 	%r13, global_smem;
	@%p3 st.shared.b64 [ %r13 + 0 ], %rd4;
	bar.sync 	0;
	shl.b32 	%r19, %r15, 3;
	add.s32 	%r14, %r13, %r19;
	ld.shared.u32 	%rd27, [%r14];
	ld.shared.u32 	%rd28, [%r14+4];
	shl.b64 	%rd29, %rd28, 32;
	or.b64  	%rd5, %rd29, %rd27;
	setp.lt.s32 	%p4, %r15, 1;
	@%p4 st.shared.b64 [ %r14 + 0 ], %rd5;
	bar.sync 	0;
	ld.shared.u32 	%rd30, [global_smem+4];
	shl.b64 	%rd31, %rd30, 32;
	ld.shared.u32 	%rd32, [global_smem];
	or.b64  	%rd6, %rd31, %rd32;
	mov.pred 	%p5, -1;
	@%p5 st.global.b64 [ %rd7 + 0 ], { %rd6 };
	ret;

}
