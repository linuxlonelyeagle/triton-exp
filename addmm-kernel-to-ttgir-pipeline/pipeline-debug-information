Args: triton-opt combine-tensor.mlir -tritongpu-pipeline -o pipeline.mlir -debug 
Load new dialect in Context builtin
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ShapedType)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::MemRefLayoutAttrInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::TypedAttr)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ElementsAttr)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DistinctAttr)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BytecodeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpAsmOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionKindInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ConditionallySpeculatable)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::MemoryEffectOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ResourceBlobManagerDialectInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpAsmDialectInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BytecodeDialectInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::AffineBinaryOpExprStorage)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::AffineConstantExprStorage)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::AffineDimExprStorage)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::AffineMapStorage)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::IntegerSetStorage)
Load new dialect in Context builtin
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ZeroOperands<mlir::TypeID::get<mlir::OpTrait::ZeroOperands>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneRegion<mlir::TypeID::get<mlir::OpTrait::OneRegion>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ZeroResults<mlir::TypeID::get<mlir::OpTrait::ZeroResults>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ZeroSuccessors<mlir::TypeID::get<mlir::OpTrait::ZeroSuccessors>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NoRegionArguments<mlir::TypeID::get<mlir::OpTrait::NoRegionArguments>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NoTerminator<mlir::TypeID::get<mlir::OpTrait::NoTerminator>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SingleBlock<mlir::TypeID::get<mlir::OpTrait::SingleBlock>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OpInvariants<mlir::TypeID::get<mlir::OpTrait::OpInvariants>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BytecodeOpInterface::Trait<mlir::TypeID::get<mlir::BytecodeOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AffineScope<mlir::TypeID::get<mlir::OpTrait::AffineScope>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::IsIsolatedFromAbove<mlir::TypeID::get<mlir::OpTrait::IsIsolatedFromAbove>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SymbolTable<mlir::TypeID::get<mlir::OpTrait::SymbolTable>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolOpInterface::Trait<mlir::TypeID::get<mlir::SymbolOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpAsmOpInterface::Trait<mlir::TypeID::get<mlir::OpAsmOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionKindInterface::Trait<mlir::TypeID::get<mlir::RegionKindInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasOnlyGraphRegion<mlir::TypeID::get<mlir::OpTrait::HasOnlyGraphRegion>()::Empty>)
Load new dialect in Context triton_gpu
Load new dialect in Context tt
Load new dialect in Context arith
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithFastMathInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::VectorUnrollOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::InferTypeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::InferIntRangeInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithIntegerOverflowFlagsInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CastOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithRoundingModeInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SelectLikeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DialectInlinerInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ConvertToLLVMPatternInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::bufferization::BufferDeallocationOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::bufferization::BufferizableOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ValueBoundsOpInterface)
Load new dialect in Context math
Load new dialect in Context scf
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionBranchTerminatorOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionBranchOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::LoopLikeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DestinationStyleOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ParallelCombiningOpInterface)
Load new dialect in Context cf
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BranchOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CallOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolUserOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CallableOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::FunctionOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::TensorOrMemDesc)
Load new dialect in Context gpu
ImplicitTypeIDRegistry::lookupOrInsert(mlir::gpu::AsyncTokenType)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::gpu::MMAMatrixType)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::gpu::SparseDnTensorHandleType)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::gpu::SparseSpMatHandleType)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::gpu::SparseSpGEMMOpHandleType)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::gpu::AsyncOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DataLayoutOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DeviceMappingAttrInterface)
Load new dialect in Context tensor
Load new dialect in Context affine
Load new dialect in Context ub
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ub::PoisonAttrInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineMapAccessInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineDmaStartOp)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineDmaWaitOp)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineReadOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineWriteOpInterface)
Load new dialect in Context complex
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ReifyRankedShapedTypeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ShapedDimOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OffsetSizeAndStrideOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::transform::FindPayloadReplacementOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SubsetOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SubsetInsertionOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SubsetExtractionOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::TilingInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::triton::gpu::TritonGPU_AttrTrait)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::triton::gpu::DistributedEncodingTrait)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::triton::gpu::MmaEncodingTrait)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::triton::DialectInferLayoutInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AutomaticAllocationScope<mlir::TypeID::get<mlir::OpTrait::AutomaticAllocationScope>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CallableOpInterface::Trait<mlir::TypeID::get<mlir::CallableOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::FunctionOpInterface::Trait<mlir::TypeID::get<mlir::FunctionOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::TensorSizeTrait<mlir::TypeID::get<mlir::OpTrait::TensorSizeTrait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::VerifyTensorLayoutsTrait<mlir::TypeID::get<mlir::OpTrait::VerifyTensorLayoutsTrait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ZeroRegions<mlir::TypeID::get<mlir::OpTrait::ZeroRegions>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneResult<mlir::TypeID::get<mlir::OpTrait::OneResult>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::Type>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::Type>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ConstantLike<mlir::TypeID::get<mlir::OpTrait::ConstantLike>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ConditionallySpeculatable::Trait<mlir::TypeID::get<mlir::ConditionallySpeculatable::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AlwaysSpeculatableImplTrait<mlir::TypeID::get<mlir::OpTrait::AlwaysSpeculatableImplTrait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::MemoryEffectOpInterface::Trait<mlir::TypeID::get<mlir::MemoryEffectOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::InferIntRangeInterface::Trait<mlir::TypeID::get<mlir::InferIntRangeInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::InferTypeOpInterface::Trait<mlir::TypeID::get<mlir::InferTypeOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::VerifiableTensorEncoding)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::detail::ConstantOpGenericAdaptorBase::Properties)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::IntegerType>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::IntegerType>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::triton::detail::GetProgramIdOpGenericAdaptorBase::Properties)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NOperands<2>::Impl<mlir::TypeID::get<mlir::OpTrait::NOperands<2>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::IsCommutative<mlir::TypeID::get<mlir::OpTrait::IsCommutative>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithIntegerOverflowFlagsInterface::Trait<mlir::TypeID::get<mlir::arith::ArithIntegerOverflowFlagsInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SameOperandsAndResultType<mlir::TypeID::get<mlir::OpTrait::SameOperandsAndResultType>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::VectorUnrollOpInterface::Trait<mlir::TypeID::get<mlir::VectorUnrollOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::Elementwise<mlir::TypeID::get<mlir::OpTrait::Elementwise>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::Scalarizable<mlir::TypeID::get<mlir::OpTrait::Scalarizable>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::Vectorizable<mlir::TypeID::get<mlir::OpTrait::Vectorizable>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::Tensorizable<mlir::TypeID::get<mlir::OpTrait::Tensorizable>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneOperand<mlir::TypeID::get<mlir::OpTrait::OneOperand>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SameOperandsAndResultElementType<mlir::TypeID::get<mlir::OpTrait::SameOperandsAndResultElementType>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SameOperandsAndResultEncoding<mlir::TypeID::get<mlir::OpTrait::SameOperandsAndResultEncoding>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SameOperandsAndResultShape<mlir::TypeID::get<mlir::OpTrait::SameOperandsAndResultShape>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SameTypeOperands<mlir::TypeID::get<mlir::OpTrait::SameTypeOperands>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::detail::CmpIOpGenericAdaptorBase::Properties)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::VariadicResults<mlir::TypeID::get<mlir::OpTrait::VariadicResults>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AtLeastNOperands<3>::Impl<mlir::TypeID::get<mlir::OpTrait::AtLeastNOperands<3>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SingleBlockImplicitTerminator<mlir::scf::YieldOp>::Impl<mlir::TypeID::get<mlir::OpTrait::SingleBlockImplicitTerminator<mlir::scf::YieldOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::LoopLikeOpInterface::Trait<mlir::TypeID::get<mlir::LoopLikeOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionBranchOpInterface::Trait<mlir::TypeID::get<mlir::RegionBranchOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasRecursiveMemoryEffects<mlir::TypeID::get<mlir::OpTrait::HasRecursiveMemoryEffects>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::IsIdempotent<mlir::TypeID::get<mlir::OpTrait::IsIdempotent>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AtLeastNOperands<1>::Impl<mlir::TypeID::get<mlir::OpTrait::AtLeastNOperands<1>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AttrSizedOperandSegments<mlir::TypeID::get<mlir::OpTrait::AttrSizedOperandSegments>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SameLoadStoreOperandsAndResultShape<mlir::TypeID::get<mlir::OpTrait::SameLoadStoreOperandsAndResultShape>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SameLoadStoreOperandsAndResultEncoding<mlir::TypeID::get<mlir::OpTrait::SameLoadStoreOperandsAndResultEncoding>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::triton::detail::LoadOpGenericAdaptorBase::Properties)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NOperands<3>::Impl<mlir::TypeID::get<mlir::OpTrait::NOperands<3>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::DotLike<mlir::TypeID::get<mlir::OpTrait::DotLike>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::VariadicOperands<mlir::TypeID::get<mlir::OpTrait::VariadicOperands>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasParent<mlir::scf::ExecuteRegionOp, mlir::scf::ForOp, mlir::scf::IfOp, mlir::scf::IndexSwitchOp, mlir::scf::WhileOp>::Impl<mlir::TypeID::get<mlir::OpTrait::HasParent<mlir::scf::ExecuteRegionOp, mlir::scf::ForOp, mlir::scf::IfOp, mlir::scf::IndexSwitchOp, mlir::scf::WhileOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionBranchTerminatorOpInterface::Trait<mlir::TypeID::get<mlir::RegionBranchTerminatorOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ReturnLike<mlir::TypeID::get<mlir::OpTrait::ReturnLike>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::IsTerminator<mlir::TypeID::get<mlir::OpTrait::IsTerminator>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CastOpInterface::Trait<mlir::TypeID::get<mlir::CastOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithFastMathInterface::Trait<mlir::TypeID::get<mlir::arith::ArithFastMathInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithRoundingModeInterface::Trait<mlir::TypeID::get<mlir::arith::ArithRoundingModeInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AtLeastNOperands<2>::Impl<mlir::TypeID::get<mlir::OpTrait::AtLeastNOperands<2>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SameLoadStoreOperandsShape<mlir::TypeID::get<mlir::OpTrait::SameLoadStoreOperandsShape>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SameLoadStoreOperandsEncoding<mlir::TypeID::get<mlir::OpTrait::SameLoadStoreOperandsEncoding>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasParent<mlir::triton::FuncOp>::Impl<mlir::TypeID::get<mlir::OpTrait::HasParent<mlir::triton::FuncOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DataLayoutSpecInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ValueSemantics<mlir::TypeID::get<mlir::ValueSemantics>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ShapedType::Trait<mlir::TypeID::get<mlir::ShapedType::Trait>()::Empty>)
Load new dialect in Context triton_nvidia_gpu
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::OpToOpPassAdaptor)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::dataflow::CFGEdge)
Priming analysis: mlir::dataflow::DeadCodeAnalysis
ImplicitTypeIDRegistry::lookupOrInsert(mlir::dataflow::Executable)
Propagating update to mlir::dataflow::Executable of ^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %c32_i32 = arith.constant 32 : i32
  %c31_i32 = arith.constant 31 : i32
  %cst_1 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %5 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %7 = arith.addi %6, %3 : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %8 = arith.muli %1, %c32_i32 : i32
  %9 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %10 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %11 = arith.addi %9, %4 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %12 = arith.addi %10, %5 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %13 = tt.expand_dims %7 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %14 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %15 = arith.muli %13, %14 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %16 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.broadcast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %18 = tt.broadcast %16 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = arith.addi %17, %18 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %20 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %22 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %23 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %24 = arith.muli %22, %23 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %11 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %26 = tt.broadcast %24 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = tt.broadcast %25 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = arith.addi %26, %27 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %32 = tt.addptr %31, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %33 = arith.addi %arg8, %c31_i32 : i32
  %34 = arith.divsi %33, %c32_i32 : i32
  %35 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = arith.cmpi slt, %13, %35 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = tt.broadcast %36 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %38 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = arith.cmpi slt, %25, %38 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.broadcast %39 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %41 = arith.muli %arg10, %c32_i32 : i32
  %42 = tt.splat %41 : i32 -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %43:3 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %21, %arg15 = %30) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>)  : i32 {
    %66 = arith.muli %arg12, %c32_i32 : i32
    %67 = arith.subi %arg8, %66 : i32
    %68 = tt.splat %67 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %69 = arith.cmpi slt, %16, %68 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %70 = tt.broadcast %69 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %71 = arith.andi %37, %70 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %72 = tt.load %arg14, %71, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %73 = tt.splat %67 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %74 = arith.cmpi slt, %22, %73 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %75 = tt.broadcast %74 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %76 = arith.andi %75, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %77 = tt.load %arg15, %76, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %78 = triton_gpu.convert_layout %72 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %79 = triton_gpu.convert_layout %77 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %80 = tt.dot %78, %79, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %81 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %82 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    scf.yield %80, %81, %82 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  }
  %44 = tt.splat %arg7 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %45 = arith.cmpi slt, %12, %44 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %46 = tt.load %32, %45, %cst_2 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %47 = arith.sitofp %arg4 : i32 to f32
  %48 = tt.splat %47 : f32 -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %49 = arith.mulf %43#0, %48 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %50 = arith.sitofp %arg5 : i32 to f16
  %51 = tt.splat %50 : f16 -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %52 = arith.mulf %46, %51 : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %53 = tt.expand_dims %52 {axis = 0 : i32} : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>> -> tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %54 = arith.extf %53 : tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %55 = tt.broadcast %54 : tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %56 = arith.addf %49, %55 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %57 = arith.truncf %56 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %58 = tt.splat %arg11 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = arith.muli %58, %13 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %61 = tt.addptr %60, %59 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = tt.broadcast %61 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = tt.addptr %62, %27 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %64 = arith.andi %37, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = triton_gpu.convert_layout %57 : tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.store %63, %65, %64 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.return

Value: live
ImplicitTypeIDRegistry::lookupOrInsert(mlir::dataflow::Lattice<mlir::dataflow::ConstantValue>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::dataflow::PredecessorState)
Creating dependency between mlir::dataflow::PredecessorState of tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {...}
and mlir::dataflow::PredecessorState on tt.return
Priming analysis: mlir::{anonymous}::ConstantAnalysis
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
Value: dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %c0_i32 = arith.constant 0 : i32
Value: 0 : i32
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %c1_i32 = arith.constant 1 : i32
Value: 1 : i32
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %c32_i32 = arith.constant 32 : i32
Value: 32 : i32
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %c31_i32 = arith.constant 31 : i32
Value: 31 : i32
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %cst_1 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %cst_2 = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
Value: dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %0 = tt.get_program_id x : i32
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %1 = tt.get_program_id y : i32
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %2 = arith.muli %0, %c32_i32 : i32
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %5 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %6 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %7 = arith.addi %6, %3 : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %8 = arith.muli %1, %c32_i32 : i32
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %9 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %10 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %11 = arith.addi %9, %4 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %12 = arith.addi %10, %5 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %13 = tt.expand_dims %7 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %14 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %15 = arith.muli %13, %14 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %16 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %17 = tt.broadcast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %18 = tt.broadcast %16 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %19 = arith.addi %17, %18 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %20 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %22 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %23 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %24 = arith.muli %22, %23 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %25 = tt.expand_dims %11 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %26 = tt.broadcast %24 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %27 = tt.broadcast %25 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %28 = arith.addi %26, %27 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %29 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %31 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %32 = tt.addptr %31, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %33 = arith.addi %arg8, %c31_i32 : i32
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %34 = arith.divsi %33, %c32_i32 : i32
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %35 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %36 = arith.cmpi slt, %13, %35 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %37 = tt.broadcast %36 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %38 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %39 = arith.cmpi slt, %25, %38 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %40 = tt.broadcast %39 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %41 = arith.muli %arg10, %c32_i32 : i32
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %42 = tt.splat %41 : i32 -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %66 = arith.muli %arg12, %c32_i32 : i32
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %67 = arith.subi %arg8, %66 : i32
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %68 = tt.splat %67 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %69 = arith.cmpi slt, %16, %68 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %70 = tt.broadcast %69 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %71 = arith.andi %37, %70 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %72 = tt.load %arg14, %71, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %73 = tt.splat %67 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %74 = arith.cmpi slt, %22, %73 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %75 = tt.broadcast %74 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %76 = arith.andi %75, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %77 = tt.load %arg15, %76, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %78 = triton_gpu.convert_layout %72 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %79 = triton_gpu.convert_layout %77 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %80 = tt.dot %78, %79, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %81 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %82 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %43:3 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %21, %arg15 = %30) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>)  : i32 {...}
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %43:3 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %21, %arg15 = %30) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>)  : i32 {...}
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %43:3 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %21, %arg15 = %30) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>)  : i32 {...}
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of <block argument> of type 'i32' at index: 0
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of <block argument> of type 'tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>' at index: 1
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of <block argument> of type 'tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>' at index: 2
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of <block argument> of type 'tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>' at index: 3
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %44 = tt.splat %arg7 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %45 = arith.cmpi slt, %12, %44 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %46 = tt.load %32, %45, %cst_2 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %47 = arith.sitofp %arg4 : i32 to f32
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %48 = tt.splat %47 : f32 -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %49 = arith.mulf %43#0, %48 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %50 = arith.sitofp %arg5 : i32 to f16
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %51 = tt.splat %50 : f16 -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %52 = arith.mulf %46, %51 : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %53 = tt.expand_dims %52 {axis = 0 : i32} : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>> -> tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %54 = arith.extf %53 : tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %55 = tt.broadcast %54 : tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %56 = arith.addf %49, %55 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %57 = arith.truncf %56 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %58 = tt.splat %arg11 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %59 = arith.muli %58, %13 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %60 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %61 = tt.addptr %60, %59 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %62 = tt.broadcast %61 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %63 = tt.addptr %62, %27 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %64 = arith.andi %37, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of %65 = triton_gpu.convert_layout %57 : tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of <block argument> of type '!tt.ptr<f16>' at index: 0
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of <block argument> of type '!tt.ptr<f16>' at index: 1
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of <block argument> of type '!tt.ptr<f16>' at index: 2
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of <block argument> of type '!tt.ptr<f16>' at index: 3
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of <block argument> of type 'i32' at index: 4
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of <block argument> of type 'i32' at index: 5
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of <block argument> of type 'i32' at index: 6
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of <block argument> of type 'i32' at index: 7
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of <block argument> of type 'i32' at index: 8
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of <block argument> of type 'i32' at index: 9
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of <block argument> of type 'i32' at index: 10
Value: <UNKNOWN>
Propagating update to mlir::dataflow::Lattice<mlir::dataflow::ConstantValue> of <block argument> of type 'i32' at index: 11
Value: <UNKNOWN>
Priming analysis: mlir::triton::{anonymous}::AxisInfoAnalysis
ImplicitTypeIDRegistry::lookupOrInsert(mlir::dataflow::Lattice<mlir::triton::AxisInfo>)
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of <block argument> of type '!tt.ptr<f16>' at index: 0
Value: contiguity = [1], divisibility = [16], constancy = [1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of <block argument> of type '!tt.ptr<f16>' at index: 1
Value: contiguity = [1], divisibility = [16], constancy = [1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of <block argument> of type '!tt.ptr<f16>' at index: 2
Value: contiguity = [1], divisibility = [16], constancy = [1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of <block argument> of type '!tt.ptr<f16>' at index: 3
Value: contiguity = [1], divisibility = [16], constancy = [1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of <block argument> of type 'i32' at index: 4
Value: contiguity = [1], divisibility = [1], constancy = [1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of <block argument> of type 'i32' at index: 5
Value: contiguity = [1], divisibility = [1], constancy = [1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of <block argument> of type 'i32' at index: 6
Value: contiguity = [1], divisibility = [16], constancy = [1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of <block argument> of type 'i32' at index: 7
Value: contiguity = [1], divisibility = [16], constancy = [1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of <block argument> of type 'i32' at index: 8
Value: contiguity = [1], divisibility = [16], constancy = [1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of <block argument> of type 'i32' at index: 9
Value: contiguity = [1], divisibility = [16], constancy = [1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of <block argument> of type 'i32' at index: 10
Value: contiguity = [1], divisibility = [16], constancy = [1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of <block argument> of type 'i32' at index: 11
Value: contiguity = [1], divisibility = [16], constancy = [1], constant_value = <none>
Creating dependency between mlir::dataflow::PredecessorState of tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {...}
and mlir::dataflow::PredecessorState on ^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %c32_i32 = arith.constant 32 : i32
  %c31_i32 = arith.constant 31 : i32
  %cst_1 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %5 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %7 = arith.addi %6, %3 : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %8 = arith.muli %1, %c32_i32 : i32
  %9 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %10 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %11 = arith.addi %9, %4 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %12 = arith.addi %10, %5 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %13 = tt.expand_dims %7 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %14 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %15 = arith.muli %13, %14 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %16 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.broadcast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %18 = tt.broadcast %16 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = arith.addi %17, %18 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %20 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %22 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %23 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %24 = arith.muli %22, %23 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %11 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %26 = tt.broadcast %24 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = tt.broadcast %25 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = arith.addi %26, %27 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %32 = tt.addptr %31, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %33 = arith.addi %arg8, %c31_i32 : i32
  %34 = arith.divsi %33, %c32_i32 : i32
  %35 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = arith.cmpi slt, %13, %35 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = tt.broadcast %36 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %38 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = arith.cmpi slt, %25, %38 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.broadcast %39 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %41 = arith.muli %arg10, %c32_i32 : i32
  %42 = tt.splat %41 : i32 -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %43:3 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %21, %arg15 = %30) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>)  : i32 {
    %66 = arith.muli %arg12, %c32_i32 : i32
    %67 = arith.subi %arg8, %66 : i32
    %68 = tt.splat %67 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %69 = arith.cmpi slt, %16, %68 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %70 = tt.broadcast %69 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %71 = arith.andi %37, %70 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %72 = tt.load %arg14, %71, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %73 = tt.splat %67 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %74 = arith.cmpi slt, %22, %73 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %75 = tt.broadcast %74 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %76 = arith.andi %75, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %77 = tt.load %arg15, %76, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %78 = triton_gpu.convert_layout %72 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %79 = triton_gpu.convert_layout %77 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %80 = tt.dot %78, %79, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %81 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %82 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    scf.yield %80, %81, %82 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  }
  %44 = tt.splat %arg7 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %45 = arith.cmpi slt, %12, %44 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %46 = tt.load %32, %45, %cst_2 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %47 = arith.sitofp %arg4 : i32 to f32
  %48 = tt.splat %47 : f32 -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %49 = arith.mulf %43#0, %48 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %50 = arith.sitofp %arg5 : i32 to f16
  %51 = tt.splat %50 : f16 -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %52 = arith.mulf %46, %51 : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %53 = tt.expand_dims %52 {axis = 0 : i32} : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>> -> tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %54 = arith.extf %53 : tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %55 = tt.broadcast %54 : tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %56 = arith.addf %49, %55 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %57 = arith.truncf %56 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %58 = tt.splat %arg11 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = arith.muli %58, %13 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %61 = tt.addptr %60, %59 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = tt.broadcast %61 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = tt.addptr %62, %27 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %64 = arith.andi %37, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = triton_gpu.convert_layout %57 : tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.store %63, %65, %64 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.return

Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
Value: contiguity = [1, 1], divisibility = [1, 1], constancy = [1, 1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %c0_i32 = arith.constant 0 : i32
Value: contiguity = [1], divisibility = [4611686018427387904], constancy = [1], constant_value = 0
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %c1_i32 = arith.constant 1 : i32
Value: contiguity = [1], divisibility = [1], constancy = [1], constant_value = 1
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [1, 1], constancy = [1, 1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %c32_i32 = arith.constant 32 : i32
Value: contiguity = [1], divisibility = [32], constancy = [1], constant_value = 32
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %c31_i32 = arith.constant 31 : i32
Value: contiguity = [1], divisibility = [1], constancy = [1], constant_value = 31
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %cst_1 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [32, 32], constancy = [32, 32], constant_value = 32
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %cst_2 = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
Value: contiguity = [1], divisibility = [1], constancy = [1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %0 = tt.get_program_id x : i32
Value: contiguity = [1], divisibility = [1], constancy = [1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %1 = tt.get_program_id y : i32
Value: contiguity = [1], divisibility = [1], constancy = [1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %2 = arith.muli %0, %c32_i32 : i32
Value: contiguity = [1], divisibility = [32], constancy = [1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
Value: contiguity = [32], divisibility = [1073741824], constancy = [1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
Value: contiguity = [32], divisibility = [1073741824], constancy = [1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %5 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
Value: contiguity = [32], divisibility = [1073741824], constancy = [1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %6 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
Value: contiguity = [1], divisibility = [32], constancy = [32], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %7 = arith.addi %6, %3 : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
Value: contiguity = [32], divisibility = [32], constancy = [1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %8 = arith.muli %1, %c32_i32 : i32
Value: contiguity = [1], divisibility = [32], constancy = [1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %9 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
Value: contiguity = [1], divisibility = [32], constancy = [32], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %10 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
Value: contiguity = [1], divisibility = [32], constancy = [32], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %11 = arith.addi %9, %4 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
Value: contiguity = [32], divisibility = [32], constancy = [1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %12 = arith.addi %10, %5 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
Value: contiguity = [32], divisibility = [32], constancy = [1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %13 = tt.expand_dims %7 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [32, 1], divisibility = [32, 1], constancy = [1, 1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %14 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [16, 16], constancy = [32, 1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %15 = arith.muli %13, %14 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [16, 16], constancy = [1, 1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %16 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 32], divisibility = [1, 1073741824], constancy = [1, 1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %17 = tt.broadcast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [16, 16], constancy = [1, 32], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %18 = tt.broadcast %16 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 32], divisibility = [1, 1073741824], constancy = [32, 1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %19 = arith.addi %17, %18 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 32], divisibility = [1, 16], constancy = [1, 1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %20 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [16, 16], constancy = [32, 32], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 32], divisibility = [2, 16], constancy = [1, 1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %22 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [32, 1], divisibility = [1073741824, 1], constancy = [1, 1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %23 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [16, 16], constancy = [32, 1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %24 = arith.muli %22, %23 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [16, 16], constancy = [1, 1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %25 = tt.expand_dims %11 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 32], divisibility = [1, 32], constancy = [1, 1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %26 = tt.broadcast %24 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [16, 16], constancy = [1, 32], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %27 = tt.broadcast %25 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 32], divisibility = [1, 32], constancy = [32, 1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %28 = arith.addi %26, %27 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 32], divisibility = [1, 16], constancy = [1, 1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %29 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [16, 16], constancy = [32, 32], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 32], divisibility = [2, 16], constancy = [1, 1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %31 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
Value: contiguity = [1], divisibility = [16], constancy = [32], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %32 = tt.addptr %31, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
Value: contiguity = [32], divisibility = [16], constancy = [1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %33 = arith.addi %arg8, %c31_i32 : i32
Value: contiguity = [1], divisibility = [1], constancy = [1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %34 = arith.divsi %33, %c32_i32 : i32
Value: contiguity = [1], divisibility = [1], constancy = [1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %35 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [16, 16], constancy = [32, 1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %36 = arith.cmpi slt, %13, %35 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [1, 1], constancy = [16, 1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %37 = tt.broadcast %36 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [1, 1], constancy = [16, 32], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %38 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [16, 16], constancy = [1, 32], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %39 = arith.cmpi slt, %25, %38 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [1, 1], constancy = [1, 16], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %40 = tt.broadcast %39 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [1, 1], constancy = [32, 16], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %41 = arith.muli %arg10, %c32_i32 : i32
Value: contiguity = [1], divisibility = [512], constancy = [1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %42 = tt.splat %41 : i32 -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [512, 512], constancy = [32, 32], constant_value = <none>
Creating dependency between mlir::dataflow::PredecessorState of %43:3 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %21, %arg15 = %30) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>)  : i32 {...}
and mlir::dataflow::PredecessorState on %43:3 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %21, %arg15 = %30) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>)  : i32 {...}
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %44 = tt.splat %arg7 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
Value: contiguity = [1], divisibility = [16], constancy = [32], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %45 = arith.cmpi slt, %12, %44 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
Value: contiguity = [1], divisibility = [1], constancy = [16], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %46 = tt.load %32, %45, %cst_2 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
Value: contiguity = [1], divisibility = [1], constancy = [1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %47 = arith.sitofp %arg4 : i32 to f32
Value: contiguity = [1], divisibility = [1], constancy = [1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %48 = tt.splat %47 : f32 -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
Value: contiguity = [1, 1], divisibility = [1, 1], constancy = [32, 32], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %43:3 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %21, %arg15 = %30) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>)  : i32 {...}
Value: contiguity = [4611686018427387904, 4611686018427387904], divisibility = [4611686018427387904, 4611686018427387904], constancy = [4611686018427387904, 4611686018427387904], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %49 = arith.mulf %43#0, %48 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
Value: contiguity = [1, 1], divisibility = [1, 1], constancy = [1, 1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %50 = arith.sitofp %arg5 : i32 to f16
Value: contiguity = [1], divisibility = [1], constancy = [1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %51 = tt.splat %50 : f16 -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
Value: contiguity = [1], divisibility = [1], constancy = [32], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %52 = arith.mulf %46, %51 : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
Value: contiguity = [1], divisibility = [1], constancy = [1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %53 = tt.expand_dims %52 {axis = 0 : i32} : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>> -> tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
Value: contiguity = [1, 1], divisibility = [1, 1], constancy = [1, 1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %54 = arith.extf %53 : tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
Value: contiguity = [1, 1], divisibility = [1, 1], constancy = [1, 1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %55 = tt.broadcast %54 : tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
Value: contiguity = [1, 1], divisibility = [1, 1], constancy = [32, 1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %56 = arith.addf %49, %55 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
Value: contiguity = [1, 1], divisibility = [1, 1], constancy = [1, 1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %57 = arith.truncf %56 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
Value: contiguity = [1, 1], divisibility = [1, 1], constancy = [1, 1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %58 = tt.splat %arg11 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [16, 16], constancy = [32, 1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %59 = arith.muli %58, %13 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [16, 16], constancy = [1, 1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %60 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [16, 16], constancy = [32, 1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %61 = tt.addptr %60, %59 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [16, 16], constancy = [1, 1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %62 = tt.broadcast %61 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [16, 16], constancy = [1, 32], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %63 = tt.addptr %62, %27 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 32], divisibility = [2, 16], constancy = [1, 1], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %64 = arith.andi %37, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [1, 1], constancy = [16, 16], constant_value = <none>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %65 = triton_gpu.convert_layout %57 : tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [1, 1], constancy = [1, 1], constant_value = <none>
Invoking 'mlir::dataflow::DeadCodeAnalysis' on: %43:3 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %21, %arg15 = %30) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>)  : i32 {...}
Propagating update to mlir::dataflow::Executable of ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>):
  %66 = arith.muli %arg12, %c32_i32 : i32
  %67 = arith.subi %arg8, %66 : i32
  %68 = tt.splat %67 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = arith.cmpi slt, %16, %68 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = tt.broadcast %69 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = arith.andi %37, %70 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %72 = tt.load %arg14, %71, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %73 = tt.splat %67 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %74 = arith.cmpi slt, %22, %73 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = tt.broadcast %74 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %76 = arith.andi %75, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %77 = tt.load %arg15, %76, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = triton_gpu.convert_layout %72 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %79 = triton_gpu.convert_layout %77 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %80 = tt.dot %78, %79, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %81 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  scf.yield %80, %81, %82 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

Value: live
Propagating update to mlir::dataflow::PredecessorState of ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>):
  %66 = arith.muli %arg12, %c32_i32 : i32
  %67 = arith.subi %arg8, %66 : i32
  %68 = tt.splat %67 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = arith.cmpi slt, %16, %68 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = tt.broadcast %69 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = arith.andi %37, %70 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %72 = tt.load %arg14, %71, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %73 = tt.splat %67 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %74 = arith.cmpi slt, %22, %73 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = tt.broadcast %74 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %76 = arith.andi %75, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %77 = tt.load %arg15, %76, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = triton_gpu.convert_layout %72 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %79 = triton_gpu.convert_layout %77 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %80 = tt.dot %78, %79, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %81 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  scf.yield %80, %81, %82 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

Value: (all) predecessors:
  %43:3 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %21, %arg15 = %30) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>)  : i32 {
  %66 = arith.muli %arg12, %c32_i32 : i32
  %67 = arith.subi %arg8, %66 : i32
  %68 = tt.splat %67 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = arith.cmpi slt, %16, %68 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = tt.broadcast %69 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = arith.andi %37, %70 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %72 = tt.load %arg14, %71, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %73 = tt.splat %67 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %74 = arith.cmpi slt, %22, %73 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = tt.broadcast %74 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %76 = arith.andi %75, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %77 = tt.load %arg15, %76, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = triton_gpu.convert_layout %72 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %79 = triton_gpu.convert_layout %77 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %80 = tt.dot %78, %79, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %81 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  scf.yield %80, %81, %82 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
}

Propagating update to mlir::dataflow::Executable of %43:3 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %21, %arg15 = %30) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>)  : i32 {...}
Value: live
Propagating update to mlir::dataflow::PredecessorState of %43:3 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %21, %arg15 = %30) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>)  : i32 {...}
Value: (all) predecessors:
  %43:3 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %21, %arg15 = %30) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>)  : i32 {
  %66 = arith.muli %arg12, %c32_i32 : i32
  %67 = arith.subi %arg8, %66 : i32
  %68 = tt.splat %67 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = arith.cmpi slt, %16, %68 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = tt.broadcast %69 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = arith.andi %37, %70 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %72 = tt.load %arg14, %71, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %73 = tt.splat %67 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %74 = arith.cmpi slt, %22, %73 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = tt.broadcast %74 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %76 = arith.andi %75, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %77 = tt.load %arg15, %76, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = triton_gpu.convert_layout %72 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %79 = triton_gpu.convert_layout %77 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %80 = tt.dot %78, %79, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %81 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  scf.yield %80, %81, %82 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
}

Invoking 'mlir::triton::{anonymous}::AxisInfoAnalysis' on: %49 = arith.mulf %43#0, %48 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
Invoking 'mlir::dataflow::DeadCodeAnalysis' on: ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>):
  %66 = arith.muli %arg12, %c32_i32 : i32
  %67 = arith.subi %arg8, %66 : i32
  %68 = tt.splat %67 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = arith.cmpi slt, %16, %68 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = tt.broadcast %69 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = arith.andi %37, %70 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %72 = tt.load %arg14, %71, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %73 = tt.splat %67 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %74 = arith.cmpi slt, %22, %73 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = tt.broadcast %74 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %76 = arith.andi %75, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %77 = tt.load %arg15, %76, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = triton_gpu.convert_layout %72 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %79 = triton_gpu.convert_layout %77 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %80 = tt.dot %78, %79, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %81 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  scf.yield %80, %81, %82 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

Invoking 'mlir::triton::{anonymous}::AxisInfoAnalysis' on: ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>):
  %66 = arith.muli %arg12, %c32_i32 : i32
  %67 = arith.subi %arg8, %66 : i32
  %68 = tt.splat %67 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = arith.cmpi slt, %16, %68 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = tt.broadcast %69 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = arith.andi %37, %70 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %72 = tt.load %arg14, %71, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %73 = tt.splat %67 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %74 = arith.cmpi slt, %22, %73 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = tt.broadcast %74 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %76 = arith.andi %75, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %77 = tt.load %arg15, %76, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = triton_gpu.convert_layout %72 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %79 = triton_gpu.convert_layout %77 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %80 = tt.dot %78, %79, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %81 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  scf.yield %80, %81, %82 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

Creating dependency between mlir::dataflow::PredecessorState of ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>):
  %66 = arith.muli %arg12, %c32_i32 : i32
  %67 = arith.subi %arg8, %66 : i32
  %68 = tt.splat %67 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = arith.cmpi slt, %16, %68 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = tt.broadcast %69 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = arith.andi %37, %70 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %72 = tt.load %arg14, %71, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %73 = tt.splat %67 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %74 = arith.cmpi slt, %22, %73 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = tt.broadcast %74 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %76 = arith.andi %75, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %77 = tt.load %arg15, %76, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = triton_gpu.convert_layout %72 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %79 = triton_gpu.convert_layout %77 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %80 = tt.dot %78, %79, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %81 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  scf.yield %80, %81, %82 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

and mlir::dataflow::PredecessorState on ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>):
  %66 = arith.muli %arg12, %c32_i32 : i32
  %67 = arith.subi %arg8, %66 : i32
  %68 = tt.splat %67 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = arith.cmpi slt, %16, %68 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = tt.broadcast %69 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = arith.andi %37, %70 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %72 = tt.load %arg14, %71, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %73 = tt.splat %67 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %74 = arith.cmpi slt, %22, %73 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = tt.broadcast %74 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %76 = arith.andi %75, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %77 = tt.load %arg15, %76, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = triton_gpu.convert_layout %72 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %79 = triton_gpu.convert_layout %77 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %80 = tt.dot %78, %79, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %81 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  scf.yield %80, %81, %82 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

Creating dependency between mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %c0_i32 = arith.constant 0 : i32
and mlir::dataflow::Lattice<mlir::triton::AxisInfo> on %43:3 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %21, %arg15 = %30) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>)  : i32 {...}
Creating dependency between mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %c1_i32 = arith.constant 1 : i32
and mlir::dataflow::Lattice<mlir::triton::AxisInfo> on %43:3 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %21, %arg15 = %30) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>)  : i32 {...}
Creating dependency between mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
and mlir::dataflow::Lattice<mlir::triton::AxisInfo> on ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>):
  %66 = arith.muli %arg12, %c32_i32 : i32
  %67 = arith.subi %arg8, %66 : i32
  %68 = tt.splat %67 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = arith.cmpi slt, %16, %68 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = tt.broadcast %69 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = arith.andi %37, %70 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %72 = tt.load %arg14, %71, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %73 = tt.splat %67 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %74 = arith.cmpi slt, %22, %73 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = tt.broadcast %74 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %76 = arith.andi %75, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %77 = tt.load %arg15, %76, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = triton_gpu.convert_layout %72 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %79 = triton_gpu.convert_layout %77 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %80 = tt.dot %78, %79, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %81 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  scf.yield %80, %81, %82 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of <block argument> of type 'tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>' at index: 1
Value: contiguity = [1, 1], divisibility = [1, 1], constancy = [1, 1], constant_value = <none>
Creating dependency between mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
and mlir::dataflow::Lattice<mlir::triton::AxisInfo> on ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>):
  %66 = arith.muli %arg12, %c32_i32 : i32
  %67 = arith.subi %arg8, %66 : i32
  %68 = tt.splat %67 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = arith.cmpi slt, %16, %68 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = tt.broadcast %69 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = arith.andi %37, %70 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %72 = tt.load %arg14, %71, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %73 = tt.splat %67 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %74 = arith.cmpi slt, %22, %73 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = tt.broadcast %74 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %76 = arith.andi %75, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %77 = tt.load %arg15, %76, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = triton_gpu.convert_layout %72 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %79 = triton_gpu.convert_layout %77 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %80 = tt.dot %78, %79, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %81 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  scf.yield %80, %81, %82 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of <block argument> of type 'tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>' at index: 2
Value: contiguity = [1, 32], divisibility = [2, 16], constancy = [1, 1], constant_value = <none>
Creating dependency between mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
and mlir::dataflow::Lattice<mlir::triton::AxisInfo> on ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>):
  %66 = arith.muli %arg12, %c32_i32 : i32
  %67 = arith.subi %arg8, %66 : i32
  %68 = tt.splat %67 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = arith.cmpi slt, %16, %68 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = tt.broadcast %69 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = arith.andi %37, %70 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %72 = tt.load %arg14, %71, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %73 = tt.splat %67 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %74 = arith.cmpi slt, %22, %73 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = tt.broadcast %74 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %76 = arith.andi %75, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %77 = tt.load %arg15, %76, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = triton_gpu.convert_layout %72 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %79 = triton_gpu.convert_layout %77 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %80 = tt.dot %78, %79, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %81 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  scf.yield %80, %81, %82 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of <block argument> of type 'tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>' at index: 3
Value: contiguity = [1, 32], divisibility = [2, 16], constancy = [1, 1], constant_value = <none>
Invoking 'mlir::dataflow::DeadCodeAnalysis' on: %66 = arith.muli %arg12, %c32_i32 : i32
Invoking 'mlir::dataflow::DeadCodeAnalysis' on: %67 = arith.subi %arg8, %66 : i32
Invoking 'mlir::dataflow::DeadCodeAnalysis' on: %68 = tt.splat %67 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Invoking 'mlir::dataflow::DeadCodeAnalysis' on: %69 = arith.cmpi slt, %16, %68 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Invoking 'mlir::dataflow::DeadCodeAnalysis' on: %70 = tt.broadcast %69 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Invoking 'mlir::dataflow::DeadCodeAnalysis' on: %71 = arith.andi %37, %70 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Invoking 'mlir::dataflow::DeadCodeAnalysis' on: %72 = tt.load %arg14, %71, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Invoking 'mlir::dataflow::DeadCodeAnalysis' on: %73 = tt.splat %67 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Invoking 'mlir::dataflow::DeadCodeAnalysis' on: %74 = arith.cmpi slt, %22, %73 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Invoking 'mlir::dataflow::DeadCodeAnalysis' on: %75 = tt.broadcast %74 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Invoking 'mlir::dataflow::DeadCodeAnalysis' on: %76 = arith.andi %75, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Invoking 'mlir::dataflow::DeadCodeAnalysis' on: %77 = tt.load %arg15, %76, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Invoking 'mlir::dataflow::DeadCodeAnalysis' on: %78 = triton_gpu.convert_layout %72 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
Invoking 'mlir::dataflow::DeadCodeAnalysis' on: %79 = triton_gpu.convert_layout %77 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
Invoking 'mlir::dataflow::DeadCodeAnalysis' on: %80 = tt.dot %78, %79, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
Invoking 'mlir::dataflow::DeadCodeAnalysis' on: %81 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Invoking 'mlir::dataflow::DeadCodeAnalysis' on: %82 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Invoking 'mlir::dataflow::DeadCodeAnalysis' on: scf.yield %80, %81, %82 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Propagating update to mlir::dataflow::PredecessorState of ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>):
  %66 = arith.muli %arg12, %c32_i32 : i32
  %67 = arith.subi %arg8, %66 : i32
  %68 = tt.splat %67 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = arith.cmpi slt, %16, %68 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = tt.broadcast %69 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = arith.andi %37, %70 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %72 = tt.load %arg14, %71, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %73 = tt.splat %67 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %74 = arith.cmpi slt, %22, %73 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = tt.broadcast %74 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %76 = arith.andi %75, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %77 = tt.load %arg15, %76, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = triton_gpu.convert_layout %72 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %79 = triton_gpu.convert_layout %77 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %80 = tt.dot %78, %79, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %81 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  scf.yield %80, %81, %82 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

Value: (all) predecessors:
  %43:3 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %21, %arg15 = %30) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>)  : i32 {
  %66 = arith.muli %arg12, %c32_i32 : i32
  %67 = arith.subi %arg8, %66 : i32
  %68 = tt.splat %67 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = arith.cmpi slt, %16, %68 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = tt.broadcast %69 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = arith.andi %37, %70 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %72 = tt.load %arg14, %71, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %73 = tt.splat %67 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %74 = arith.cmpi slt, %22, %73 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = tt.broadcast %74 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %76 = arith.andi %75, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %77 = tt.load %arg15, %76, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = triton_gpu.convert_layout %72 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %79 = triton_gpu.convert_layout %77 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %80 = tt.dot %78, %79, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %81 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  scf.yield %80, %81, %82 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
}
  scf.yield %80, %81, %82 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

Propagating update to mlir::dataflow::PredecessorState of %43:3 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %21, %arg15 = %30) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>)  : i32 {...}
Value: (all) predecessors:
  %43:3 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %21, %arg15 = %30) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>)  : i32 {
  %66 = arith.muli %arg12, %c32_i32 : i32
  %67 = arith.subi %arg8, %66 : i32
  %68 = tt.splat %67 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = arith.cmpi slt, %16, %68 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = tt.broadcast %69 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = arith.andi %37, %70 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %72 = tt.load %arg14, %71, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %73 = tt.splat %67 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %74 = arith.cmpi slt, %22, %73 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = tt.broadcast %74 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %76 = arith.andi %75, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %77 = tt.load %arg15, %76, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = triton_gpu.convert_layout %72 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %79 = triton_gpu.convert_layout %77 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %80 = tt.dot %78, %79, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %81 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  scf.yield %80, %81, %82 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
}
  scf.yield %80, %81, %82 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

Invoking 'mlir::triton::{anonymous}::AxisInfoAnalysis' on: %66 = arith.muli %arg12, %c32_i32 : i32
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %66 = arith.muli %arg12, %c32_i32 : i32
Value: contiguity = [1], divisibility = [32], constancy = [1], constant_value = <none>
Invoking 'mlir::triton::{anonymous}::AxisInfoAnalysis' on: %67 = arith.subi %arg8, %66 : i32
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %67 = arith.subi %arg8, %66 : i32
Value: contiguity = [1], divisibility = [16], constancy = [1], constant_value = <none>
Invoking 'mlir::triton::{anonymous}::AxisInfoAnalysis' on: %68 = tt.splat %67 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %68 = tt.splat %67 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [16, 16], constancy = [1, 32], constant_value = <none>
Invoking 'mlir::triton::{anonymous}::AxisInfoAnalysis' on: %69 = arith.cmpi slt, %16, %68 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %69 = arith.cmpi slt, %16, %68 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [1, 1], constancy = [1, 16], constant_value = <none>
Invoking 'mlir::triton::{anonymous}::AxisInfoAnalysis' on: %70 = tt.broadcast %69 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %70 = tt.broadcast %69 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [1, 1], constancy = [32, 16], constant_value = <none>
Invoking 'mlir::triton::{anonymous}::AxisInfoAnalysis' on: %71 = arith.andi %37, %70 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %71 = arith.andi %37, %70 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [1, 1], constancy = [16, 16], constant_value = <none>
Invoking 'mlir::triton::{anonymous}::AxisInfoAnalysis' on: %72 = tt.load %arg14, %71, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %72 = tt.load %arg14, %71, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [1, 1], constancy = [1, 1], constant_value = <none>
Invoking 'mlir::triton::{anonymous}::AxisInfoAnalysis' on: %73 = tt.splat %67 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %73 = tt.splat %67 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [16, 16], constancy = [32, 1], constant_value = <none>
Invoking 'mlir::triton::{anonymous}::AxisInfoAnalysis' on: %74 = arith.cmpi slt, %22, %73 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %74 = arith.cmpi slt, %22, %73 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [1, 1], constancy = [16, 1], constant_value = <none>
Invoking 'mlir::triton::{anonymous}::AxisInfoAnalysis' on: %75 = tt.broadcast %74 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %75 = tt.broadcast %74 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [1, 1], constancy = [16, 32], constant_value = <none>
Invoking 'mlir::triton::{anonymous}::AxisInfoAnalysis' on: %76 = arith.andi %75, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %76 = arith.andi %75, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [1, 1], constancy = [16, 16], constant_value = <none>
Invoking 'mlir::triton::{anonymous}::AxisInfoAnalysis' on: %77 = tt.load %arg15, %76, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %77 = tt.load %arg15, %76, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 1], divisibility = [1, 1], constancy = [1, 1], constant_value = <none>
Invoking 'mlir::triton::{anonymous}::AxisInfoAnalysis' on: %78 = triton_gpu.convert_layout %72 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %78 = triton_gpu.convert_layout %72 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
Value: contiguity = [1, 1], divisibility = [1, 1], constancy = [1, 1], constant_value = <none>
Invoking 'mlir::triton::{anonymous}::AxisInfoAnalysis' on: %79 = triton_gpu.convert_layout %77 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %79 = triton_gpu.convert_layout %77 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
Value: contiguity = [1, 1], divisibility = [1, 1], constancy = [1, 1], constant_value = <none>
Invoking 'mlir::triton::{anonymous}::AxisInfoAnalysis' on: %80 = tt.dot %78, %79, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %80 = tt.dot %78, %79, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
Value: contiguity = [1, 1], divisibility = [1, 1], constancy = [1, 1], constant_value = <none>
Invoking 'mlir::triton::{anonymous}::AxisInfoAnalysis' on: %81 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %81 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 32], divisibility = [2, 16], constancy = [1, 1], constant_value = <none>
Invoking 'mlir::triton::{anonymous}::AxisInfoAnalysis' on: %82 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %82 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Value: contiguity = [1, 32], divisibility = [2, 16], constancy = [1, 1], constant_value = <none>
Invoking 'mlir::triton::{anonymous}::AxisInfoAnalysis' on: scf.yield %80, %81, %82 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
Invoking 'mlir::triton::{anonymous}::AxisInfoAnalysis' on: %43:3 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %21, %arg15 = %30) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>)  : i32 {...}
Creating dependency between mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
and mlir::dataflow::Lattice<mlir::triton::AxisInfo> on %43:3 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %21, %arg15 = %30) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>)  : i32 {...}
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %43:3 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %21, %arg15 = %30) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>)  : i32 {...}
Value: contiguity = [1, 1], divisibility = [1, 1], constancy = [1, 1], constant_value = <none>
Creating dependency between mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
and mlir::dataflow::Lattice<mlir::triton::AxisInfo> on %43:3 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %21, %arg15 = %30) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>)  : i32 {...}
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %43:3 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %21, %arg15 = %30) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>)  : i32 {...}
Value: contiguity = [1, 32], divisibility = [2, 16], constancy = [1, 1], constant_value = <none>
Creating dependency between mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
and mlir::dataflow::Lattice<mlir::triton::AxisInfo> on %43:3 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %21, %arg15 = %30) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>)  : i32 {...}
Propagating update to mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %43:3 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %21, %arg15 = %30) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>)  : i32 {...}
Value: contiguity = [1, 32], divisibility = [2, 16], constancy = [1, 1], constant_value = <none>
Creating dependency between mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %80 = tt.dot %78, %79, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
and mlir::dataflow::Lattice<mlir::triton::AxisInfo> on %43:3 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %21, %arg15 = %30) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>)  : i32 {...}
Creating dependency between mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %81 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
and mlir::dataflow::Lattice<mlir::triton::AxisInfo> on %43:3 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %21, %arg15 = %30) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>)  : i32 {...}
Creating dependency between mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %82 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
and mlir::dataflow::Lattice<mlir::triton::AxisInfo> on %43:3 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %21, %arg15 = %30) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>)  : i32 {...}
Invoking 'mlir::triton::{anonymous}::AxisInfoAnalysis' on: ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>):
  %66 = arith.muli %arg12, %c32_i32 : i32
  %67 = arith.subi %arg8, %66 : i32
  %68 = tt.splat %67 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = arith.cmpi slt, %16, %68 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = tt.broadcast %69 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = arith.andi %37, %70 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %72 = tt.load %arg14, %71, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %73 = tt.splat %67 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %74 = arith.cmpi slt, %22, %73 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = tt.broadcast %74 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %76 = arith.andi %75, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %77 = tt.load %arg15, %76, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = triton_gpu.convert_layout %72 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %79 = triton_gpu.convert_layout %77 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %80 = tt.dot %78, %79, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %81 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  scf.yield %80, %81, %82 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

Creating dependency between mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %80 = tt.dot %78, %79, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
and mlir::dataflow::Lattice<mlir::triton::AxisInfo> on ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>):
  %66 = arith.muli %arg12, %c32_i32 : i32
  %67 = arith.subi %arg8, %66 : i32
  %68 = tt.splat %67 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = arith.cmpi slt, %16, %68 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = tt.broadcast %69 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = arith.andi %37, %70 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %72 = tt.load %arg14, %71, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %73 = tt.splat %67 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %74 = arith.cmpi slt, %22, %73 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = tt.broadcast %74 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %76 = arith.andi %75, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %77 = tt.load %arg15, %76, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = triton_gpu.convert_layout %72 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %79 = triton_gpu.convert_layout %77 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %80 = tt.dot %78, %79, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %81 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  scf.yield %80, %81, %82 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

Creating dependency between mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %81 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
and mlir::dataflow::Lattice<mlir::triton::AxisInfo> on ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>):
  %66 = arith.muli %arg12, %c32_i32 : i32
  %67 = arith.subi %arg8, %66 : i32
  %68 = tt.splat %67 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = arith.cmpi slt, %16, %68 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = tt.broadcast %69 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = arith.andi %37, %70 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %72 = tt.load %arg14, %71, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %73 = tt.splat %67 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %74 = arith.cmpi slt, %22, %73 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = tt.broadcast %74 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %76 = arith.andi %75, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %77 = tt.load %arg15, %76, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = triton_gpu.convert_layout %72 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %79 = triton_gpu.convert_layout %77 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %80 = tt.dot %78, %79, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %81 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  scf.yield %80, %81, %82 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

Creating dependency between mlir::dataflow::Lattice<mlir::triton::AxisInfo> of %82 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
and mlir::dataflow::Lattice<mlir::triton::AxisInfo> on ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>):
  %66 = arith.muli %arg12, %c32_i32 : i32
  %67 = arith.subi %arg8, %66 : i32
  %68 = tt.splat %67 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = arith.cmpi slt, %16, %68 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = tt.broadcast %69 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = arith.andi %37, %70 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %72 = tt.load %arg14, %71, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %73 = tt.splat %67 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %74 = arith.cmpi slt, %22, %73 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = tt.broadcast %74 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %76 = arith.andi %75, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %77 = tt.load %arg15, %76, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = triton_gpu.convert_layout %72 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %79 = triton_gpu.convert_layout %77 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %80 = tt.dot %78, %79, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %81 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  scf.yield %80, %81, %82 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

Invoking 'mlir::triton::{anonymous}::AxisInfoAnalysis' on: %43:3 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %21, %arg15 = %30) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>)  : i32 {...}
Invoking 'mlir::triton::{anonymous}::AxisInfoAnalysis' on: %49 = arith.mulf %43#0, %48 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
[triton-matmul-loop-pipeline]: Found 2 loads to pipeline:
[triton-matmul-loop-pipeline]:   - load: %72 = tt.load %arg14, %71, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
[triton-matmul-loop-pipeline]:     at indirection level: 0
[triton-matmul-loop-pipeline]:     used by op: %80 = tt.dot %78, %79, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
[triton-matmul-loop-pipeline]:   - load: %77 = tt.load %arg15, %76, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
[triton-matmul-loop-pipeline]:     at indirection level: 0
[triton-matmul-loop-pipeline]:     used by op: %80 = tt.dot %78, %79, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
[axis-info]: getPtrAlignment order[0] 1 maxMultipleBytes = 16 maxContig = 32 elemNumBits = 16 maxMultiple = 8 alignment 8
[axis-info]: -- contiguity = [1, 32], divisibility = [2, 16], constancy = [1, 1], constant_value = <none>
[axis-info]: getPtrContiguity uniqueContigPerThread = 8
[axis-info]: getMaskAlignment maskOrder[0] 1 alignment 16
[axis-info]: -- contiguity = [1, 1], divisibility = [1, 1], constancy = [16, 16], constant_value = <none>
[triton-matmul-loop-pipeline]: Load %72 = tt.load %arg14, %71, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> has width 128
[axis-info]: getPtrAlignment order[0] 1 maxMultipleBytes = 16 maxContig = 32 elemNumBits = 16 maxMultiple = 8 alignment 8
[axis-info]: -- contiguity = [1, 32], divisibility = [2, 16], constancy = [1, 1], constant_value = <none>
[axis-info]: getPtrContiguity uniqueContigPerThread = 8
[axis-info]: getMaskAlignment maskOrder[0] 1 alignment 16
[axis-info]: -- contiguity = [1, 1], divisibility = [1, 1], constancy = [16, 16], constant_value = <none>
[triton-matmul-loop-pipeline]: Load %77 = tt.load %arg15, %76, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> has width 128
[triton-matmul-loop-pipeline]: Coarse schedule loads only:

---- Ops in stage 0
        cluster: 1:
	%77 = tt.load %arg15, %76, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 1:
	%72 = tt.load %arg14, %71, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

---- Ops in stage 1

---- Ops in stage 2
        cluster: 0:
	%80 = tt.dot %78, %79, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
[triton-matmul-loop-pipeline]: Coarse schedule with prologue and epilogue:

---- Ops in stage 0
        cluster: 2:
	%77 = tt.load %arg15, %76, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 2:
	%72 = tt.load %arg14, %71, %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

---- Ops in stage 1

---- Ops in stage 2
        cluster: 1:
	%80 = tt.dot %78, %79, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::triton::MemDescType>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::triton::MemDescType>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::detail::AddIOpGenericAdaptorBase::Properties)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::triton::gpu::detail::AsyncCopyGlobalToLocalOpGenericAdaptorBase::Properties)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::triton::gpu::detail::AsyncWaitOpGenericAdaptorBase::Properties)
[triton-matmul-loop-pipeline]: Coarse schedule with async loads:

---- Ops in stage 0
        cluster: 2:
	ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::triton::gpu::AsyncTokenType>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::triton::gpu::AsyncTokenType>::Impl>()::Empty>)
%82 = triton_gpu.async_commit_group %81
        cluster: 2:
	%91 = triton_gpu.async_copy_global_to_local %arg15, %90 mask %89 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
        cluster: 2:
	%81 = triton_gpu.async_copy_global_to_local %arg14, %80 mask %79 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
        cluster: 2:
	%92 = triton_gpu.async_commit_group %91

---- Ops in stage 1
        cluster: 4:
	%94 = triton_gpu.memdesc_subview %44[%73, %c0_i32_6, %c0_i32_6] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
        cluster: 4:
	%84 = triton_gpu.memdesc_subview %43[%73, %c0_i32_5, %c0_i32_5] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
        cluster: 4:
	%83 = triton_gpu.async_wait %82 {num = 0 : i32}
        cluster: 4:
	%93 = triton_gpu.async_wait %92 {num = 0 : i32}

---- Ops in stage 2
        cluster: 1:
	%98 = tt.dot %96, %97, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
[triton-matmul-loop-pipeline]: Coarse schedule with dependencies:

---- Ops in stage 0
        cluster: 2:
	%82 = triton_gpu.async_commit_group %81
        cluster: 2:
	%80 = triton_gpu.memdesc_subview %43[%70, %c0_i32_5, %c0_i32_5] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
        cluster: 2:
	%77 = arith.cmpi slt, %16, %76 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 2:
	%86 = tt.splat %75 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 2:
	%69 = arith.cmpi slt, %68, %c2_i32 : i32
        cluster: 2:
	%91 = triton_gpu.async_copy_global_to_local %arg15, %90 mask %89 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
        cluster: 2:
	%78 = tt.broadcast %77 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 2:
	%68 = arith.addi %arg16, %c1_i32_4 : i32
        cluster: 2:
	%74 = arith.muli %arg12, %c32_i32 : i32
        cluster: 2:
	%81 = triton_gpu.async_copy_global_to_local %arg14, %80 mask %79 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
        cluster: 2:
	%87 = arith.cmpi slt, %22, %86 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 2:
	%88 = tt.broadcast %87 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 2:
	%75 = arith.subi %arg8, %74 : i32
        cluster: 2:
	%79 = arith.andi %37, %78 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 2:
	ImplicitTypeIDRegistry::lookupOrInsert(mlir::SelectLikeOpInterface::Trait<mlir::TypeID::get<mlir::SelectLikeOpInterface::Trait>()::Empty>)
%70 = arith.select %69, %68, %c0_i32_3 : i32
        cluster: 2:
	%90 = triton_gpu.memdesc_subview %44[%70, %c0_i32_6, %c0_i32_6] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
        cluster: 2:
	%89 = arith.andi %88, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 2:
	%76 = tt.splat %75 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 2:
	%92 = triton_gpu.async_commit_group %91

---- Ops in stage 1
        cluster: 4:
	%94 = triton_gpu.memdesc_subview %44[%73, %c0_i32_6, %c0_i32_6] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
        cluster: 4:
	%71 = arith.addi %arg17, %c1_i32_4 : i32
        cluster: 4:
	%73 = arith.select %72, %71, %c0_i32_3 : i32
        cluster: 4:
	%84 = triton_gpu.memdesc_subview %43[%73, %c0_i32_5, %c0_i32_5] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
        cluster: 4:
	%83 = triton_gpu.async_wait %82 {num = 0 : i32}
        cluster: 4:
	%72 = arith.cmpi slt, %71, %c2_i32 : i32
        cluster: 4:
	%93 = triton_gpu.async_wait %92 {num = 0 : i32}

---- Ops in stage 2
        cluster: 1:
	%97 = triton_gpu.convert_layout %95 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
        cluster: 1:
	%85 = triton_gpu.local_load %84 token %83 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 1:
	%98 = tt.dot %96, %97, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
        cluster: 1:
	%96 = triton_gpu.convert_layout %85 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
        cluster: 1:
	%95 = triton_gpu.local_load %94 token %93 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
[triton-matmul-loop-pipeline]: Coarse schedule with dist 1:

---- Ops in stage 0
        cluster: 3:
	%82 = triton_gpu.async_commit_group %81
        cluster: 3:
	%80 = triton_gpu.memdesc_subview %43[%70, %c0_i32_5, %c0_i32_5] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
        cluster: 3:
	%77 = arith.cmpi slt, %16, %76 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 3:
	%86 = tt.splat %75 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 3:
	%69 = arith.cmpi slt, %68, %c2_i32 : i32
        cluster: 3:
	%91 = triton_gpu.async_copy_global_to_local %arg15, %90 mask %89 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
        cluster: 3:
	%78 = tt.broadcast %77 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 3:
	%68 = arith.addi %arg16, %c1_i32_4 : i32
        cluster: 3:
	%74 = arith.muli %arg12, %c32_i32 : i32
        cluster: 3:
	%81 = triton_gpu.async_copy_global_to_local %arg14, %80 mask %79 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
        cluster: 3:
	%87 = arith.cmpi slt, %22, %86 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 3:
	%88 = tt.broadcast %87 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 3:
	%75 = arith.subi %arg8, %74 : i32
        cluster: 3:
	%79 = arith.andi %37, %78 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 3:
	%70 = arith.select %69, %68, %c0_i32_3 : i32
        cluster: 3:
	%90 = triton_gpu.memdesc_subview %44[%70, %c0_i32_6, %c0_i32_6] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
        cluster: 3:
	%89 = arith.andi %88, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 3:
	%76 = tt.splat %75 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 3:
	%92 = triton_gpu.async_commit_group %91

---- Ops in stage 1
        cluster: 2:
	%99 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 5:
	%94 = triton_gpu.memdesc_subview %44[%73, %c0_i32_6, %c0_i32_6] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
        cluster: 5:
	%71 = arith.addi %arg17, %c1_i32_4 : i32
        cluster: 5:
	%73 = arith.select %72, %71, %c0_i32_3 : i32
        cluster: 5:
	%84 = triton_gpu.memdesc_subview %43[%73, %c0_i32_5, %c0_i32_5] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
        cluster: 5:
	%83 = triton_gpu.async_wait %82 {num = 0 : i32}
        cluster: 5:
	%72 = arith.cmpi slt, %71, %c2_i32 : i32
        cluster: 2:
	%100 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 5:
	%93 = triton_gpu.async_wait %92 {num = 0 : i32}

---- Ops in stage 2
        cluster: 1:
	%97 = triton_gpu.convert_layout %95 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
        cluster: 1:
	%85 = triton_gpu.local_load %84 token %83 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 1:
	%98 = tt.dot %96, %97, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
        cluster: 1:
	%96 = triton_gpu.convert_layout %85 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
        cluster: 1:
	%95 = triton_gpu.local_load %94 token %93 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
[triton-matmul-loop-pipeline]: Final coarse schedule:

---- Ops in stage 0
        cluster: 3:
	%82 = triton_gpu.async_commit_group %81
        cluster: 3:
	%80 = triton_gpu.memdesc_subview %43[%70, %c0_i32_5, %c0_i32_5] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
        cluster: 3:
	%77 = arith.cmpi slt, %16, %76 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 3:
	%86 = tt.splat %75 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 3:
	%69 = arith.cmpi slt, %68, %c2_i32 : i32
        cluster: 3:
	%91 = triton_gpu.async_copy_global_to_local %arg15, %90 mask %89 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
        cluster: 3:
	%78 = tt.broadcast %77 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 3:
	%68 = arith.addi %arg16, %c1_i32_4 : i32
        cluster: 3:
	%74 = arith.muli %arg12, %c32_i32 : i32
        cluster: 3:
	%81 = triton_gpu.async_copy_global_to_local %arg14, %80 mask %79 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
        cluster: 3:
	%87 = arith.cmpi slt, %22, %86 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 3:
	%88 = tt.broadcast %87 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 3:
	%75 = arith.subi %arg8, %74 : i32
        cluster: 3:
	%79 = arith.andi %37, %78 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 3:
	%70 = arith.select %69, %68, %c0_i32_3 : i32
        cluster: 3:
	%90 = triton_gpu.memdesc_subview %44[%70, %c0_i32_6, %c0_i32_6] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
        cluster: 3:
	%89 = arith.andi %88, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 3:
	%76 = tt.splat %75 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 3:
	%92 = triton_gpu.async_commit_group %91

---- Ops in stage 1
        cluster: 2:
	%99 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 5:
	%94 = triton_gpu.memdesc_subview %44[%73, %c0_i32_6, %c0_i32_6] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
        cluster: 5:
	%71 = arith.addi %arg17, %c1_i32_4 : i32
        cluster: 5:
	%73 = arith.select %72, %71, %c0_i32_3 : i32
        cluster: 5:
	%84 = triton_gpu.memdesc_subview %43[%73, %c0_i32_5, %c0_i32_5] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
        cluster: 5:
	%83 = triton_gpu.async_wait %82 {num = 0 : i32}
        cluster: 5:
	%72 = arith.cmpi slt, %71, %c2_i32 : i32
        cluster: 2:
	%100 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 5:
	%93 = triton_gpu.async_wait %92 {num = 0 : i32}

---- Ops in stage 2
        cluster: 1:
	%97 = triton_gpu.convert_layout %95 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
        cluster: 1:
	%85 = triton_gpu.local_load %84 token %83 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
        cluster: 1:
	%98 = tt.dot %96, %97, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
        cluster: 1:
	%96 = triton_gpu.convert_layout %85 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
        cluster: 1:
	%95 = triton_gpu.local_load %94 token %93 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
[triton-loop-pipelining]: Start initializeLoopInfo
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::detail::MulIOpGenericAdaptorBase::Properties)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::triton::GlobalMemory)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::MemoryEffects::Read)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::triton::gpu::SharedMemory)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::MemoryEffects::Write)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::detail::SubIOpGenericAdaptorBase::Properties)
[triton-matmul-loop-pipeline]: Original loop:
%110:11 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %78, %arg15 = %79, %arg16 = %82, %arg17 = %105, %arg18 = %107, %arg19 = %106, %arg20 = %109, %arg21 = %108, %arg22 = %93, %arg23 = %102) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token)  : i32 {
  %c2_i32_11 = arith.constant 2 : i32
  %134 = arith.muli %c1_i32, %c2_i32_11 : i32
  %135 = arith.subi %34, %134 : i32
  %136 = arith.cmpi slt, %arg12, %135 : i32
  %c1_i32_12 = arith.constant 1 : i32
  %137 = arith.muli %c1_i32, %c1_i32_12 : i32
  %138 = arith.subi %34, %137 : i32
  %139 = arith.cmpi slt, %arg12, %138 : i32
  %140 = triton_gpu.local_load %arg18 token %arg19 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %141 = triton_gpu.local_load %arg20 token %arg21 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %142 = triton_gpu.convert_layout %140 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %143 = triton_gpu.convert_layout %141 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %144 = tt.dot %142, %143, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %145 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %146 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %147 = arith.addi %arg16, %c1_i32_4 : i32
  %148 = arith.cmpi slt, %147, %c2_i32 : i32
  %149 = arith.select %148, %147, %c0_i32_3 : i32
  %c2_i32_13 = arith.constant 2 : i32
  %150 = arith.muli %c1_i32, %c2_i32_13 : i32
  %151 = arith.addi %arg12, %150 : i32
  %152 = arith.muli %151, %c32_i32 : i32
  %153 = arith.subi %arg8, %152 : i32
  %154 = tt.splat %153 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %155 = arith.cmpi slt, %16, %154 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %156 = tt.broadcast %155 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %157 = arith.andi %37, %156 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %158 = triton_gpu.memdesc_subview %43[%149, %c0_i32_5, %c0_i32_5] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %159 = tt.splat %136 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %160 = arith.andi %159, %157 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %161 = triton_gpu.async_copy_global_to_local %145, %158 mask %160 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %162 = triton_gpu.async_commit_group %161
  %163 = tt.splat %153 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %164 = arith.cmpi slt, %22, %163 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %165 = tt.broadcast %164 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %166 = arith.andi %165, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %167 = triton_gpu.memdesc_subview %44[%149, %c0_i32_6, %c0_i32_6] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %168 = tt.splat %136 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %169 = arith.andi %168, %166 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %170 = triton_gpu.async_copy_global_to_local %146, %167 mask %169 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %171 = triton_gpu.async_commit_group %170
  %172 = arith.addi %arg17, %c1_i32_4 : i32
  %173 = arith.cmpi slt, %172, %c2_i32 : i32
  %174 = arith.select %173, %172, %c0_i32_3 : i32
  %175 = triton_gpu.async_wait %arg22 {num = 0 : i32}
  %176 = triton_gpu.memdesc_subview %43[%174, %c0_i32_5, %c0_i32_5] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %177 = triton_gpu.async_wait %arg23 {num = 0 : i32}
  %178 = triton_gpu.memdesc_subview %44[%174, %c0_i32_6, %c0_i32_6] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  scf.yield %144, %145, %146, %149, %174, %176, %175, %178, %177, %162, %171 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token
}
[triton-matmul-loop-pipeline]: No properly async dots.
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DialectFoldInterface)
** Replace : 'arith.constant'(0x55bafa42ccb0)
** Modified: 'arith.select'(0x55bafa41dcb0)
** Modified: 'arith.select'(0x55bafa431c30)
** Modified: 'arith.select'(0x55bafa427f20)
** Modified: 'arith.select'(0x55bafa424290)
** Modified: 'arith.select'(0x55bafa424bf0)
** Erase   : 'arith.constant'(0x55bafa42ccb0)
** Replace : 'arith.constant'(0x55bafa4273a0)
** Modified: 'arith.addi'(0x55bafa41db50)
** Modified: 'arith.addi'(0x55bafa431ad0)
** Modified: 'arith.addi'(0x55bafa427dc0)
** Modified: 'arith.addi'(0x55bafa424130)
** Modified: 'arith.addi'(0x55bafa33b640)
** Erase   : 'arith.constant'(0x55bafa4273a0)
** Replace : 'arith.constant'(0x55bafa4271c0)
** Modified: 'triton_gpu.memdesc_subview'(0x55bafa41de10)
** Modified: 'triton_gpu.memdesc_subview'(0x55bafa41de10)
** Modified: 'triton_gpu.memdesc_subview'(0x55bafa4322b0)
** Modified: 'triton_gpu.memdesc_subview'(0x55bafa4322b0)
** Modified: 'triton_gpu.memdesc_subview'(0x55bafa428080)
** Modified: 'triton_gpu.memdesc_subview'(0x55bafa428080)
** Modified: 'triton_gpu.memdesc_subview'(0x55bafa424940)
** Modified: 'triton_gpu.memdesc_subview'(0x55bafa424940)
** Modified: 'triton_gpu.memdesc_subview'(0x55bafa364a60)
** Modified: 'triton_gpu.memdesc_subview'(0x55bafa364a60)
** Erase   : 'arith.constant'(0x55bafa4271c0)
** Replace : 'arith.constant'(0x55bafa3b9e50)
** Modified: 'triton_gpu.memdesc_subview'(0x55bafa41df90)
** Modified: 'triton_gpu.memdesc_subview'(0x55bafa41df90)
** Modified: 'triton_gpu.memdesc_subview'(0x55bafa432900)
** Modified: 'triton_gpu.memdesc_subview'(0x55bafa432900)
** Modified: 'triton_gpu.memdesc_subview'(0x55bafa428200)
** Modified: 'triton_gpu.memdesc_subview'(0x55bafa428200)
** Modified: 'triton_gpu.memdesc_subview'(0x55bafa3885c0)
** Modified: 'triton_gpu.memdesc_subview'(0x55bafa3885c0)
** Modified: 'triton_gpu.memdesc_subview'(0x55bafa4272b0)
** Modified: 'triton_gpu.memdesc_subview'(0x55bafa4272b0)
** Erase   : 'arith.constant'(0x55bafa3b9e50)
** Replace : 'arith.constant'(0x55bafa430680)
** Modified: 'arith.muli'(0x55bafa4306f0)
** Erase   : 'arith.constant'(0x55bafa430680)
** Replace : 'arith.constant'(0x55bafa353050)
** Modified: 'arith.muli'(0x55bafa3530c0)
** Erase   : 'arith.constant'(0x55bafa353050)
** Replace : 'arith.constant'(0x55bafa423b80)
** Modified: 'arith.muli'(0x55bafa423bf0)
** Erase   : 'arith.constant'(0x55bafa423b80)
** Replace : 'arith.constant'(0x55bafa423e00)
** Modified: 'arith.muli'(0x55bafa423e70)
** Erase   : 'arith.constant'(0x55bafa423e00)
** Replace : 'arith.constant'(0x55bafa42bd50)
** Modified: 'arith.muli'(0x55bafa433500)
** Erase   : 'arith.constant'(0x55bafa42bd50)
** Replace : 'arith.constant'(0x55bafa433710)
** Modified: 'arith.muli'(0x55bafa433780)
** Erase   : 'arith.constant'(0x55bafa433710)
** Replace : 'arith.constant'(0x55bafa431db0)
** Modified: 'arith.muli'(0x55bafa431e20)
** Erase   : 'arith.constant'(0x55bafa431db0)

//===-------------------------------------------===//
Processing operation : 'tt.return'(0x55bafa41c8e0) {
  "tt.return"() : () -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.store'(0x55bafa41c810) {
  "tt.store"(%140, %142, %141) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> ()

ImplicitTypeIDRegistry::lookupOrInsert(mlir::MemoryEffects::Allocate)
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.convert_layout'(0x55bafa41c730) {
  %142 = "triton_gpu.convert_layout"(%134) : (tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.andi'(0x55bafa41c620) {
  %141 = "arith.andi"(%47, %50) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.addptr'(0x55bafa41c510) {
  %140 = "tt.addptr"(%139, %37) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.broadcast'(0x55bafa41c440) {
  %139 = "tt.broadcast"(%138) : (tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.addptr'(0x55bafa41c390) {
  %138 = "tt.addptr"(%137, %136) : (tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa41c300) {
  %137 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.muli'(0x55bafa41c250) {
  %136 = "arith.muli"(%135, %23) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa41c1c0) {
  %135 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.truncf'(0x55bafa41c120) {
  %134 = "arith.truncf"(%133) : (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>) -> tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.addf'(0x55bafa41c070) {
  %133 = "arith.addf"(%126, %132) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>) -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.broadcast'(0x55bafa41bfe0) {
  %132 = "tt.broadcast"(%131) : (tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>) -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.extf'(0x55bafa41bf50) {
  %131 = "arith.extf"(%130) : (tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>) -> tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.expand_dims'(0x55bafa41bec0) {
  %130 = "tt.expand_dims"(%129) <{axis = 0 : i32}> : (tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>) -> tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.mulf'(0x55bafa41be10) {
  %129 = "arith.mulf"(%123, %128) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>) -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa41bd80) {
  %128 = "tt.splat"(%127) : (f16) -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.sitofp'(0x55bafa41a070) {
  %127 = "arith.sitofp"(%arg5) : (i32) -> f16

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.mulf'(0x55bafa41b850) {
  %126 = "arith.mulf"(%119#0, %125) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>) -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa41b7c0) {
  %125 = "tt.splat"(%124) : (f32) -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.sitofp'(0x55bafa41b730) {
  %124 = "arith.sitofp"(%arg4) : (i32) -> f32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.load'(0x55bafa41b630) {
  %123 = "tt.load"(%42, %122, %9) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi1, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>) -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa41b580) {
  %122 = "arith.cmpi"(%22, %121) <{predicate = 2 : i64}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>) -> tensor<32xi1, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa41b4f0) {
  %121 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.local_dealloc'(0x55bafa428560) {
  "triton_gpu.local_dealloc"(%54) : (!tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>) -> ()

ImplicitTypeIDRegistry::lookupOrInsert(mlir::MemoryEffects::Free)
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.local_dealloc'(0x55bafa3b9eb0) {
  "triton_gpu.local_dealloc"(%53) : (!tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.async_wait'(0x55bafa41a110) {
  %120 = "triton_gpu.async_wait"() <{num = 0 : i32}> : () -> !triton_gpu.async.token

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'scf.yield'(0x55bafa425fe0) {
  "scf.yield"(%153, %154, %155, %158, %183, %184, %185, %186, %185, %171, %180) : (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.async_wait'(0x55bafa419c00) {
  %185 = "triton_gpu.async_wait"(%arg23) <{num = 2 : i32}> : (!triton_gpu.async.token) -> !triton_gpu.async.token

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa41dc00) {
  %182 = "arith.cmpi"(%181, %0) <{predicate = 2 : i64}> : (i32, i32) -> i1

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.async_commit_group'(0x55bafa41dac0) {
  %180 = "triton_gpu.async_commit_group"(%179) : (!triton_gpu.async.token) -> !triton_gpu.async.token

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.async_copy_global_to_local'(0x55bafa41d870) {
  %179 = "triton_gpu.async_copy_global_to_local"(%155, %176, %178, %5) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> !triton_gpu.async.token

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.andi'(0x55bafa41da10) {
  %178 = "arith.andi"(%177, %175) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa41d980) {
  %177 = "tt.splat"(%145) : (i1) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.andi'(0x55bafa432850) {
  %175 = "arith.andi"(%174, %50) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.broadcast'(0x55bafa4327c0) {
  %174 = "tt.broadcast"(%173) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa432710) {
  %173 = "arith.cmpi"(%32, %172) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa432680) {
  %172 = "tt.splat"(%162) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.async_commit_group'(0x55bafa4325f0) {
  %171 = "triton_gpu.async_commit_group"(%170) : (!triton_gpu.async.token) -> !triton_gpu.async.token

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.async_copy_global_to_local'(0x55bafa4323a0) {
  %170 = "triton_gpu.async_copy_global_to_local"(%154, %167, %169, %5) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> !triton_gpu.async.token

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.andi'(0x55bafa432540) {
  %169 = "arith.andi"(%168, %166) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa4324b0) {
  %168 = "tt.splat"(%145) : (i1) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.andi'(0x55bafa432200) {
  %166 = "arith.andi"(%47, %165) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.broadcast'(0x55bafa432170) {
  %165 = "tt.broadcast"(%164) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa4320c0) {
  %164 = "arith.cmpi"(%26, %163) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa432030) {
  %163 = "tt.splat"(%162) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.subi'(0x55bafa431f80) {
  %162 = "arith.subi"(%arg8, %161) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.muli'(0x55bafa431d00) {
  %161 = "arith.muli"(%160, %6) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.addi'(0x55bafa431ed0) {
  %160 = "arith.addi"(%arg12, %159) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.muli'(0x55bafa431e20) {
  %159 = "arith.muli"(%4, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> success : operation was folded
//===-------------------------------------------===//
** Insert  : 'arith.constant'(0x55bafa423b80)
** Replace : 'arith.muli'(0x55bafa431e20)
** Modified: 'arith.addi'(0x55bafa431ed0)
** Erase   : 'arith.muli'(0x55bafa431e20)
// *** IR Dump After Successful Folding ***
%109:11 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %78, %arg15 = %79, %arg16 = %82, %arg17 = %105, %arg18 = %106, %arg19 = %107, %arg20 = %108, %arg21 = %107, %arg22 = %93, %arg23 = %102) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token)  : i32 {
  %133 = arith.muli %c1_i32, %c2_i32 : i32
  %134 = arith.subi %34, %133 : i32
  %135 = arith.cmpi slt, %arg12, %134 : i32
  %136 = arith.muli %c1_i32, %c1_i32 : i32
  %137 = arith.subi %34, %136 : i32
  %138 = arith.cmpi slt, %arg12, %137 : i32
  %139 = triton_gpu.local_load %arg18 token %arg19 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %140 = triton_gpu.local_load %arg20 token %arg21 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %141 = triton_gpu.convert_layout %139 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %142 = triton_gpu.convert_layout %140 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %143 = tt.dot %141, %142, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %144 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %145 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %146 = arith.addi %arg16, %c1_i32 : i32
  %147 = arith.cmpi slt, %146, %c2_i32 : i32
  %148 = arith.select %147, %146, %c0_i32 : i32
  %c2_i32_3 = arith.constant 2 : i32
  %149 = arith.addi %arg12, %c2_i32_3 : i32
  %150 = arith.muli %149, %c32_i32 : i32
  %151 = arith.subi %arg8, %150 : i32
  %152 = tt.splat %151 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %153 = arith.cmpi slt, %16, %152 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %154 = tt.broadcast %153 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %155 = arith.andi %37, %154 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %156 = triton_gpu.memdesc_subview %43[%148, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %157 = tt.splat %135 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %158 = arith.andi %157, %155 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %159 = triton_gpu.async_copy_global_to_local %144, %156 mask %158 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %160 = triton_gpu.async_commit_group %159
  %161 = tt.splat %151 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %162 = arith.cmpi slt, %22, %161 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %163 = tt.broadcast %162 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %164 = arith.andi %163, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %165 = triton_gpu.memdesc_subview %44[%148, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %166 = tt.splat %135 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %167 = arith.andi %166, %164 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %168 = triton_gpu.async_copy_global_to_local %145, %165 mask %167 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %169 = triton_gpu.async_commit_group %168
  %170 = arith.addi %arg17, %c1_i32 : i32
  %171 = arith.cmpi slt, %170, %c2_i32 : i32
  %172 = arith.select %171, %170, %c0_i32 : i32
  %173 = triton_gpu.memdesc_subview %43[%172, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %174 = triton_gpu.async_wait %arg23 {num = 2 : i32}
  %175 = triton_gpu.memdesc_subview %44[%172, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  scf.yield %143, %144, %145, %148, %172, %173, %174, %175, %174, %160, %169 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token
}



//===-------------------------------------------===//
Processing operation : 'arith.addi'(0x55bafa431ed0) {
  %160 = "arith.addi"(%arg12, %159) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.constant'(0x55bafa423b80) {
  %159 = "arith.constant"() <{value = 2 : i32}> : () -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa431b80) {
  %157 = "arith.cmpi"(%156, %0) <{predicate = 2 : i64}> : (i32, i32) -> i1

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.addptr'(0x55bafa433cc0) {
  %155 = "tt.addptr"(%arg15, %52) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.addptr'(0x55bafa433c10) {
  %154 = "tt.addptr"(%arg14, %8) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.dot'(0x55bafa40c2a0) {
  %153 = "tt.dot"(%151, %152, %arg13) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>, tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>) -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.convert_layout'(0x55bafa433b80) {
  %152 = "triton_gpu.convert_layout"(%150) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.convert_layout'(0x55bafa433af0) {
  %151 = "triton_gpu.convert_layout"(%149) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.local_load'(0x55bafa433a40) {
  %150 = "triton_gpu.local_load"(%arg20, %arg21) : (!tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.local_load'(0x55bafa433990) {
  %149 = "triton_gpu.local_load"(%arg18, %arg19) : (!tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa4338e0) {
  %148 = "arith.cmpi"(%arg12, %147) <{predicate = 2 : i64}> : (i32, i32) -> i1

  ** Erase   : 'arith.cmpi'(0x55bafa4338e0)
} -> success : operation is trivially dead
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.subi'(0x55bafa433830) {
  %147 = "arith.subi"(%44, %146) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

  ** Erase   : 'arith.subi'(0x55bafa433830)
} -> success : operation is trivially dead
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.muli'(0x55bafa433780) {
  %146 = "arith.muli"(%4, %4) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

  ** Erase   : 'arith.muli'(0x55bafa433780)
} -> success : operation is trivially dead
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa433660) {
  %145 = "arith.cmpi"(%arg12, %144) <{predicate = 2 : i64}> : (i32, i32) -> i1

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.subi'(0x55bafa4335b0) {
  %144 = "arith.subi"(%44, %143) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.muli'(0x55bafa433500) {
  %143 = "arith.muli"(%4, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> success : operation was folded
//===-------------------------------------------===//
** Insert  : 'arith.constant'(0x55bafa353050)
** Replace : 'arith.muli'(0x55bafa433500)
** Modified: 'arith.subi'(0x55bafa4335b0)
** Erase   : 'arith.muli'(0x55bafa433500)
// *** IR Dump After Successful Folding ***
%109:11 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %78, %arg15 = %79, %arg16 = %82, %arg17 = %105, %arg18 = %106, %arg19 = %107, %arg20 = %108, %arg21 = %107, %arg22 = %93, %arg23 = %102) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token)  : i32 {
  %c2_i32_3 = arith.constant 2 : i32
  %133 = arith.subi %34, %c2_i32_3 : i32
  %134 = arith.cmpi slt, %arg12, %133 : i32
  %135 = triton_gpu.local_load %arg18 token %arg19 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %136 = triton_gpu.local_load %arg20 token %arg21 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %137 = triton_gpu.convert_layout %135 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %138 = triton_gpu.convert_layout %136 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
  %139 = tt.dot %137, %138, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %140 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %141 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %142 = arith.addi %arg16, %c1_i32 : i32
  %143 = arith.cmpi slt, %142, %c2_i32 : i32
  %144 = arith.select %143, %142, %c0_i32 : i32
  %c2_i32_4 = arith.constant 2 : i32
  %145 = arith.addi %arg12, %c2_i32_4 : i32
  %146 = arith.muli %145, %c32_i32 : i32
  %147 = arith.subi %arg8, %146 : i32
  %148 = tt.splat %147 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %149 = arith.cmpi slt, %16, %148 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %150 = tt.broadcast %149 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %151 = arith.andi %37, %150 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %152 = triton_gpu.memdesc_subview %43[%144, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %153 = tt.splat %134 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %154 = arith.andi %153, %151 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %155 = triton_gpu.async_copy_global_to_local %140, %152 mask %154 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %156 = triton_gpu.async_commit_group %155
  %157 = tt.splat %147 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %158 = arith.cmpi slt, %22, %157 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %159 = tt.broadcast %158 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %160 = arith.andi %159, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %161 = triton_gpu.memdesc_subview %44[%144, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %162 = tt.splat %134 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %163 = arith.andi %162, %160 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %164 = triton_gpu.async_copy_global_to_local %141, %161 mask %163 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %165 = triton_gpu.async_commit_group %164
  %166 = arith.addi %arg17, %c1_i32 : i32
  %167 = arith.cmpi slt, %166, %c2_i32 : i32
  %168 = arith.select %167, %166, %c0_i32 : i32
  %169 = triton_gpu.memdesc_subview %43[%168, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %170 = triton_gpu.async_wait %arg23 {num = 2 : i32}
  %171 = triton_gpu.memdesc_subview %44[%168, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  scf.yield %139, %140, %141, %144, %168, %169, %170, %171, %170, %156, %165 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token
}



//===-------------------------------------------===//
Processing operation : 'arith.subi'(0x55bafa4335b0) {
  %144 = "arith.subi"(%44, %143) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.constant'(0x55bafa353050) {
  %143 = "arith.constant"() <{value = 2 : i32}> : () -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.async_wait'(0x55bafa41fa50) {
  %117 = "triton_gpu.async_wait"(%82) <{num = 2 : i32}> : (!triton_gpu.async.token) -> !triton_gpu.async.token

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa427e70) {
  %114 = "arith.cmpi"(%113, %0) <{predicate = 2 : i64}> : (i32, i32) -> i1

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.async_commit_group'(0x55bafa427d30) {
  %112 = "triton_gpu.async_commit_group"(%111) : (!triton_gpu.async.token) -> !triton_gpu.async.token

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.async_copy_global_to_local'(0x55bafa427ae0) {
  %111 = "triton_gpu.async_copy_global_to_local"(%89, %108, %110, %5) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> !triton_gpu.async.token

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.andi'(0x55bafa427c80) {
  %110 = "arith.andi"(%109, %107) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa427bf0) {
  %109 = "tt.splat"(%85) : (i1) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.andi'(0x55bafa427a30) {
  %107 = "arith.andi"(%106, %50) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.broadcast'(0x55bafa4279a0) {
  %106 = "tt.broadcast"(%105) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa4278f0) {
  %105 = "arith.cmpi"(%32, %104) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa427860) {
  %104 = "tt.splat"(%94) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.async_commit_group'(0x55bafa4277d0) {
  %103 = "triton_gpu.async_commit_group"(%102) : (!triton_gpu.async.token) -> !triton_gpu.async.token

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.async_copy_global_to_local'(0x55bafa427580) {
  %102 = "triton_gpu.async_copy_global_to_local"(%88, %99, %101, %5) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> !triton_gpu.async.token

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.andi'(0x55bafa427720) {
  %101 = "arith.andi"(%100, %98) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa427690) {
  %100 = "tt.splat"(%85) : (i1) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.andi'(0x55bafa424690) {
  %98 = "arith.andi"(%47, %97) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.broadcast'(0x55bafa424600) {
  %97 = "tt.broadcast"(%96) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa424550) {
  %96 = "arith.cmpi"(%26, %95) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa4244c0) {
  %95 = "tt.splat"(%94) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.subi'(0x55bafa424410) {
  %94 = "arith.subi"(%arg8, %93) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.muli'(0x55bafa424360) {
  %93 = "arith.muli"(%87, %6) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa4241e0) {
  %91 = "arith.cmpi"(%90, %0) <{predicate = 2 : i64}> : (i32, i32) -> i1

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.addptr'(0x55bafa424080) {
  %89 = "tt.addptr"(%40, %52) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.addptr'(0x55bafa423fd0) {
  %88 = "tt.addptr"(%31, %8) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.addi'(0x55bafa423f20) {
  %87 = "arith.addi"(%3, %86) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> success : operation was folded
//===-------------------------------------------===//
** Modified: 'arith.addi'(0x55bafa423f20)
// *** IR Dump After Successful Folding ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c2_i32 = arith.constant 2 : i32
  %c-1_i32 = arith.constant -1 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %c32_i32 = arith.constant 32 : i32
  %c31_i32 = arith.constant 31 : i32
  %cst_1 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %5 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %7 = arith.addi %6, %3 : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %8 = arith.muli %1, %c32_i32 : i32
  %9 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %10 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %11 = arith.addi %9, %4 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %12 = arith.addi %10, %5 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %13 = tt.expand_dims %7 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %14 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %15 = arith.muli %13, %14 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %16 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.broadcast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %18 = tt.broadcast %16 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = arith.addi %17, %18 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %20 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %22 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %23 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %24 = arith.muli %22, %23 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %11 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %26 = tt.broadcast %24 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = tt.broadcast %25 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = arith.addi %26, %27 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %32 = tt.addptr %31, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %33 = arith.addi %arg8, %c31_i32 : i32
  %34 = arith.divsi %33, %c32_i32 : i32
  %35 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = arith.cmpi slt, %13, %35 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = tt.broadcast %36 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %38 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = arith.cmpi slt, %25, %38 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.broadcast %39 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %41 = arith.muli %arg10, %c32_i32 : i32
  %42 = tt.splat %41 : i32 -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %43 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %44 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %45 = arith.muli %c1_i32, %c0_i32 : i32
  %46 = arith.addi %c0_i32, %45 : i32
  %47 = arith.cmpi slt, %46, %34 : i32
  %48 = arith.muli %c1_i32, %c0_i32 : i32
  %49 = arith.addi %c0_i32, %48 : i32
  %50 = arith.addi %c-1_i32, %c1_i32 : i32
  %51 = arith.cmpi slt, %50, %c2_i32 : i32
  %52 = arith.select %51, %50, %c0_i32 : i32
  %53 = arith.muli %49, %c32_i32 : i32
  %54 = arith.subi %arg8, %53 : i32
  %55 = tt.splat %54 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = arith.cmpi slt, %16, %55 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = tt.broadcast %56 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %58 = arith.andi %37, %57 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = triton_gpu.memdesc_subview %43[%52, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %60 = tt.splat %47 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %61 = arith.andi %60, %58 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = triton_gpu.async_copy_global_to_local %21, %59 mask %61 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %63 = triton_gpu.async_commit_group %62
  %64 = tt.splat %54 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = arith.cmpi slt, %22, %64 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %66 = tt.broadcast %65 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = arith.andi %66, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %68 = triton_gpu.memdesc_subview %44[%52, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %69 = tt.splat %47 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = arith.andi %69, %67 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = triton_gpu.async_copy_global_to_local %30, %68 mask %70 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %72 = triton_gpu.async_commit_group %71
  %73 = arith.muli %c1_i32, %c1_i32 : i32
  %74 = arith.addi %c0_i32, %73 : i32
  %75 = arith.cmpi slt, %74, %34 : i32
  %76 = arith.muli %c1_i32, %c1_i32 : i32
  %77 = arith.addi %76, %c0_i32 : i32
  %78 = tt.addptr %21, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = tt.addptr %30, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %80 = arith.addi %52, %c1_i32 : i32
  %81 = arith.cmpi slt, %80, %c2_i32 : i32
  %82 = arith.select %81, %80, %c0_i32 : i32
  %83 = arith.muli %77, %c32_i32 : i32
  %84 = arith.subi %arg8, %83 : i32
  %85 = tt.splat %84 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = arith.cmpi slt, %16, %85 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %87 = tt.broadcast %86 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = arith.andi %37, %87 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %89 = triton_gpu.memdesc_subview %43[%82, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %90 = tt.splat %75 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %91 = arith.andi %90, %88 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %92 = triton_gpu.async_copy_global_to_local %78, %89 mask %91 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %93 = triton_gpu.async_commit_group %92
  %94 = tt.splat %84 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %95 = arith.cmpi slt, %22, %94 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %96 = tt.broadcast %95 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %97 = arith.andi %96, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %98 = triton_gpu.memdesc_subview %44[%82, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %99 = tt.splat %75 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %100 = arith.andi %99, %97 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %101 = triton_gpu.async_copy_global_to_local %79, %98 mask %100 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %102 = triton_gpu.async_commit_group %101
  %103 = arith.addi %c-1_i32, %c1_i32 : i32
  %104 = arith.cmpi slt, %103, %c2_i32 : i32
  %105 = arith.select %104, %103, %c0_i32 : i32
  %106 = triton_gpu.memdesc_subview %43[%105, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %107 = triton_gpu.async_wait %72 {num = 2 : i32}
  %108 = triton_gpu.memdesc_subview %44[%105, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %109:11 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %78, %arg15 = %79, %arg16 = %82, %arg17 = %105, %arg18 = %106, %arg19 = %107, %arg20 = %108, %arg21 = %107, %arg22 = %93, %arg23 = %102) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token)  : i32 {
    %c2_i32_3 = arith.constant 2 : i32
    %133 = arith.subi %34, %c2_i32_3 : i32
    %134 = arith.cmpi slt, %arg12, %133 : i32
    %135 = triton_gpu.local_load %arg18 token %arg19 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %136 = triton_gpu.local_load %arg20 token %arg21 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %137 = triton_gpu.convert_layout %135 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %138 = triton_gpu.convert_layout %136 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %139 = tt.dot %137, %138, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %140 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %141 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %142 = arith.addi %arg16, %c1_i32 : i32
    %143 = arith.cmpi slt, %142, %c2_i32 : i32
    %144 = arith.select %143, %142, %c0_i32 : i32
    %c2_i32_4 = arith.constant 2 : i32
    %145 = arith.addi %arg12, %c2_i32_4 : i32
    %146 = arith.muli %145, %c32_i32 : i32
    %147 = arith.subi %arg8, %146 : i32
    %148 = tt.splat %147 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = arith.cmpi slt, %16, %148 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %150 = tt.broadcast %149 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %151 = arith.andi %37, %150 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %152 = triton_gpu.memdesc_subview %43[%144, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %153 = tt.splat %134 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %154 = arith.andi %153, %151 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %155 = triton_gpu.async_copy_global_to_local %140, %152 mask %154 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %156 = triton_gpu.async_commit_group %155
    %157 = tt.splat %147 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %158 = arith.cmpi slt, %22, %157 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %159 = tt.broadcast %158 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %160 = arith.andi %159, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %161 = triton_gpu.memdesc_subview %44[%144, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %162 = tt.splat %134 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %163 = arith.andi %162, %160 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %164 = triton_gpu.async_copy_global_to_local %141, %161 mask %163 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %165 = triton_gpu.async_commit_group %164
    %166 = arith.addi %arg17, %c1_i32 : i32
    %167 = arith.cmpi slt, %166, %c2_i32 : i32
    %168 = arith.select %167, %166, %c0_i32 : i32
    %169 = triton_gpu.memdesc_subview %43[%168, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %170 = triton_gpu.async_wait %arg23 {num = 2 : i32}
    %171 = triton_gpu.memdesc_subview %44[%168, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    scf.yield %139, %140, %141, %144, %168, %169, %170, %171, %170, %156, %165 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token
  }
  %110 = triton_gpu.async_wait  {num = 0 : i32}
  triton_gpu.local_dealloc %43 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  triton_gpu.local_dealloc %44 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %111 = tt.splat %arg7 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %112 = arith.cmpi slt, %12, %111 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %113 = tt.load %32, %112, %cst_2 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %114 = arith.sitofp %arg4 : i32 to f32
  %115 = tt.splat %114 : f32 -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %116 = arith.mulf %109#0, %115 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %117 = arith.sitofp %arg5 : i32 to f16
  %118 = tt.splat %117 : f16 -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %119 = arith.mulf %113, %118 : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %120 = tt.expand_dims %119 {axis = 0 : i32} : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>> -> tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %121 = arith.extf %120 : tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %122 = tt.broadcast %121 : tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %123 = arith.addf %116, %122 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %124 = arith.truncf %123 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %125 = tt.splat %arg11 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %126 = arith.muli %125, %13 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %127 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %128 = tt.addptr %127, %126 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %129 = tt.broadcast %128 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %130 = tt.addptr %129, %27 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %131 = arith.andi %37, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %132 = triton_gpu.convert_layout %124 : tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.store %130, %132, %131 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.return
}



//===-------------------------------------------===//
Processing operation : 'arith.addi'(0x55bafa423f20) {
  %87 = "arith.addi"(%86, %3) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> success : operation was folded
//===-------------------------------------------===//
** Replace : 'arith.addi'(0x55bafa423f20)
** Modified: 'arith.muli'(0x55bafa424360)
** Erase   : 'arith.addi'(0x55bafa423f20)
// *** IR Dump After Successful Folding ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c2_i32 = arith.constant 2 : i32
  %c-1_i32 = arith.constant -1 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %c32_i32 = arith.constant 32 : i32
  %c31_i32 = arith.constant 31 : i32
  %cst_1 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %5 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %7 = arith.addi %6, %3 : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %8 = arith.muli %1, %c32_i32 : i32
  %9 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %10 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %11 = arith.addi %9, %4 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %12 = arith.addi %10, %5 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %13 = tt.expand_dims %7 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %14 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %15 = arith.muli %13, %14 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %16 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.broadcast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %18 = tt.broadcast %16 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = arith.addi %17, %18 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %20 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %22 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %23 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %24 = arith.muli %22, %23 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %11 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %26 = tt.broadcast %24 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = tt.broadcast %25 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = arith.addi %26, %27 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %32 = tt.addptr %31, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %33 = arith.addi %arg8, %c31_i32 : i32
  %34 = arith.divsi %33, %c32_i32 : i32
  %35 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = arith.cmpi slt, %13, %35 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = tt.broadcast %36 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %38 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = arith.cmpi slt, %25, %38 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.broadcast %39 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %41 = arith.muli %arg10, %c32_i32 : i32
  %42 = tt.splat %41 : i32 -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %43 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %44 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %45 = arith.muli %c1_i32, %c0_i32 : i32
  %46 = arith.addi %c0_i32, %45 : i32
  %47 = arith.cmpi slt, %46, %34 : i32
  %48 = arith.muli %c1_i32, %c0_i32 : i32
  %49 = arith.addi %c0_i32, %48 : i32
  %50 = arith.addi %c-1_i32, %c1_i32 : i32
  %51 = arith.cmpi slt, %50, %c2_i32 : i32
  %52 = arith.select %51, %50, %c0_i32 : i32
  %53 = arith.muli %49, %c32_i32 : i32
  %54 = arith.subi %arg8, %53 : i32
  %55 = tt.splat %54 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = arith.cmpi slt, %16, %55 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = tt.broadcast %56 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %58 = arith.andi %37, %57 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = triton_gpu.memdesc_subview %43[%52, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %60 = tt.splat %47 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %61 = arith.andi %60, %58 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = triton_gpu.async_copy_global_to_local %21, %59 mask %61 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %63 = triton_gpu.async_commit_group %62
  %64 = tt.splat %54 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = arith.cmpi slt, %22, %64 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %66 = tt.broadcast %65 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = arith.andi %66, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %68 = triton_gpu.memdesc_subview %44[%52, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %69 = tt.splat %47 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = arith.andi %69, %67 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = triton_gpu.async_copy_global_to_local %30, %68 mask %70 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %72 = triton_gpu.async_commit_group %71
  %73 = arith.muli %c1_i32, %c1_i32 : i32
  %74 = arith.addi %c0_i32, %73 : i32
  %75 = arith.cmpi slt, %74, %34 : i32
  %76 = arith.muli %c1_i32, %c1_i32 : i32
  %77 = tt.addptr %21, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = tt.addptr %30, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = arith.addi %52, %c1_i32 : i32
  %80 = arith.cmpi slt, %79, %c2_i32 : i32
  %81 = arith.select %80, %79, %c0_i32 : i32
  %82 = arith.muli %76, %c32_i32 : i32
  %83 = arith.subi %arg8, %82 : i32
  %84 = tt.splat %83 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %85 = arith.cmpi slt, %16, %84 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = tt.broadcast %85 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %87 = arith.andi %37, %86 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = triton_gpu.memdesc_subview %43[%81, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %89 = tt.splat %75 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = arith.andi %89, %87 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %91 = triton_gpu.async_copy_global_to_local %77, %88 mask %90 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %92 = triton_gpu.async_commit_group %91
  %93 = tt.splat %83 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %94 = arith.cmpi slt, %22, %93 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %95 = tt.broadcast %94 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %96 = arith.andi %95, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %97 = triton_gpu.memdesc_subview %44[%81, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %98 = tt.splat %75 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %99 = arith.andi %98, %96 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %100 = triton_gpu.async_copy_global_to_local %78, %97 mask %99 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %101 = triton_gpu.async_commit_group %100
  %102 = arith.addi %c-1_i32, %c1_i32 : i32
  %103 = arith.cmpi slt, %102, %c2_i32 : i32
  %104 = arith.select %103, %102, %c0_i32 : i32
  %105 = triton_gpu.memdesc_subview %43[%104, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %106 = triton_gpu.async_wait %72 {num = 2 : i32}
  %107 = triton_gpu.memdesc_subview %44[%104, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %108:11 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %77, %arg15 = %78, %arg16 = %81, %arg17 = %104, %arg18 = %105, %arg19 = %106, %arg20 = %107, %arg21 = %106, %arg22 = %92, %arg23 = %101) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token)  : i32 {
    %c2_i32_3 = arith.constant 2 : i32
    %132 = arith.subi %34, %c2_i32_3 : i32
    %133 = arith.cmpi slt, %arg12, %132 : i32
    %134 = triton_gpu.local_load %arg18 token %arg19 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %135 = triton_gpu.local_load %arg20 token %arg21 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %136 = triton_gpu.convert_layout %134 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %137 = triton_gpu.convert_layout %135 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %138 = tt.dot %136, %137, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %139 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %140 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %141 = arith.addi %arg16, %c1_i32 : i32
    %142 = arith.cmpi slt, %141, %c2_i32 : i32
    %143 = arith.select %142, %141, %c0_i32 : i32
    %c2_i32_4 = arith.constant 2 : i32
    %144 = arith.addi %arg12, %c2_i32_4 : i32
    %145 = arith.muli %144, %c32_i32 : i32
    %146 = arith.subi %arg8, %145 : i32
    %147 = tt.splat %146 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %148 = arith.cmpi slt, %16, %147 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = tt.broadcast %148 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %150 = arith.andi %37, %149 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %151 = triton_gpu.memdesc_subview %43[%143, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %152 = tt.splat %133 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %153 = arith.andi %152, %150 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %154 = triton_gpu.async_copy_global_to_local %139, %151 mask %153 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %155 = triton_gpu.async_commit_group %154
    %156 = tt.splat %146 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %157 = arith.cmpi slt, %22, %156 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %158 = tt.broadcast %157 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %159 = arith.andi %158, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %160 = triton_gpu.memdesc_subview %44[%143, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %161 = tt.splat %133 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %162 = arith.andi %161, %159 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %163 = triton_gpu.async_copy_global_to_local %140, %160 mask %162 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %164 = triton_gpu.async_commit_group %163
    %165 = arith.addi %arg17, %c1_i32 : i32
    %166 = arith.cmpi slt, %165, %c2_i32 : i32
    %167 = arith.select %166, %165, %c0_i32 : i32
    %168 = triton_gpu.memdesc_subview %43[%167, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %169 = triton_gpu.async_wait %arg23 {num = 2 : i32}
    %170 = triton_gpu.memdesc_subview %44[%167, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    scf.yield %138, %139, %140, %143, %167, %168, %169, %170, %169, %155, %164 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token
  }
  %109 = triton_gpu.async_wait  {num = 0 : i32}
  triton_gpu.local_dealloc %43 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  triton_gpu.local_dealloc %44 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %110 = tt.splat %arg7 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %111 = arith.cmpi slt, %12, %110 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %112 = tt.load %32, %111, %cst_2 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %113 = arith.sitofp %arg4 : i32 to f32
  %114 = tt.splat %113 : f32 -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %115 = arith.mulf %108#0, %114 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %116 = arith.sitofp %arg5 : i32 to f16
  %117 = tt.splat %116 : f16 -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %118 = arith.mulf %112, %117 : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %119 = tt.expand_dims %118 {axis = 0 : i32} : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>> -> tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %120 = arith.extf %119 : tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %121 = tt.broadcast %120 : tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %122 = arith.addf %115, %121 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %123 = arith.truncf %122 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %124 = tt.splat %arg11 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %125 = arith.muli %124, %13 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %126 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %127 = tt.addptr %126, %125 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %128 = tt.broadcast %127 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %129 = tt.addptr %128, %27 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %130 = arith.andi %37, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %131 = triton_gpu.convert_layout %123 : tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.store %129, %131, %130 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.return
}



//===-------------------------------------------===//
Processing operation : 'arith.muli'(0x55bafa424360) {
  %92 = "arith.muli"(%86, %6) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.muli'(0x55bafa423e70) {
  %86 = "arith.muli"(%4, %4) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> success : operation was folded
//===-------------------------------------------===//
** Replace : 'arith.muli'(0x55bafa423e70)
** Modified: 'arith.muli'(0x55bafa424360)
** Erase   : 'arith.muli'(0x55bafa423e70)
// *** IR Dump After Successful Folding ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c2_i32 = arith.constant 2 : i32
  %c-1_i32 = arith.constant -1 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %c32_i32 = arith.constant 32 : i32
  %c31_i32 = arith.constant 31 : i32
  %cst_1 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %5 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %7 = arith.addi %6, %3 : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %8 = arith.muli %1, %c32_i32 : i32
  %9 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %10 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %11 = arith.addi %9, %4 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %12 = arith.addi %10, %5 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %13 = tt.expand_dims %7 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %14 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %15 = arith.muli %13, %14 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %16 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.broadcast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %18 = tt.broadcast %16 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = arith.addi %17, %18 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %20 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %22 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %23 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %24 = arith.muli %22, %23 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %11 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %26 = tt.broadcast %24 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = tt.broadcast %25 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = arith.addi %26, %27 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %32 = tt.addptr %31, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %33 = arith.addi %arg8, %c31_i32 : i32
  %34 = arith.divsi %33, %c32_i32 : i32
  %35 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = arith.cmpi slt, %13, %35 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = tt.broadcast %36 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %38 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = arith.cmpi slt, %25, %38 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.broadcast %39 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %41 = arith.muli %arg10, %c32_i32 : i32
  %42 = tt.splat %41 : i32 -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %43 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %44 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %45 = arith.muli %c1_i32, %c0_i32 : i32
  %46 = arith.addi %c0_i32, %45 : i32
  %47 = arith.cmpi slt, %46, %34 : i32
  %48 = arith.muli %c1_i32, %c0_i32 : i32
  %49 = arith.addi %c0_i32, %48 : i32
  %50 = arith.addi %c-1_i32, %c1_i32 : i32
  %51 = arith.cmpi slt, %50, %c2_i32 : i32
  %52 = arith.select %51, %50, %c0_i32 : i32
  %53 = arith.muli %49, %c32_i32 : i32
  %54 = arith.subi %arg8, %53 : i32
  %55 = tt.splat %54 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = arith.cmpi slt, %16, %55 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = tt.broadcast %56 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %58 = arith.andi %37, %57 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = triton_gpu.memdesc_subview %43[%52, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %60 = tt.splat %47 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %61 = arith.andi %60, %58 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = triton_gpu.async_copy_global_to_local %21, %59 mask %61 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %63 = triton_gpu.async_commit_group %62
  %64 = tt.splat %54 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = arith.cmpi slt, %22, %64 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %66 = tt.broadcast %65 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = arith.andi %66, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %68 = triton_gpu.memdesc_subview %44[%52, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %69 = tt.splat %47 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = arith.andi %69, %67 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = triton_gpu.async_copy_global_to_local %30, %68 mask %70 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %72 = triton_gpu.async_commit_group %71
  %73 = arith.muli %c1_i32, %c1_i32 : i32
  %74 = arith.addi %c0_i32, %73 : i32
  %75 = arith.cmpi slt, %74, %34 : i32
  %76 = tt.addptr %21, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %77 = tt.addptr %30, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = arith.addi %52, %c1_i32 : i32
  %79 = arith.cmpi slt, %78, %c2_i32 : i32
  %80 = arith.select %79, %78, %c0_i32 : i32
  %81 = arith.muli %c1_i32, %c32_i32 : i32
  %82 = arith.subi %arg8, %81 : i32
  %83 = tt.splat %82 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = arith.cmpi slt, %16, %83 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %85 = tt.broadcast %84 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = arith.andi %37, %85 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %87 = triton_gpu.memdesc_subview %43[%80, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %88 = tt.splat %75 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %89 = arith.andi %88, %86 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = triton_gpu.async_copy_global_to_local %76, %87 mask %89 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %91 = triton_gpu.async_commit_group %90
  %92 = tt.splat %82 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = arith.cmpi slt, %22, %92 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %94 = tt.broadcast %93 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %95 = arith.andi %94, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %96 = triton_gpu.memdesc_subview %44[%80, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %97 = tt.splat %75 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %98 = arith.andi %97, %95 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %99 = triton_gpu.async_copy_global_to_local %77, %96 mask %98 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %100 = triton_gpu.async_commit_group %99
  %101 = arith.addi %c-1_i32, %c1_i32 : i32
  %102 = arith.cmpi slt, %101, %c2_i32 : i32
  %103 = arith.select %102, %101, %c0_i32 : i32
  %104 = triton_gpu.memdesc_subview %43[%103, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %105 = triton_gpu.async_wait %72 {num = 2 : i32}
  %106 = triton_gpu.memdesc_subview %44[%103, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %107:11 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %76, %arg15 = %77, %arg16 = %80, %arg17 = %103, %arg18 = %104, %arg19 = %105, %arg20 = %106, %arg21 = %105, %arg22 = %91, %arg23 = %100) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token)  : i32 {
    %c2_i32_3 = arith.constant 2 : i32
    %131 = arith.subi %34, %c2_i32_3 : i32
    %132 = arith.cmpi slt, %arg12, %131 : i32
    %133 = triton_gpu.local_load %arg18 token %arg19 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %134 = triton_gpu.local_load %arg20 token %arg21 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %135 = triton_gpu.convert_layout %133 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %136 = triton_gpu.convert_layout %134 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %137 = tt.dot %135, %136, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %138 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %139 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %140 = arith.addi %arg16, %c1_i32 : i32
    %141 = arith.cmpi slt, %140, %c2_i32 : i32
    %142 = arith.select %141, %140, %c0_i32 : i32
    %c2_i32_4 = arith.constant 2 : i32
    %143 = arith.addi %arg12, %c2_i32_4 : i32
    %144 = arith.muli %143, %c32_i32 : i32
    %145 = arith.subi %arg8, %144 : i32
    %146 = tt.splat %145 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %147 = arith.cmpi slt, %16, %146 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %148 = tt.broadcast %147 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = arith.andi %37, %148 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %150 = triton_gpu.memdesc_subview %43[%142, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %151 = tt.splat %132 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %152 = arith.andi %151, %149 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %153 = triton_gpu.async_copy_global_to_local %138, %150 mask %152 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %154 = triton_gpu.async_commit_group %153
    %155 = tt.splat %145 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %156 = arith.cmpi slt, %22, %155 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %157 = tt.broadcast %156 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %158 = arith.andi %157, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %159 = triton_gpu.memdesc_subview %44[%142, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %160 = tt.splat %132 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %161 = arith.andi %160, %158 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %162 = triton_gpu.async_copy_global_to_local %139, %159 mask %161 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %163 = triton_gpu.async_commit_group %162
    %164 = arith.addi %arg17, %c1_i32 : i32
    %165 = arith.cmpi slt, %164, %c2_i32 : i32
    %166 = arith.select %165, %164, %c0_i32 : i32
    %167 = triton_gpu.memdesc_subview %43[%166, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %168 = triton_gpu.async_wait %arg23 {num = 2 : i32}
    %169 = triton_gpu.memdesc_subview %44[%166, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    scf.yield %137, %138, %139, %142, %166, %167, %168, %169, %168, %154, %163 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token
  }
  %108 = triton_gpu.async_wait  {num = 0 : i32}
  triton_gpu.local_dealloc %43 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  triton_gpu.local_dealloc %44 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %109 = tt.splat %arg7 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %110 = arith.cmpi slt, %12, %109 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %111 = tt.load %32, %110, %cst_2 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %112 = arith.sitofp %arg4 : i32 to f32
  %113 = tt.splat %112 : f32 -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %114 = arith.mulf %107#0, %113 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %115 = arith.sitofp %arg5 : i32 to f16
  %116 = tt.splat %115 : f16 -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %117 = arith.mulf %111, %116 : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %118 = tt.expand_dims %117 {axis = 0 : i32} : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>> -> tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %119 = arith.extf %118 : tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %120 = tt.broadcast %119 : tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %121 = arith.addf %114, %120 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %122 = arith.truncf %121 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %123 = tt.splat %arg11 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %124 = arith.muli %123, %13 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %125 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %126 = tt.addptr %125, %124 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %127 = tt.broadcast %126 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %128 = tt.addptr %127, %27 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %129 = arith.andi %37, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %130 = triton_gpu.convert_layout %122 : tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.store %128, %130, %129 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.return
}



//===-------------------------------------------===//
Processing operation : 'arith.muli'(0x55bafa424360) {
  %91 = "arith.muli"(%4, %6) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> success : operation was folded
//===-------------------------------------------===//
** Insert  : 'arith.constant'(0x55bafa430680)
** Replace : 'arith.muli'(0x55bafa424360)
** Modified: 'arith.subi'(0x55bafa424410)
** Erase   : 'arith.muli'(0x55bafa424360)
// *** IR Dump After Successful Folding ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c2_i32 = arith.constant 2 : i32
  %c-1_i32 = arith.constant -1 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %c32_i32 = arith.constant 32 : i32
  %c31_i32 = arith.constant 31 : i32
  %cst_1 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %5 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %7 = arith.addi %6, %3 : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %8 = arith.muli %1, %c32_i32 : i32
  %9 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %10 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %11 = arith.addi %9, %4 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %12 = arith.addi %10, %5 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %13 = tt.expand_dims %7 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %14 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %15 = arith.muli %13, %14 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %16 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.broadcast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %18 = tt.broadcast %16 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = arith.addi %17, %18 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %20 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %22 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %23 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %24 = arith.muli %22, %23 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %11 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %26 = tt.broadcast %24 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = tt.broadcast %25 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = arith.addi %26, %27 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %32 = tt.addptr %31, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %33 = arith.addi %arg8, %c31_i32 : i32
  %34 = arith.divsi %33, %c32_i32 : i32
  %35 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = arith.cmpi slt, %13, %35 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = tt.broadcast %36 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %38 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = arith.cmpi slt, %25, %38 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.broadcast %39 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %41 = arith.muli %arg10, %c32_i32 : i32
  %42 = tt.splat %41 : i32 -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %43 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %44 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %45 = arith.muli %c1_i32, %c0_i32 : i32
  %46 = arith.addi %c0_i32, %45 : i32
  %47 = arith.cmpi slt, %46, %34 : i32
  %48 = arith.muli %c1_i32, %c0_i32 : i32
  %49 = arith.addi %c0_i32, %48 : i32
  %50 = arith.addi %c-1_i32, %c1_i32 : i32
  %51 = arith.cmpi slt, %50, %c2_i32 : i32
  %52 = arith.select %51, %50, %c0_i32 : i32
  %53 = arith.muli %49, %c32_i32 : i32
  %54 = arith.subi %arg8, %53 : i32
  %55 = tt.splat %54 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = arith.cmpi slt, %16, %55 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = tt.broadcast %56 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %58 = arith.andi %37, %57 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = triton_gpu.memdesc_subview %43[%52, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %60 = tt.splat %47 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %61 = arith.andi %60, %58 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = triton_gpu.async_copy_global_to_local %21, %59 mask %61 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %63 = triton_gpu.async_commit_group %62
  %64 = tt.splat %54 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = arith.cmpi slt, %22, %64 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %66 = tt.broadcast %65 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = arith.andi %66, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %68 = triton_gpu.memdesc_subview %44[%52, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %69 = tt.splat %47 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = arith.andi %69, %67 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = triton_gpu.async_copy_global_to_local %30, %68 mask %70 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %72 = triton_gpu.async_commit_group %71
  %73 = arith.muli %c1_i32, %c1_i32 : i32
  %74 = arith.addi %c0_i32, %73 : i32
  %75 = arith.cmpi slt, %74, %34 : i32
  %76 = tt.addptr %21, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %77 = tt.addptr %30, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = arith.addi %52, %c1_i32 : i32
  %79 = arith.cmpi slt, %78, %c2_i32 : i32
  %80 = arith.select %79, %78, %c0_i32 : i32
  %c32_i32_3 = arith.constant 32 : i32
  %81 = arith.subi %arg8, %c32_i32_3 : i32
  %82 = tt.splat %81 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = arith.cmpi slt, %16, %82 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = tt.broadcast %83 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %85 = arith.andi %37, %84 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = triton_gpu.memdesc_subview %43[%80, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %87 = tt.splat %75 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = arith.andi %87, %85 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %89 = triton_gpu.async_copy_global_to_local %76, %86 mask %88 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %90 = triton_gpu.async_commit_group %89
  %91 = tt.splat %81 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %92 = arith.cmpi slt, %22, %91 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = tt.broadcast %92 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %94 = arith.andi %93, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %95 = triton_gpu.memdesc_subview %44[%80, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %96 = tt.splat %75 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %97 = arith.andi %96, %94 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %98 = triton_gpu.async_copy_global_to_local %77, %95 mask %97 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %99 = triton_gpu.async_commit_group %98
  %100 = arith.addi %c-1_i32, %c1_i32 : i32
  %101 = arith.cmpi slt, %100, %c2_i32 : i32
  %102 = arith.select %101, %100, %c0_i32 : i32
  %103 = triton_gpu.memdesc_subview %43[%102, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %104 = triton_gpu.async_wait %72 {num = 2 : i32}
  %105 = triton_gpu.memdesc_subview %44[%102, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %106:11 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %76, %arg15 = %77, %arg16 = %80, %arg17 = %102, %arg18 = %103, %arg19 = %104, %arg20 = %105, %arg21 = %104, %arg22 = %90, %arg23 = %99) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token)  : i32 {
    %c2_i32_4 = arith.constant 2 : i32
    %130 = arith.subi %34, %c2_i32_4 : i32
    %131 = arith.cmpi slt, %arg12, %130 : i32
    %132 = triton_gpu.local_load %arg18 token %arg19 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %133 = triton_gpu.local_load %arg20 token %arg21 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %134 = triton_gpu.convert_layout %132 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %135 = triton_gpu.convert_layout %133 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %136 = tt.dot %134, %135, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %137 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %138 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %139 = arith.addi %arg16, %c1_i32 : i32
    %140 = arith.cmpi slt, %139, %c2_i32 : i32
    %141 = arith.select %140, %139, %c0_i32 : i32
    %c2_i32_5 = arith.constant 2 : i32
    %142 = arith.addi %arg12, %c2_i32_5 : i32
    %143 = arith.muli %142, %c32_i32 : i32
    %144 = arith.subi %arg8, %143 : i32
    %145 = tt.splat %144 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %146 = arith.cmpi slt, %16, %145 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %147 = tt.broadcast %146 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %148 = arith.andi %37, %147 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = triton_gpu.memdesc_subview %43[%141, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %150 = tt.splat %131 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %151 = arith.andi %150, %148 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %152 = triton_gpu.async_copy_global_to_local %137, %149 mask %151 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %153 = triton_gpu.async_commit_group %152
    %154 = tt.splat %144 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %155 = arith.cmpi slt, %22, %154 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %156 = tt.broadcast %155 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %157 = arith.andi %156, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %158 = triton_gpu.memdesc_subview %44[%141, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %159 = tt.splat %131 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %160 = arith.andi %159, %157 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %161 = triton_gpu.async_copy_global_to_local %138, %158 mask %160 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %162 = triton_gpu.async_commit_group %161
    %163 = arith.addi %arg17, %c1_i32 : i32
    %164 = arith.cmpi slt, %163, %c2_i32 : i32
    %165 = arith.select %164, %163, %c0_i32 : i32
    %166 = triton_gpu.memdesc_subview %43[%165, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %167 = triton_gpu.async_wait %arg23 {num = 2 : i32}
    %168 = triton_gpu.memdesc_subview %44[%165, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    scf.yield %136, %137, %138, %141, %165, %166, %167, %168, %167, %153, %162 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token
  }
  %107 = triton_gpu.async_wait  {num = 0 : i32}
  triton_gpu.local_dealloc %43 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  triton_gpu.local_dealloc %44 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %108 = tt.splat %arg7 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %109 = arith.cmpi slt, %12, %108 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %110 = tt.load %32, %109, %cst_2 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %111 = arith.sitofp %arg4 : i32 to f32
  %112 = tt.splat %111 : f32 -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %113 = arith.mulf %106#0, %112 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %114 = arith.sitofp %arg5 : i32 to f16
  %115 = tt.splat %114 : f16 -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %116 = arith.mulf %110, %115 : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %117 = tt.expand_dims %116 {axis = 0 : i32} : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>> -> tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %118 = arith.extf %117 : tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %119 = tt.broadcast %118 : tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %120 = arith.addf %113, %119 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %121 = arith.truncf %120 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %122 = tt.splat %arg11 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %123 = arith.muli %122, %13 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %124 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %125 = tt.addptr %124, %123 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %126 = tt.broadcast %125 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %127 = tt.addptr %126, %27 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %128 = arith.andi %37, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %129 = triton_gpu.convert_layout %121 : tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.store %127, %129, %128 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.return
}



//===-------------------------------------------===//
Processing operation : 'arith.subi'(0x55bafa424410) {
  %92 = "arith.subi"(%arg8, %91) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.constant'(0x55bafa430680) {
  %91 = "arith.constant"() <{value = 32 : i32}> : () -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa423d50) {
  %85 = "arith.cmpi"(%84, %44) <{predicate = 2 : i64}> : (i32, i32) -> i1

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.addi'(0x55bafa423ca0) {
  %84 = "arith.addi"(%3, %83) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> success : operation was folded
//===-------------------------------------------===//
** Modified: 'arith.addi'(0x55bafa423ca0)
// *** IR Dump After Successful Folding ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c2_i32 = arith.constant 2 : i32
  %c-1_i32 = arith.constant -1 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %c32_i32 = arith.constant 32 : i32
  %c31_i32 = arith.constant 31 : i32
  %cst_1 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %5 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %7 = arith.addi %6, %3 : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %8 = arith.muli %1, %c32_i32 : i32
  %9 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %10 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %11 = arith.addi %9, %4 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %12 = arith.addi %10, %5 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %13 = tt.expand_dims %7 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %14 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %15 = arith.muli %13, %14 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %16 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.broadcast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %18 = tt.broadcast %16 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = arith.addi %17, %18 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %20 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %22 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %23 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %24 = arith.muli %22, %23 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %11 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %26 = tt.broadcast %24 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = tt.broadcast %25 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = arith.addi %26, %27 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %32 = tt.addptr %31, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %33 = arith.addi %arg8, %c31_i32 : i32
  %34 = arith.divsi %33, %c32_i32 : i32
  %35 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = arith.cmpi slt, %13, %35 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = tt.broadcast %36 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %38 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = arith.cmpi slt, %25, %38 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.broadcast %39 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %41 = arith.muli %arg10, %c32_i32 : i32
  %42 = tt.splat %41 : i32 -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %43 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %44 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %45 = arith.muli %c1_i32, %c0_i32 : i32
  %46 = arith.addi %c0_i32, %45 : i32
  %47 = arith.cmpi slt, %46, %34 : i32
  %48 = arith.muli %c1_i32, %c0_i32 : i32
  %49 = arith.addi %c0_i32, %48 : i32
  %50 = arith.addi %c-1_i32, %c1_i32 : i32
  %51 = arith.cmpi slt, %50, %c2_i32 : i32
  %52 = arith.select %51, %50, %c0_i32 : i32
  %53 = arith.muli %49, %c32_i32 : i32
  %54 = arith.subi %arg8, %53 : i32
  %55 = tt.splat %54 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = arith.cmpi slt, %16, %55 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = tt.broadcast %56 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %58 = arith.andi %37, %57 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = triton_gpu.memdesc_subview %43[%52, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %60 = tt.splat %47 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %61 = arith.andi %60, %58 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = triton_gpu.async_copy_global_to_local %21, %59 mask %61 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %63 = triton_gpu.async_commit_group %62
  %64 = tt.splat %54 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = arith.cmpi slt, %22, %64 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %66 = tt.broadcast %65 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = arith.andi %66, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %68 = triton_gpu.memdesc_subview %44[%52, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %69 = tt.splat %47 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = arith.andi %69, %67 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = triton_gpu.async_copy_global_to_local %30, %68 mask %70 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %72 = triton_gpu.async_commit_group %71
  %73 = arith.muli %c1_i32, %c1_i32 : i32
  %74 = arith.addi %73, %c0_i32 : i32
  %75 = arith.cmpi slt, %74, %34 : i32
  %76 = tt.addptr %21, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %77 = tt.addptr %30, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = arith.addi %52, %c1_i32 : i32
  %79 = arith.cmpi slt, %78, %c2_i32 : i32
  %80 = arith.select %79, %78, %c0_i32 : i32
  %c32_i32_3 = arith.constant 32 : i32
  %81 = arith.subi %arg8, %c32_i32_3 : i32
  %82 = tt.splat %81 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = arith.cmpi slt, %16, %82 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = tt.broadcast %83 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %85 = arith.andi %37, %84 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = triton_gpu.memdesc_subview %43[%80, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %87 = tt.splat %75 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = arith.andi %87, %85 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %89 = triton_gpu.async_copy_global_to_local %76, %86 mask %88 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %90 = triton_gpu.async_commit_group %89
  %91 = tt.splat %81 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %92 = arith.cmpi slt, %22, %91 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = tt.broadcast %92 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %94 = arith.andi %93, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %95 = triton_gpu.memdesc_subview %44[%80, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %96 = tt.splat %75 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %97 = arith.andi %96, %94 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %98 = triton_gpu.async_copy_global_to_local %77, %95 mask %97 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %99 = triton_gpu.async_commit_group %98
  %100 = arith.addi %c-1_i32, %c1_i32 : i32
  %101 = arith.cmpi slt, %100, %c2_i32 : i32
  %102 = arith.select %101, %100, %c0_i32 : i32
  %103 = triton_gpu.memdesc_subview %43[%102, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %104 = triton_gpu.async_wait %72 {num = 2 : i32}
  %105 = triton_gpu.memdesc_subview %44[%102, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %106:11 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %76, %arg15 = %77, %arg16 = %80, %arg17 = %102, %arg18 = %103, %arg19 = %104, %arg20 = %105, %arg21 = %104, %arg22 = %90, %arg23 = %99) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token)  : i32 {
    %c2_i32_4 = arith.constant 2 : i32
    %130 = arith.subi %34, %c2_i32_4 : i32
    %131 = arith.cmpi slt, %arg12, %130 : i32
    %132 = triton_gpu.local_load %arg18 token %arg19 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %133 = triton_gpu.local_load %arg20 token %arg21 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %134 = triton_gpu.convert_layout %132 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %135 = triton_gpu.convert_layout %133 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %136 = tt.dot %134, %135, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %137 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %138 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %139 = arith.addi %arg16, %c1_i32 : i32
    %140 = arith.cmpi slt, %139, %c2_i32 : i32
    %141 = arith.select %140, %139, %c0_i32 : i32
    %c2_i32_5 = arith.constant 2 : i32
    %142 = arith.addi %arg12, %c2_i32_5 : i32
    %143 = arith.muli %142, %c32_i32 : i32
    %144 = arith.subi %arg8, %143 : i32
    %145 = tt.splat %144 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %146 = arith.cmpi slt, %16, %145 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %147 = tt.broadcast %146 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %148 = arith.andi %37, %147 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = triton_gpu.memdesc_subview %43[%141, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %150 = tt.splat %131 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %151 = arith.andi %150, %148 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %152 = triton_gpu.async_copy_global_to_local %137, %149 mask %151 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %153 = triton_gpu.async_commit_group %152
    %154 = tt.splat %144 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %155 = arith.cmpi slt, %22, %154 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %156 = tt.broadcast %155 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %157 = arith.andi %156, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %158 = triton_gpu.memdesc_subview %44[%141, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %159 = tt.splat %131 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %160 = arith.andi %159, %157 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %161 = triton_gpu.async_copy_global_to_local %138, %158 mask %160 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %162 = triton_gpu.async_commit_group %161
    %163 = arith.addi %arg17, %c1_i32 : i32
    %164 = arith.cmpi slt, %163, %c2_i32 : i32
    %165 = arith.select %164, %163, %c0_i32 : i32
    %166 = triton_gpu.memdesc_subview %43[%165, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %167 = triton_gpu.async_wait %arg23 {num = 2 : i32}
    %168 = triton_gpu.memdesc_subview %44[%165, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    scf.yield %136, %137, %138, %141, %165, %166, %167, %168, %167, %153, %162 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token
  }
  %107 = triton_gpu.async_wait  {num = 0 : i32}
  triton_gpu.local_dealloc %43 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  triton_gpu.local_dealloc %44 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %108 = tt.splat %arg7 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %109 = arith.cmpi slt, %12, %108 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %110 = tt.load %32, %109, %cst_2 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %111 = arith.sitofp %arg4 : i32 to f32
  %112 = tt.splat %111 : f32 -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %113 = arith.mulf %106#0, %112 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %114 = arith.sitofp %arg5 : i32 to f16
  %115 = tt.splat %114 : f16 -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %116 = arith.mulf %110, %115 : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %117 = tt.expand_dims %116 {axis = 0 : i32} : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>> -> tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %118 = arith.extf %117 : tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %119 = tt.broadcast %118 : tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %120 = arith.addf %113, %119 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %121 = arith.truncf %120 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %122 = tt.splat %arg11 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %123 = arith.muli %122, %13 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %124 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %125 = tt.addptr %124, %123 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %126 = tt.broadcast %125 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %127 = tt.addptr %126, %27 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %128 = arith.andi %37, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %129 = triton_gpu.convert_layout %121 : tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.store %127, %129, %128 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.return
}



//===-------------------------------------------===//
Processing operation : 'arith.addi'(0x55bafa423ca0) {
  %84 = "arith.addi"(%83, %3) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> success : operation was folded
//===-------------------------------------------===//
** Replace : 'arith.addi'(0x55bafa423ca0)
** Modified: 'arith.cmpi'(0x55bafa423d50)
** Erase   : 'arith.addi'(0x55bafa423ca0)
// *** IR Dump After Successful Folding ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c2_i32 = arith.constant 2 : i32
  %c-1_i32 = arith.constant -1 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %c32_i32 = arith.constant 32 : i32
  %c31_i32 = arith.constant 31 : i32
  %cst_1 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %5 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %7 = arith.addi %6, %3 : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %8 = arith.muli %1, %c32_i32 : i32
  %9 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %10 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %11 = arith.addi %9, %4 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %12 = arith.addi %10, %5 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %13 = tt.expand_dims %7 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %14 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %15 = arith.muli %13, %14 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %16 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.broadcast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %18 = tt.broadcast %16 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = arith.addi %17, %18 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %20 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %22 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %23 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %24 = arith.muli %22, %23 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %11 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %26 = tt.broadcast %24 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = tt.broadcast %25 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = arith.addi %26, %27 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %32 = tt.addptr %31, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %33 = arith.addi %arg8, %c31_i32 : i32
  %34 = arith.divsi %33, %c32_i32 : i32
  %35 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = arith.cmpi slt, %13, %35 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = tt.broadcast %36 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %38 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = arith.cmpi slt, %25, %38 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.broadcast %39 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %41 = arith.muli %arg10, %c32_i32 : i32
  %42 = tt.splat %41 : i32 -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %43 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %44 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %45 = arith.muli %c1_i32, %c0_i32 : i32
  %46 = arith.addi %c0_i32, %45 : i32
  %47 = arith.cmpi slt, %46, %34 : i32
  %48 = arith.muli %c1_i32, %c0_i32 : i32
  %49 = arith.addi %c0_i32, %48 : i32
  %50 = arith.addi %c-1_i32, %c1_i32 : i32
  %51 = arith.cmpi slt, %50, %c2_i32 : i32
  %52 = arith.select %51, %50, %c0_i32 : i32
  %53 = arith.muli %49, %c32_i32 : i32
  %54 = arith.subi %arg8, %53 : i32
  %55 = tt.splat %54 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = arith.cmpi slt, %16, %55 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = tt.broadcast %56 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %58 = arith.andi %37, %57 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = triton_gpu.memdesc_subview %43[%52, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %60 = tt.splat %47 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %61 = arith.andi %60, %58 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = triton_gpu.async_copy_global_to_local %21, %59 mask %61 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %63 = triton_gpu.async_commit_group %62
  %64 = tt.splat %54 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = arith.cmpi slt, %22, %64 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %66 = tt.broadcast %65 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = arith.andi %66, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %68 = triton_gpu.memdesc_subview %44[%52, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %69 = tt.splat %47 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = arith.andi %69, %67 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = triton_gpu.async_copy_global_to_local %30, %68 mask %70 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %72 = triton_gpu.async_commit_group %71
  %73 = arith.muli %c1_i32, %c1_i32 : i32
  %74 = arith.cmpi slt, %73, %34 : i32
  %75 = tt.addptr %21, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %76 = tt.addptr %30, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %77 = arith.addi %52, %c1_i32 : i32
  %78 = arith.cmpi slt, %77, %c2_i32 : i32
  %79 = arith.select %78, %77, %c0_i32 : i32
  %c32_i32_3 = arith.constant 32 : i32
  %80 = arith.subi %arg8, %c32_i32_3 : i32
  %81 = tt.splat %80 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = arith.cmpi slt, %16, %81 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = tt.broadcast %82 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = arith.andi %37, %83 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %85 = triton_gpu.memdesc_subview %43[%79, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %86 = tt.splat %74 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %87 = arith.andi %86, %84 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = triton_gpu.async_copy_global_to_local %75, %85 mask %87 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %89 = triton_gpu.async_commit_group %88
  %90 = tt.splat %80 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %91 = arith.cmpi slt, %22, %90 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %92 = tt.broadcast %91 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = arith.andi %92, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %94 = triton_gpu.memdesc_subview %44[%79, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %95 = tt.splat %74 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %96 = arith.andi %95, %93 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %97 = triton_gpu.async_copy_global_to_local %76, %94 mask %96 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %98 = triton_gpu.async_commit_group %97
  %99 = arith.addi %c-1_i32, %c1_i32 : i32
  %100 = arith.cmpi slt, %99, %c2_i32 : i32
  %101 = arith.select %100, %99, %c0_i32 : i32
  %102 = triton_gpu.memdesc_subview %43[%101, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %103 = triton_gpu.async_wait %72 {num = 2 : i32}
  %104 = triton_gpu.memdesc_subview %44[%101, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %105:11 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %75, %arg15 = %76, %arg16 = %79, %arg17 = %101, %arg18 = %102, %arg19 = %103, %arg20 = %104, %arg21 = %103, %arg22 = %89, %arg23 = %98) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token)  : i32 {
    %c2_i32_4 = arith.constant 2 : i32
    %129 = arith.subi %34, %c2_i32_4 : i32
    %130 = arith.cmpi slt, %arg12, %129 : i32
    %131 = triton_gpu.local_load %arg18 token %arg19 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %132 = triton_gpu.local_load %arg20 token %arg21 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %133 = triton_gpu.convert_layout %131 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %134 = triton_gpu.convert_layout %132 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %135 = tt.dot %133, %134, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %136 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %137 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %138 = arith.addi %arg16, %c1_i32 : i32
    %139 = arith.cmpi slt, %138, %c2_i32 : i32
    %140 = arith.select %139, %138, %c0_i32 : i32
    %c2_i32_5 = arith.constant 2 : i32
    %141 = arith.addi %arg12, %c2_i32_5 : i32
    %142 = arith.muli %141, %c32_i32 : i32
    %143 = arith.subi %arg8, %142 : i32
    %144 = tt.splat %143 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %145 = arith.cmpi slt, %16, %144 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %146 = tt.broadcast %145 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %147 = arith.andi %37, %146 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %148 = triton_gpu.memdesc_subview %43[%140, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %149 = tt.splat %130 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %150 = arith.andi %149, %147 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %151 = triton_gpu.async_copy_global_to_local %136, %148 mask %150 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %152 = triton_gpu.async_commit_group %151
    %153 = tt.splat %143 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %154 = arith.cmpi slt, %22, %153 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %155 = tt.broadcast %154 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %156 = arith.andi %155, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %157 = triton_gpu.memdesc_subview %44[%140, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %158 = tt.splat %130 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %159 = arith.andi %158, %156 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %160 = triton_gpu.async_copy_global_to_local %137, %157 mask %159 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %161 = triton_gpu.async_commit_group %160
    %162 = arith.addi %arg17, %c1_i32 : i32
    %163 = arith.cmpi slt, %162, %c2_i32 : i32
    %164 = arith.select %163, %162, %c0_i32 : i32
    %165 = triton_gpu.memdesc_subview %43[%164, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %166 = triton_gpu.async_wait %arg23 {num = 2 : i32}
    %167 = triton_gpu.memdesc_subview %44[%164, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    scf.yield %135, %136, %137, %140, %164, %165, %166, %167, %166, %152, %161 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token
  }
  %106 = triton_gpu.async_wait  {num = 0 : i32}
  triton_gpu.local_dealloc %43 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  triton_gpu.local_dealloc %44 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %107 = tt.splat %arg7 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %108 = arith.cmpi slt, %12, %107 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %109 = tt.load %32, %108, %cst_2 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %110 = arith.sitofp %arg4 : i32 to f32
  %111 = tt.splat %110 : f32 -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %112 = arith.mulf %105#0, %111 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %113 = arith.sitofp %arg5 : i32 to f16
  %114 = tt.splat %113 : f16 -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %115 = arith.mulf %109, %114 : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %116 = tt.expand_dims %115 {axis = 0 : i32} : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>> -> tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %117 = arith.extf %116 : tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %118 = tt.broadcast %117 : tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %119 = arith.addf %112, %118 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %120 = arith.truncf %119 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %121 = tt.splat %arg11 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %122 = arith.muli %121, %13 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %123 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %124 = tt.addptr %123, %122 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %125 = tt.broadcast %124 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %126 = tt.addptr %125, %27 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %127 = arith.andi %37, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %128 = triton_gpu.convert_layout %120 : tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.store %126, %128, %127 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.return
}



//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa423d50) {
  %84 = "arith.cmpi"(%83, %44) <{predicate = 2 : i64}> : (i32, i32) -> i1

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.muli'(0x55bafa423bf0) {
  %83 = "arith.muli"(%4, %4) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> success : operation was folded
//===-------------------------------------------===//
** Replace : 'arith.muli'(0x55bafa423bf0)
** Modified: 'arith.cmpi'(0x55bafa423d50)
** Erase   : 'arith.muli'(0x55bafa423bf0)
// *** IR Dump After Successful Folding ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c2_i32 = arith.constant 2 : i32
  %c-1_i32 = arith.constant -1 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %c32_i32 = arith.constant 32 : i32
  %c31_i32 = arith.constant 31 : i32
  %cst_1 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %5 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %7 = arith.addi %6, %3 : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %8 = arith.muli %1, %c32_i32 : i32
  %9 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %10 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %11 = arith.addi %9, %4 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %12 = arith.addi %10, %5 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %13 = tt.expand_dims %7 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %14 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %15 = arith.muli %13, %14 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %16 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.broadcast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %18 = tt.broadcast %16 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = arith.addi %17, %18 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %20 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %22 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %23 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %24 = arith.muli %22, %23 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %11 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %26 = tt.broadcast %24 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = tt.broadcast %25 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = arith.addi %26, %27 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %32 = tt.addptr %31, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %33 = arith.addi %arg8, %c31_i32 : i32
  %34 = arith.divsi %33, %c32_i32 : i32
  %35 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = arith.cmpi slt, %13, %35 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = tt.broadcast %36 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %38 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = arith.cmpi slt, %25, %38 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.broadcast %39 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %41 = arith.muli %arg10, %c32_i32 : i32
  %42 = tt.splat %41 : i32 -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %43 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %44 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %45 = arith.muli %c1_i32, %c0_i32 : i32
  %46 = arith.addi %c0_i32, %45 : i32
  %47 = arith.cmpi slt, %46, %34 : i32
  %48 = arith.muli %c1_i32, %c0_i32 : i32
  %49 = arith.addi %c0_i32, %48 : i32
  %50 = arith.addi %c-1_i32, %c1_i32 : i32
  %51 = arith.cmpi slt, %50, %c2_i32 : i32
  %52 = arith.select %51, %50, %c0_i32 : i32
  %53 = arith.muli %49, %c32_i32 : i32
  %54 = arith.subi %arg8, %53 : i32
  %55 = tt.splat %54 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = arith.cmpi slt, %16, %55 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = tt.broadcast %56 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %58 = arith.andi %37, %57 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = triton_gpu.memdesc_subview %43[%52, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %60 = tt.splat %47 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %61 = arith.andi %60, %58 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = triton_gpu.async_copy_global_to_local %21, %59 mask %61 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %63 = triton_gpu.async_commit_group %62
  %64 = tt.splat %54 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = arith.cmpi slt, %22, %64 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %66 = tt.broadcast %65 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = arith.andi %66, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %68 = triton_gpu.memdesc_subview %44[%52, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %69 = tt.splat %47 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = arith.andi %69, %67 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = triton_gpu.async_copy_global_to_local %30, %68 mask %70 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %72 = triton_gpu.async_commit_group %71
  %73 = arith.cmpi slt, %c1_i32, %34 : i32
  %74 = tt.addptr %21, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = tt.addptr %30, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %76 = arith.addi %52, %c1_i32 : i32
  %77 = arith.cmpi slt, %76, %c2_i32 : i32
  %78 = arith.select %77, %76, %c0_i32 : i32
  %c32_i32_3 = arith.constant 32 : i32
  %79 = arith.subi %arg8, %c32_i32_3 : i32
  %80 = tt.splat %79 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = arith.cmpi slt, %16, %80 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = tt.broadcast %81 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = arith.andi %37, %82 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = triton_gpu.memdesc_subview %43[%78, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %85 = tt.splat %73 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = arith.andi %85, %83 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %87 = triton_gpu.async_copy_global_to_local %74, %84 mask %86 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %88 = triton_gpu.async_commit_group %87
  %89 = tt.splat %79 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = arith.cmpi slt, %22, %89 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %91 = tt.broadcast %90 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %92 = arith.andi %91, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = triton_gpu.memdesc_subview %44[%78, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %94 = tt.splat %73 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %95 = arith.andi %94, %92 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %96 = triton_gpu.async_copy_global_to_local %75, %93 mask %95 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %97 = triton_gpu.async_commit_group %96
  %98 = arith.addi %c-1_i32, %c1_i32 : i32
  %99 = arith.cmpi slt, %98, %c2_i32 : i32
  %100 = arith.select %99, %98, %c0_i32 : i32
  %101 = triton_gpu.memdesc_subview %43[%100, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %102 = triton_gpu.async_wait %72 {num = 2 : i32}
  %103 = triton_gpu.memdesc_subview %44[%100, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %104:11 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %74, %arg15 = %75, %arg16 = %78, %arg17 = %100, %arg18 = %101, %arg19 = %102, %arg20 = %103, %arg21 = %102, %arg22 = %88, %arg23 = %97) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token)  : i32 {
    %c2_i32_4 = arith.constant 2 : i32
    %128 = arith.subi %34, %c2_i32_4 : i32
    %129 = arith.cmpi slt, %arg12, %128 : i32
    %130 = triton_gpu.local_load %arg18 token %arg19 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %131 = triton_gpu.local_load %arg20 token %arg21 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %132 = triton_gpu.convert_layout %130 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %133 = triton_gpu.convert_layout %131 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %134 = tt.dot %132, %133, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %135 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %136 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %137 = arith.addi %arg16, %c1_i32 : i32
    %138 = arith.cmpi slt, %137, %c2_i32 : i32
    %139 = arith.select %138, %137, %c0_i32 : i32
    %c2_i32_5 = arith.constant 2 : i32
    %140 = arith.addi %arg12, %c2_i32_5 : i32
    %141 = arith.muli %140, %c32_i32 : i32
    %142 = arith.subi %arg8, %141 : i32
    %143 = tt.splat %142 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %144 = arith.cmpi slt, %16, %143 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %145 = tt.broadcast %144 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %146 = arith.andi %37, %145 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %147 = triton_gpu.memdesc_subview %43[%139, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %148 = tt.splat %129 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = arith.andi %148, %146 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %150 = triton_gpu.async_copy_global_to_local %135, %147 mask %149 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %151 = triton_gpu.async_commit_group %150
    %152 = tt.splat %142 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %153 = arith.cmpi slt, %22, %152 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %154 = tt.broadcast %153 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %155 = arith.andi %154, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %156 = triton_gpu.memdesc_subview %44[%139, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %157 = tt.splat %129 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %158 = arith.andi %157, %155 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %159 = triton_gpu.async_copy_global_to_local %136, %156 mask %158 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %160 = triton_gpu.async_commit_group %159
    %161 = arith.addi %arg17, %c1_i32 : i32
    %162 = arith.cmpi slt, %161, %c2_i32 : i32
    %163 = arith.select %162, %161, %c0_i32 : i32
    %164 = triton_gpu.memdesc_subview %43[%163, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %165 = triton_gpu.async_wait %arg23 {num = 2 : i32}
    %166 = triton_gpu.memdesc_subview %44[%163, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    scf.yield %134, %135, %136, %139, %163, %164, %165, %166, %165, %151, %160 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token
  }
  %105 = triton_gpu.async_wait  {num = 0 : i32}
  triton_gpu.local_dealloc %43 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  triton_gpu.local_dealloc %44 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %106 = tt.splat %arg7 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %107 = arith.cmpi slt, %12, %106 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %108 = tt.load %32, %107, %cst_2 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %109 = arith.sitofp %arg4 : i32 to f32
  %110 = tt.splat %109 : f32 -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %111 = arith.mulf %104#0, %110 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %112 = arith.sitofp %arg5 : i32 to f16
  %113 = tt.splat %112 : f16 -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %114 = arith.mulf %108, %113 : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %115 = tt.expand_dims %114 {axis = 0 : i32} : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>> -> tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %116 = arith.extf %115 : tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %117 = tt.broadcast %116 : tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %118 = arith.addf %111, %117 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %119 = arith.truncf %118 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %120 = tt.splat %arg11 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %121 = arith.muli %120, %13 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %122 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %123 = tt.addptr %122, %121 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %124 = tt.broadcast %123 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %125 = tt.addptr %124, %27 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %126 = arith.andi %37, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %127 = triton_gpu.convert_layout %119 : tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.store %125, %127, %126 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.return
}



//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa423d50) {
  %83 = "arith.cmpi"(%4, %44) <{predicate = 2 : i64}> : (i32, i32) -> i1

} -> success : operation was folded
//===-------------------------------------------===//
** Modified: 'arith.cmpi'(0x55bafa423d50)
// *** IR Dump After Successful Folding ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c2_i32 = arith.constant 2 : i32
  %c-1_i32 = arith.constant -1 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %c32_i32 = arith.constant 32 : i32
  %c31_i32 = arith.constant 31 : i32
  %cst_1 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %5 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %7 = arith.addi %6, %3 : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %8 = arith.muli %1, %c32_i32 : i32
  %9 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %10 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %11 = arith.addi %9, %4 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %12 = arith.addi %10, %5 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %13 = tt.expand_dims %7 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %14 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %15 = arith.muli %13, %14 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %16 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.broadcast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %18 = tt.broadcast %16 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = arith.addi %17, %18 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %20 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %22 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %23 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %24 = arith.muli %22, %23 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %11 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %26 = tt.broadcast %24 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = tt.broadcast %25 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = arith.addi %26, %27 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %32 = tt.addptr %31, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %33 = arith.addi %arg8, %c31_i32 : i32
  %34 = arith.divsi %33, %c32_i32 : i32
  %35 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = arith.cmpi slt, %13, %35 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = tt.broadcast %36 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %38 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = arith.cmpi slt, %25, %38 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.broadcast %39 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %41 = arith.muli %arg10, %c32_i32 : i32
  %42 = tt.splat %41 : i32 -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %43 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %44 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %45 = arith.muli %c1_i32, %c0_i32 : i32
  %46 = arith.addi %c0_i32, %45 : i32
  %47 = arith.cmpi slt, %46, %34 : i32
  %48 = arith.muli %c1_i32, %c0_i32 : i32
  %49 = arith.addi %c0_i32, %48 : i32
  %50 = arith.addi %c-1_i32, %c1_i32 : i32
  %51 = arith.cmpi slt, %50, %c2_i32 : i32
  %52 = arith.select %51, %50, %c0_i32 : i32
  %53 = arith.muli %49, %c32_i32 : i32
  %54 = arith.subi %arg8, %53 : i32
  %55 = tt.splat %54 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = arith.cmpi slt, %16, %55 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = tt.broadcast %56 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %58 = arith.andi %37, %57 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = triton_gpu.memdesc_subview %43[%52, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %60 = tt.splat %47 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %61 = arith.andi %60, %58 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = triton_gpu.async_copy_global_to_local %21, %59 mask %61 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %63 = triton_gpu.async_commit_group %62
  %64 = tt.splat %54 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = arith.cmpi slt, %22, %64 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %66 = tt.broadcast %65 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = arith.andi %66, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %68 = triton_gpu.memdesc_subview %44[%52, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %69 = tt.splat %47 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = arith.andi %69, %67 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = triton_gpu.async_copy_global_to_local %30, %68 mask %70 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %72 = triton_gpu.async_commit_group %71
  %73 = arith.cmpi sgt, %34, %c1_i32 : i32
  %74 = tt.addptr %21, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = tt.addptr %30, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %76 = arith.addi %52, %c1_i32 : i32
  %77 = arith.cmpi slt, %76, %c2_i32 : i32
  %78 = arith.select %77, %76, %c0_i32 : i32
  %c32_i32_3 = arith.constant 32 : i32
  %79 = arith.subi %arg8, %c32_i32_3 : i32
  %80 = tt.splat %79 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = arith.cmpi slt, %16, %80 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = tt.broadcast %81 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = arith.andi %37, %82 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = triton_gpu.memdesc_subview %43[%78, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %85 = tt.splat %73 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = arith.andi %85, %83 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %87 = triton_gpu.async_copy_global_to_local %74, %84 mask %86 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %88 = triton_gpu.async_commit_group %87
  %89 = tt.splat %79 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = arith.cmpi slt, %22, %89 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %91 = tt.broadcast %90 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %92 = arith.andi %91, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = triton_gpu.memdesc_subview %44[%78, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %94 = tt.splat %73 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %95 = arith.andi %94, %92 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %96 = triton_gpu.async_copy_global_to_local %75, %93 mask %95 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %97 = triton_gpu.async_commit_group %96
  %98 = arith.addi %c-1_i32, %c1_i32 : i32
  %99 = arith.cmpi slt, %98, %c2_i32 : i32
  %100 = arith.select %99, %98, %c0_i32 : i32
  %101 = triton_gpu.memdesc_subview %43[%100, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %102 = triton_gpu.async_wait %72 {num = 2 : i32}
  %103 = triton_gpu.memdesc_subview %44[%100, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %104:11 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %74, %arg15 = %75, %arg16 = %78, %arg17 = %100, %arg18 = %101, %arg19 = %102, %arg20 = %103, %arg21 = %102, %arg22 = %88, %arg23 = %97) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token)  : i32 {
    %c2_i32_4 = arith.constant 2 : i32
    %128 = arith.subi %34, %c2_i32_4 : i32
    %129 = arith.cmpi slt, %arg12, %128 : i32
    %130 = triton_gpu.local_load %arg18 token %arg19 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %131 = triton_gpu.local_load %arg20 token %arg21 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %132 = triton_gpu.convert_layout %130 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %133 = triton_gpu.convert_layout %131 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %134 = tt.dot %132, %133, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %135 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %136 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %137 = arith.addi %arg16, %c1_i32 : i32
    %138 = arith.cmpi slt, %137, %c2_i32 : i32
    %139 = arith.select %138, %137, %c0_i32 : i32
    %c2_i32_5 = arith.constant 2 : i32
    %140 = arith.addi %arg12, %c2_i32_5 : i32
    %141 = arith.muli %140, %c32_i32 : i32
    %142 = arith.subi %arg8, %141 : i32
    %143 = tt.splat %142 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %144 = arith.cmpi slt, %16, %143 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %145 = tt.broadcast %144 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %146 = arith.andi %37, %145 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %147 = triton_gpu.memdesc_subview %43[%139, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %148 = tt.splat %129 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = arith.andi %148, %146 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %150 = triton_gpu.async_copy_global_to_local %135, %147 mask %149 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %151 = triton_gpu.async_commit_group %150
    %152 = tt.splat %142 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %153 = arith.cmpi slt, %22, %152 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %154 = tt.broadcast %153 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %155 = arith.andi %154, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %156 = triton_gpu.memdesc_subview %44[%139, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %157 = tt.splat %129 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %158 = arith.andi %157, %155 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %159 = triton_gpu.async_copy_global_to_local %136, %156 mask %158 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %160 = triton_gpu.async_commit_group %159
    %161 = arith.addi %arg17, %c1_i32 : i32
    %162 = arith.cmpi slt, %161, %c2_i32 : i32
    %163 = arith.select %162, %161, %c0_i32 : i32
    %164 = triton_gpu.memdesc_subview %43[%163, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %165 = triton_gpu.async_wait %arg23 {num = 2 : i32}
    %166 = triton_gpu.memdesc_subview %44[%163, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    scf.yield %134, %135, %136, %139, %163, %164, %165, %166, %165, %151, %160 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token
  }
  %105 = triton_gpu.async_wait  {num = 0 : i32}
  triton_gpu.local_dealloc %43 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  triton_gpu.local_dealloc %44 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %106 = tt.splat %arg7 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %107 = arith.cmpi slt, %12, %106 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %108 = tt.load %32, %107, %cst_2 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %109 = arith.sitofp %arg4 : i32 to f32
  %110 = tt.splat %109 : f32 -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %111 = arith.mulf %104#0, %110 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %112 = arith.sitofp %arg5 : i32 to f16
  %113 = tt.splat %112 : f16 -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %114 = arith.mulf %108, %113 : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %115 = tt.expand_dims %114 {axis = 0 : i32} : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>> -> tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %116 = arith.extf %115 : tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %117 = tt.broadcast %116 : tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %118 = arith.addf %111, %117 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %119 = arith.truncf %118 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %120 = tt.splat %arg11 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %121 = arith.muli %120, %13 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %122 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %123 = tt.addptr %122, %121 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %124 = tt.broadcast %123 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %125 = tt.addptr %124, %27 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %126 = arith.andi %37, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %127 = triton_gpu.convert_layout %119 : tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.store %125, %127, %126 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.return
}



//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa423d50) {
  %83 = "arith.cmpi"(%44, %4) <{predicate = 4 : i64}> : (i32, i32) -> i1

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.async_commit_group'(0x55bafa423af0) {
  %82 = "triton_gpu.async_commit_group"(%81) : (!triton_gpu.async.token) -> !triton_gpu.async.token

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.async_copy_global_to_local'(0x55bafa42c3a0) {
  %81 = "triton_gpu.async_copy_global_to_local"(%40, %78, %80, %5) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> !triton_gpu.async.token

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.andi'(0x55bafa423a40) {
  %80 = "arith.andi"(%79, %77) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa42c4b0) {
  %79 = "tt.splat"(%57) : (i1) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.andi'(0x55bafa42c2f0) {
  %77 = "arith.andi"(%76, %50) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.broadcast'(0x55bafa42c260) {
  %76 = "tt.broadcast"(%75) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa42c1b0) {
  %75 = "arith.cmpi"(%32, %74) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa431100) {
  %74 = "tt.splat"(%64) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.async_commit_group'(0x55bafa431070) {
  %73 = "triton_gpu.async_commit_group"(%72) : (!triton_gpu.async.token) -> !triton_gpu.async.token

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.async_copy_global_to_local'(0x55bafa43a1b0) {
  %72 = "triton_gpu.async_copy_global_to_local"(%31, %69, %71, %5) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> !triton_gpu.async.token

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.andi'(0x55bafa430fc0) {
  %71 = "arith.andi"(%70, %68) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa42bcc0) {
  %70 = "tt.splat"(%57) : (i1) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.andi'(0x55bafa42bc10) {
  %68 = "arith.andi"(%47, %67) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.broadcast'(0x55bafa41a180) {
  %67 = "tt.broadcast"(%66) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa41fda0) {
  %66 = "arith.cmpi"(%26, %65) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa364ff0) {
  %65 = "tt.splat"(%64) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.subi'(0x55bafa41fcf0) {
  %64 = "arith.subi"(%arg8, %63) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.muli'(0x55bafa4234e0) {
  %63 = "arith.muli"(%59, %6) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa423430) {
  %61 = "arith.cmpi"(%60, %0) <{predicate = 2 : i64}> : (i32, i32) -> i1

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.addi'(0x55bafa33b590) {
  %59 = "arith.addi"(%3, %58) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> success : operation was folded
//===-------------------------------------------===//
** Modified: 'arith.addi'(0x55bafa33b590)
// *** IR Dump After Successful Folding ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c2_i32 = arith.constant 2 : i32
  %c-1_i32 = arith.constant -1 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %c32_i32 = arith.constant 32 : i32
  %c31_i32 = arith.constant 31 : i32
  %cst_1 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %5 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %7 = arith.addi %6, %3 : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %8 = arith.muli %1, %c32_i32 : i32
  %9 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %10 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %11 = arith.addi %9, %4 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %12 = arith.addi %10, %5 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %13 = tt.expand_dims %7 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %14 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %15 = arith.muli %13, %14 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %16 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.broadcast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %18 = tt.broadcast %16 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = arith.addi %17, %18 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %20 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %22 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %23 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %24 = arith.muli %22, %23 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %11 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %26 = tt.broadcast %24 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = tt.broadcast %25 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = arith.addi %26, %27 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %32 = tt.addptr %31, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %33 = arith.addi %arg8, %c31_i32 : i32
  %34 = arith.divsi %33, %c32_i32 : i32
  %35 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = arith.cmpi slt, %13, %35 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = tt.broadcast %36 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %38 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = arith.cmpi slt, %25, %38 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.broadcast %39 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %41 = arith.muli %arg10, %c32_i32 : i32
  %42 = tt.splat %41 : i32 -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %43 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %44 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %45 = arith.muli %c1_i32, %c0_i32 : i32
  %46 = arith.addi %c0_i32, %45 : i32
  %47 = arith.cmpi slt, %46, %34 : i32
  %48 = arith.muli %c1_i32, %c0_i32 : i32
  %49 = arith.addi %48, %c0_i32 : i32
  %50 = arith.addi %c-1_i32, %c1_i32 : i32
  %51 = arith.cmpi slt, %50, %c2_i32 : i32
  %52 = arith.select %51, %50, %c0_i32 : i32
  %53 = arith.muli %49, %c32_i32 : i32
  %54 = arith.subi %arg8, %53 : i32
  %55 = tt.splat %54 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = arith.cmpi slt, %16, %55 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = tt.broadcast %56 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %58 = arith.andi %37, %57 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = triton_gpu.memdesc_subview %43[%52, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %60 = tt.splat %47 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %61 = arith.andi %60, %58 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = triton_gpu.async_copy_global_to_local %21, %59 mask %61 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %63 = triton_gpu.async_commit_group %62
  %64 = tt.splat %54 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = arith.cmpi slt, %22, %64 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %66 = tt.broadcast %65 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = arith.andi %66, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %68 = triton_gpu.memdesc_subview %44[%52, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %69 = tt.splat %47 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = arith.andi %69, %67 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = triton_gpu.async_copy_global_to_local %30, %68 mask %70 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %72 = triton_gpu.async_commit_group %71
  %73 = arith.cmpi sgt, %34, %c1_i32 : i32
  %74 = tt.addptr %21, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = tt.addptr %30, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %76 = arith.addi %52, %c1_i32 : i32
  %77 = arith.cmpi slt, %76, %c2_i32 : i32
  %78 = arith.select %77, %76, %c0_i32 : i32
  %c32_i32_3 = arith.constant 32 : i32
  %79 = arith.subi %arg8, %c32_i32_3 : i32
  %80 = tt.splat %79 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = arith.cmpi slt, %16, %80 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = tt.broadcast %81 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = arith.andi %37, %82 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = triton_gpu.memdesc_subview %43[%78, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %85 = tt.splat %73 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = arith.andi %85, %83 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %87 = triton_gpu.async_copy_global_to_local %74, %84 mask %86 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %88 = triton_gpu.async_commit_group %87
  %89 = tt.splat %79 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = arith.cmpi slt, %22, %89 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %91 = tt.broadcast %90 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %92 = arith.andi %91, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = triton_gpu.memdesc_subview %44[%78, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %94 = tt.splat %73 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %95 = arith.andi %94, %92 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %96 = triton_gpu.async_copy_global_to_local %75, %93 mask %95 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %97 = triton_gpu.async_commit_group %96
  %98 = arith.addi %c-1_i32, %c1_i32 : i32
  %99 = arith.cmpi slt, %98, %c2_i32 : i32
  %100 = arith.select %99, %98, %c0_i32 : i32
  %101 = triton_gpu.memdesc_subview %43[%100, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %102 = triton_gpu.async_wait %72 {num = 2 : i32}
  %103 = triton_gpu.memdesc_subview %44[%100, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %104:11 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %74, %arg15 = %75, %arg16 = %78, %arg17 = %100, %arg18 = %101, %arg19 = %102, %arg20 = %103, %arg21 = %102, %arg22 = %88, %arg23 = %97) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token)  : i32 {
    %c2_i32_4 = arith.constant 2 : i32
    %128 = arith.subi %34, %c2_i32_4 : i32
    %129 = arith.cmpi slt, %arg12, %128 : i32
    %130 = triton_gpu.local_load %arg18 token %arg19 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %131 = triton_gpu.local_load %arg20 token %arg21 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %132 = triton_gpu.convert_layout %130 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %133 = triton_gpu.convert_layout %131 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %134 = tt.dot %132, %133, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %135 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %136 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %137 = arith.addi %arg16, %c1_i32 : i32
    %138 = arith.cmpi slt, %137, %c2_i32 : i32
    %139 = arith.select %138, %137, %c0_i32 : i32
    %c2_i32_5 = arith.constant 2 : i32
    %140 = arith.addi %arg12, %c2_i32_5 : i32
    %141 = arith.muli %140, %c32_i32 : i32
    %142 = arith.subi %arg8, %141 : i32
    %143 = tt.splat %142 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %144 = arith.cmpi slt, %16, %143 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %145 = tt.broadcast %144 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %146 = arith.andi %37, %145 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %147 = triton_gpu.memdesc_subview %43[%139, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %148 = tt.splat %129 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = arith.andi %148, %146 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %150 = triton_gpu.async_copy_global_to_local %135, %147 mask %149 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %151 = triton_gpu.async_commit_group %150
    %152 = tt.splat %142 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %153 = arith.cmpi slt, %22, %152 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %154 = tt.broadcast %153 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %155 = arith.andi %154, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %156 = triton_gpu.memdesc_subview %44[%139, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %157 = tt.splat %129 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %158 = arith.andi %157, %155 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %159 = triton_gpu.async_copy_global_to_local %136, %156 mask %158 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %160 = triton_gpu.async_commit_group %159
    %161 = arith.addi %arg17, %c1_i32 : i32
    %162 = arith.cmpi slt, %161, %c2_i32 : i32
    %163 = arith.select %162, %161, %c0_i32 : i32
    %164 = triton_gpu.memdesc_subview %43[%163, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %165 = triton_gpu.async_wait %arg23 {num = 2 : i32}
    %166 = triton_gpu.memdesc_subview %44[%163, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    scf.yield %134, %135, %136, %139, %163, %164, %165, %166, %165, %151, %160 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token
  }
  %105 = triton_gpu.async_wait  {num = 0 : i32}
  triton_gpu.local_dealloc %43 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  triton_gpu.local_dealloc %44 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %106 = tt.splat %arg7 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %107 = arith.cmpi slt, %12, %106 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %108 = tt.load %32, %107, %cst_2 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %109 = arith.sitofp %arg4 : i32 to f32
  %110 = tt.splat %109 : f32 -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %111 = arith.mulf %104#0, %110 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %112 = arith.sitofp %arg5 : i32 to f16
  %113 = tt.splat %112 : f16 -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %114 = arith.mulf %108, %113 : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %115 = tt.expand_dims %114 {axis = 0 : i32} : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>> -> tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %116 = arith.extf %115 : tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %117 = tt.broadcast %116 : tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %118 = arith.addf %111, %117 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %119 = arith.truncf %118 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %120 = tt.splat %arg11 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %121 = arith.muli %120, %13 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %122 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %123 = tt.addptr %122, %121 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %124 = tt.broadcast %123 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %125 = tt.addptr %124, %27 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %126 = arith.andi %37, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %127 = triton_gpu.convert_layout %119 : tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.store %125, %127, %126 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.return
}



//===-------------------------------------------===//
Processing operation : 'arith.addi'(0x55bafa33b590) {
  %59 = "arith.addi"(%58, %3) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> success : operation was folded
//===-------------------------------------------===//
** Replace : 'arith.addi'(0x55bafa33b590)
** Modified: 'arith.muli'(0x55bafa4234e0)
** Erase   : 'arith.addi'(0x55bafa33b590)
// *** IR Dump After Successful Folding ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c2_i32 = arith.constant 2 : i32
  %c-1_i32 = arith.constant -1 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %c32_i32 = arith.constant 32 : i32
  %c31_i32 = arith.constant 31 : i32
  %cst_1 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %5 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %7 = arith.addi %6, %3 : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %8 = arith.muli %1, %c32_i32 : i32
  %9 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %10 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %11 = arith.addi %9, %4 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %12 = arith.addi %10, %5 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %13 = tt.expand_dims %7 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %14 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %15 = arith.muli %13, %14 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %16 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.broadcast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %18 = tt.broadcast %16 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = arith.addi %17, %18 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %20 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %22 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %23 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %24 = arith.muli %22, %23 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %11 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %26 = tt.broadcast %24 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = tt.broadcast %25 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = arith.addi %26, %27 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %32 = tt.addptr %31, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %33 = arith.addi %arg8, %c31_i32 : i32
  %34 = arith.divsi %33, %c32_i32 : i32
  %35 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = arith.cmpi slt, %13, %35 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = tt.broadcast %36 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %38 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = arith.cmpi slt, %25, %38 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.broadcast %39 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %41 = arith.muli %arg10, %c32_i32 : i32
  %42 = tt.splat %41 : i32 -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %43 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %44 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %45 = arith.muli %c1_i32, %c0_i32 : i32
  %46 = arith.addi %c0_i32, %45 : i32
  %47 = arith.cmpi slt, %46, %34 : i32
  %48 = arith.muli %c1_i32, %c0_i32 : i32
  %49 = arith.addi %c-1_i32, %c1_i32 : i32
  %50 = arith.cmpi slt, %49, %c2_i32 : i32
  %51 = arith.select %50, %49, %c0_i32 : i32
  %52 = arith.muli %48, %c32_i32 : i32
  %53 = arith.subi %arg8, %52 : i32
  %54 = tt.splat %53 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %55 = arith.cmpi slt, %16, %54 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = tt.broadcast %55 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = arith.andi %37, %56 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %58 = triton_gpu.memdesc_subview %43[%51, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %59 = tt.splat %47 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = arith.andi %59, %57 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %61 = triton_gpu.async_copy_global_to_local %21, %58 mask %60 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %62 = triton_gpu.async_commit_group %61
  %63 = tt.splat %53 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %64 = arith.cmpi slt, %22, %63 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = tt.broadcast %64 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %66 = arith.andi %65, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = triton_gpu.memdesc_subview %44[%51, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %68 = tt.splat %47 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = arith.andi %68, %66 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = triton_gpu.async_copy_global_to_local %30, %67 mask %69 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %71 = triton_gpu.async_commit_group %70
  %72 = arith.cmpi sgt, %34, %c1_i32 : i32
  %73 = tt.addptr %21, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %74 = tt.addptr %30, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = arith.addi %51, %c1_i32 : i32
  %76 = arith.cmpi slt, %75, %c2_i32 : i32
  %77 = arith.select %76, %75, %c0_i32 : i32
  %c32_i32_3 = arith.constant 32 : i32
  %78 = arith.subi %arg8, %c32_i32_3 : i32
  %79 = tt.splat %78 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %80 = arith.cmpi slt, %16, %79 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = tt.broadcast %80 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = arith.andi %37, %81 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = triton_gpu.memdesc_subview %43[%77, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %84 = tt.splat %72 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %85 = arith.andi %84, %82 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = triton_gpu.async_copy_global_to_local %73, %83 mask %85 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %87 = triton_gpu.async_commit_group %86
  %88 = tt.splat %78 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %89 = arith.cmpi slt, %22, %88 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = tt.broadcast %89 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %91 = arith.andi %90, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %92 = triton_gpu.memdesc_subview %44[%77, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %93 = tt.splat %72 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %94 = arith.andi %93, %91 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %95 = triton_gpu.async_copy_global_to_local %74, %92 mask %94 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %96 = triton_gpu.async_commit_group %95
  %97 = arith.addi %c-1_i32, %c1_i32 : i32
  %98 = arith.cmpi slt, %97, %c2_i32 : i32
  %99 = arith.select %98, %97, %c0_i32 : i32
  %100 = triton_gpu.memdesc_subview %43[%99, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %101 = triton_gpu.async_wait %71 {num = 2 : i32}
  %102 = triton_gpu.memdesc_subview %44[%99, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %103:11 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %73, %arg15 = %74, %arg16 = %77, %arg17 = %99, %arg18 = %100, %arg19 = %101, %arg20 = %102, %arg21 = %101, %arg22 = %87, %arg23 = %96) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token)  : i32 {
    %c2_i32_4 = arith.constant 2 : i32
    %127 = arith.subi %34, %c2_i32_4 : i32
    %128 = arith.cmpi slt, %arg12, %127 : i32
    %129 = triton_gpu.local_load %arg18 token %arg19 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %130 = triton_gpu.local_load %arg20 token %arg21 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %131 = triton_gpu.convert_layout %129 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %132 = triton_gpu.convert_layout %130 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %133 = tt.dot %131, %132, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %134 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %135 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %136 = arith.addi %arg16, %c1_i32 : i32
    %137 = arith.cmpi slt, %136, %c2_i32 : i32
    %138 = arith.select %137, %136, %c0_i32 : i32
    %c2_i32_5 = arith.constant 2 : i32
    %139 = arith.addi %arg12, %c2_i32_5 : i32
    %140 = arith.muli %139, %c32_i32 : i32
    %141 = arith.subi %arg8, %140 : i32
    %142 = tt.splat %141 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %143 = arith.cmpi slt, %16, %142 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %144 = tt.broadcast %143 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %145 = arith.andi %37, %144 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %146 = triton_gpu.memdesc_subview %43[%138, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %147 = tt.splat %128 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %148 = arith.andi %147, %145 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = triton_gpu.async_copy_global_to_local %134, %146 mask %148 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %150 = triton_gpu.async_commit_group %149
    %151 = tt.splat %141 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %152 = arith.cmpi slt, %22, %151 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %153 = tt.broadcast %152 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %154 = arith.andi %153, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %155 = triton_gpu.memdesc_subview %44[%138, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %156 = tt.splat %128 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %157 = arith.andi %156, %154 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %158 = triton_gpu.async_copy_global_to_local %135, %155 mask %157 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %159 = triton_gpu.async_commit_group %158
    %160 = arith.addi %arg17, %c1_i32 : i32
    %161 = arith.cmpi slt, %160, %c2_i32 : i32
    %162 = arith.select %161, %160, %c0_i32 : i32
    %163 = triton_gpu.memdesc_subview %43[%162, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %164 = triton_gpu.async_wait %arg23 {num = 2 : i32}
    %165 = triton_gpu.memdesc_subview %44[%162, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    scf.yield %133, %134, %135, %138, %162, %163, %164, %165, %164, %150, %159 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token
  }
  %104 = triton_gpu.async_wait  {num = 0 : i32}
  triton_gpu.local_dealloc %43 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  triton_gpu.local_dealloc %44 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %105 = tt.splat %arg7 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %106 = arith.cmpi slt, %12, %105 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %107 = tt.load %32, %106, %cst_2 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %108 = arith.sitofp %arg4 : i32 to f32
  %109 = tt.splat %108 : f32 -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %110 = arith.mulf %103#0, %109 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %111 = arith.sitofp %arg5 : i32 to f16
  %112 = tt.splat %111 : f16 -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %113 = arith.mulf %107, %112 : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %114 = tt.expand_dims %113 {axis = 0 : i32} : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>> -> tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %115 = arith.extf %114 : tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %116 = tt.broadcast %115 : tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %117 = arith.addf %110, %116 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %118 = arith.truncf %117 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %119 = tt.splat %arg11 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %120 = arith.muli %119, %13 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %121 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %122 = tt.addptr %121, %120 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %123 = tt.broadcast %122 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %124 = tt.addptr %123, %27 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %125 = arith.andi %37, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %126 = triton_gpu.convert_layout %118 : tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.store %124, %126, %125 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.return
}



//===-------------------------------------------===//
Processing operation : 'arith.muli'(0x55bafa4234e0) {
  %62 = "arith.muli"(%58, %6) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.muli'(0x55bafa3530c0) {
  %58 = "arith.muli"(%4, %3) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> success : operation was folded
//===-------------------------------------------===//
** Replace : 'arith.muli'(0x55bafa3530c0)
** Modified: 'arith.muli'(0x55bafa4234e0)
** Erase   : 'arith.muli'(0x55bafa3530c0)
// *** IR Dump After Successful Folding ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c2_i32 = arith.constant 2 : i32
  %c-1_i32 = arith.constant -1 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %c32_i32 = arith.constant 32 : i32
  %c31_i32 = arith.constant 31 : i32
  %cst_1 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %5 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %7 = arith.addi %6, %3 : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %8 = arith.muli %1, %c32_i32 : i32
  %9 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %10 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %11 = arith.addi %9, %4 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %12 = arith.addi %10, %5 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %13 = tt.expand_dims %7 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %14 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %15 = arith.muli %13, %14 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %16 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.broadcast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %18 = tt.broadcast %16 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = arith.addi %17, %18 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %20 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %22 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %23 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %24 = arith.muli %22, %23 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %11 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %26 = tt.broadcast %24 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = tt.broadcast %25 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = arith.addi %26, %27 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %32 = tt.addptr %31, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %33 = arith.addi %arg8, %c31_i32 : i32
  %34 = arith.divsi %33, %c32_i32 : i32
  %35 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = arith.cmpi slt, %13, %35 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = tt.broadcast %36 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %38 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = arith.cmpi slt, %25, %38 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.broadcast %39 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %41 = arith.muli %arg10, %c32_i32 : i32
  %42 = tt.splat %41 : i32 -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %43 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %44 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %45 = arith.muli %c1_i32, %c0_i32 : i32
  %46 = arith.addi %c0_i32, %45 : i32
  %47 = arith.cmpi slt, %46, %34 : i32
  %48 = arith.addi %c-1_i32, %c1_i32 : i32
  %49 = arith.cmpi slt, %48, %c2_i32 : i32
  %50 = arith.select %49, %48, %c0_i32 : i32
  %51 = arith.muli %c0_i32, %c32_i32 : i32
  %52 = arith.subi %arg8, %51 : i32
  %53 = tt.splat %52 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = arith.cmpi slt, %16, %53 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %55 = tt.broadcast %54 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = arith.andi %37, %55 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = triton_gpu.memdesc_subview %43[%50, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %58 = tt.splat %47 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = arith.andi %58, %56 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = triton_gpu.async_copy_global_to_local %21, %57 mask %59 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %61 = triton_gpu.async_commit_group %60
  %62 = tt.splat %52 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = arith.cmpi slt, %22, %62 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %64 = tt.broadcast %63 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = arith.andi %64, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %66 = triton_gpu.memdesc_subview %44[%50, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %67 = tt.splat %47 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %68 = arith.andi %67, %65 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = triton_gpu.async_copy_global_to_local %30, %66 mask %68 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %70 = triton_gpu.async_commit_group %69
  %71 = arith.cmpi sgt, %34, %c1_i32 : i32
  %72 = tt.addptr %21, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %73 = tt.addptr %30, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %74 = arith.addi %50, %c1_i32 : i32
  %75 = arith.cmpi slt, %74, %c2_i32 : i32
  %76 = arith.select %75, %74, %c0_i32 : i32
  %c32_i32_3 = arith.constant 32 : i32
  %77 = arith.subi %arg8, %c32_i32_3 : i32
  %78 = tt.splat %77 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = arith.cmpi slt, %16, %78 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %80 = tt.broadcast %79 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = arith.andi %37, %80 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = triton_gpu.memdesc_subview %43[%76, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %83 = tt.splat %71 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = arith.andi %83, %81 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %85 = triton_gpu.async_copy_global_to_local %72, %82 mask %84 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %86 = triton_gpu.async_commit_group %85
  %87 = tt.splat %77 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = arith.cmpi slt, %22, %87 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %89 = tt.broadcast %88 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = arith.andi %89, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %91 = triton_gpu.memdesc_subview %44[%76, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %92 = tt.splat %71 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = arith.andi %92, %90 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %94 = triton_gpu.async_copy_global_to_local %73, %91 mask %93 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %95 = triton_gpu.async_commit_group %94
  %96 = arith.addi %c-1_i32, %c1_i32 : i32
  %97 = arith.cmpi slt, %96, %c2_i32 : i32
  %98 = arith.select %97, %96, %c0_i32 : i32
  %99 = triton_gpu.memdesc_subview %43[%98, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %100 = triton_gpu.async_wait %70 {num = 2 : i32}
  %101 = triton_gpu.memdesc_subview %44[%98, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %102:11 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %72, %arg15 = %73, %arg16 = %76, %arg17 = %98, %arg18 = %99, %arg19 = %100, %arg20 = %101, %arg21 = %100, %arg22 = %86, %arg23 = %95) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token)  : i32 {
    %c2_i32_4 = arith.constant 2 : i32
    %126 = arith.subi %34, %c2_i32_4 : i32
    %127 = arith.cmpi slt, %arg12, %126 : i32
    %128 = triton_gpu.local_load %arg18 token %arg19 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %129 = triton_gpu.local_load %arg20 token %arg21 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %130 = triton_gpu.convert_layout %128 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %131 = triton_gpu.convert_layout %129 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %132 = tt.dot %130, %131, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %133 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %134 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %135 = arith.addi %arg16, %c1_i32 : i32
    %136 = arith.cmpi slt, %135, %c2_i32 : i32
    %137 = arith.select %136, %135, %c0_i32 : i32
    %c2_i32_5 = arith.constant 2 : i32
    %138 = arith.addi %arg12, %c2_i32_5 : i32
    %139 = arith.muli %138, %c32_i32 : i32
    %140 = arith.subi %arg8, %139 : i32
    %141 = tt.splat %140 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %142 = arith.cmpi slt, %16, %141 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %143 = tt.broadcast %142 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %144 = arith.andi %37, %143 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %145 = triton_gpu.memdesc_subview %43[%137, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %146 = tt.splat %127 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %147 = arith.andi %146, %144 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %148 = triton_gpu.async_copy_global_to_local %133, %145 mask %147 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %149 = triton_gpu.async_commit_group %148
    %150 = tt.splat %140 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %151 = arith.cmpi slt, %22, %150 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %152 = tt.broadcast %151 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %153 = arith.andi %152, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %154 = triton_gpu.memdesc_subview %44[%137, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %155 = tt.splat %127 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %156 = arith.andi %155, %153 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %157 = triton_gpu.async_copy_global_to_local %134, %154 mask %156 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %158 = triton_gpu.async_commit_group %157
    %159 = arith.addi %arg17, %c1_i32 : i32
    %160 = arith.cmpi slt, %159, %c2_i32 : i32
    %161 = arith.select %160, %159, %c0_i32 : i32
    %162 = triton_gpu.memdesc_subview %43[%161, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %163 = triton_gpu.async_wait %arg23 {num = 2 : i32}
    %164 = triton_gpu.memdesc_subview %44[%161, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    scf.yield %132, %133, %134, %137, %161, %162, %163, %164, %163, %149, %158 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token
  }
  %103 = triton_gpu.async_wait  {num = 0 : i32}
  triton_gpu.local_dealloc %43 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  triton_gpu.local_dealloc %44 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %104 = tt.splat %arg7 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %105 = arith.cmpi slt, %12, %104 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %106 = tt.load %32, %105, %cst_2 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %107 = arith.sitofp %arg4 : i32 to f32
  %108 = tt.splat %107 : f32 -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %109 = arith.mulf %102#0, %108 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %110 = arith.sitofp %arg5 : i32 to f16
  %111 = tt.splat %110 : f16 -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %112 = arith.mulf %106, %111 : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %113 = tt.expand_dims %112 {axis = 0 : i32} : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>> -> tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %114 = arith.extf %113 : tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %115 = tt.broadcast %114 : tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %116 = arith.addf %109, %115 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %117 = arith.truncf %116 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %118 = tt.splat %arg11 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %119 = arith.muli %118, %13 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %120 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %121 = tt.addptr %120, %119 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %122 = tt.broadcast %121 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %123 = tt.addptr %122, %27 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %124 = arith.andi %37, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %125 = triton_gpu.convert_layout %117 : tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.store %123, %125, %124 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.return
}



//===-------------------------------------------===//
Processing operation : 'arith.muli'(0x55bafa4234e0) {
  %61 = "arith.muli"(%3, %6) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> success : operation was folded
//===-------------------------------------------===//
** Insert  : 'arith.constant'(0x55bafa3b9e50)
** Replace : 'arith.muli'(0x55bafa4234e0)
** Modified: 'arith.subi'(0x55bafa41fcf0)
** Erase   : 'arith.muli'(0x55bafa4234e0)
// *** IR Dump After Successful Folding ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c2_i32 = arith.constant 2 : i32
  %c-1_i32 = arith.constant -1 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %c32_i32 = arith.constant 32 : i32
  %c31_i32 = arith.constant 31 : i32
  %cst_1 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %5 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %7 = arith.addi %6, %3 : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %8 = arith.muli %1, %c32_i32 : i32
  %9 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %10 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %11 = arith.addi %9, %4 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %12 = arith.addi %10, %5 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %13 = tt.expand_dims %7 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %14 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %15 = arith.muli %13, %14 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %16 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.broadcast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %18 = tt.broadcast %16 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = arith.addi %17, %18 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %20 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %22 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %23 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %24 = arith.muli %22, %23 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %11 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %26 = tt.broadcast %24 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = tt.broadcast %25 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = arith.addi %26, %27 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %32 = tt.addptr %31, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %33 = arith.addi %arg8, %c31_i32 : i32
  %34 = arith.divsi %33, %c32_i32 : i32
  %35 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = arith.cmpi slt, %13, %35 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = tt.broadcast %36 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %38 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = arith.cmpi slt, %25, %38 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.broadcast %39 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %41 = arith.muli %arg10, %c32_i32 : i32
  %42 = tt.splat %41 : i32 -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %43 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %44 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %45 = arith.muli %c1_i32, %c0_i32 : i32
  %46 = arith.addi %c0_i32, %45 : i32
  %47 = arith.cmpi slt, %46, %34 : i32
  %48 = arith.addi %c-1_i32, %c1_i32 : i32
  %49 = arith.cmpi slt, %48, %c2_i32 : i32
  %50 = arith.select %49, %48, %c0_i32 : i32
  %c0_i32_3 = arith.constant 0 : i32
  %51 = arith.subi %arg8, %c0_i32_3 : i32
  %52 = tt.splat %51 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %53 = arith.cmpi slt, %16, %52 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = tt.broadcast %53 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %55 = arith.andi %37, %54 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = triton_gpu.memdesc_subview %43[%50, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %57 = tt.splat %47 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %58 = arith.andi %57, %55 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = triton_gpu.async_copy_global_to_local %21, %56 mask %58 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %60 = triton_gpu.async_commit_group %59
  %61 = tt.splat %51 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = arith.cmpi slt, %22, %61 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = tt.broadcast %62 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %64 = arith.andi %63, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = triton_gpu.memdesc_subview %44[%50, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %66 = tt.splat %47 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = arith.andi %66, %64 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %68 = triton_gpu.async_copy_global_to_local %30, %65 mask %67 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %69 = triton_gpu.async_commit_group %68
  %70 = arith.cmpi sgt, %34, %c1_i32 : i32
  %71 = tt.addptr %21, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %72 = tt.addptr %30, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %73 = arith.addi %50, %c1_i32 : i32
  %74 = arith.cmpi slt, %73, %c2_i32 : i32
  %75 = arith.select %74, %73, %c0_i32 : i32
  %c32_i32_4 = arith.constant 32 : i32
  %76 = arith.subi %arg8, %c32_i32_4 : i32
  %77 = tt.splat %76 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = arith.cmpi slt, %16, %77 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = tt.broadcast %78 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %80 = arith.andi %37, %79 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = triton_gpu.memdesc_subview %43[%75, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %82 = tt.splat %70 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = arith.andi %82, %80 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = triton_gpu.async_copy_global_to_local %71, %81 mask %83 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %85 = triton_gpu.async_commit_group %84
  %86 = tt.splat %76 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %87 = arith.cmpi slt, %22, %86 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = tt.broadcast %87 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %89 = arith.andi %88, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = triton_gpu.memdesc_subview %44[%75, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %91 = tt.splat %70 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %92 = arith.andi %91, %89 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = triton_gpu.async_copy_global_to_local %72, %90 mask %92 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %94 = triton_gpu.async_commit_group %93
  %95 = arith.addi %c-1_i32, %c1_i32 : i32
  %96 = arith.cmpi slt, %95, %c2_i32 : i32
  %97 = arith.select %96, %95, %c0_i32 : i32
  %98 = triton_gpu.memdesc_subview %43[%97, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %99 = triton_gpu.async_wait %69 {num = 2 : i32}
  %100 = triton_gpu.memdesc_subview %44[%97, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %101:11 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %71, %arg15 = %72, %arg16 = %75, %arg17 = %97, %arg18 = %98, %arg19 = %99, %arg20 = %100, %arg21 = %99, %arg22 = %85, %arg23 = %94) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token)  : i32 {
    %c2_i32_5 = arith.constant 2 : i32
    %125 = arith.subi %34, %c2_i32_5 : i32
    %126 = arith.cmpi slt, %arg12, %125 : i32
    %127 = triton_gpu.local_load %arg18 token %arg19 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %128 = triton_gpu.local_load %arg20 token %arg21 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %129 = triton_gpu.convert_layout %127 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %130 = triton_gpu.convert_layout %128 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %131 = tt.dot %129, %130, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %132 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %133 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %134 = arith.addi %arg16, %c1_i32 : i32
    %135 = arith.cmpi slt, %134, %c2_i32 : i32
    %136 = arith.select %135, %134, %c0_i32 : i32
    %c2_i32_6 = arith.constant 2 : i32
    %137 = arith.addi %arg12, %c2_i32_6 : i32
    %138 = arith.muli %137, %c32_i32 : i32
    %139 = arith.subi %arg8, %138 : i32
    %140 = tt.splat %139 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %141 = arith.cmpi slt, %16, %140 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %142 = tt.broadcast %141 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %143 = arith.andi %37, %142 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %144 = triton_gpu.memdesc_subview %43[%136, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %145 = tt.splat %126 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %146 = arith.andi %145, %143 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %147 = triton_gpu.async_copy_global_to_local %132, %144 mask %146 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %148 = triton_gpu.async_commit_group %147
    %149 = tt.splat %139 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %150 = arith.cmpi slt, %22, %149 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %151 = tt.broadcast %150 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %152 = arith.andi %151, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %153 = triton_gpu.memdesc_subview %44[%136, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %154 = tt.splat %126 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %155 = arith.andi %154, %152 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %156 = triton_gpu.async_copy_global_to_local %133, %153 mask %155 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %157 = triton_gpu.async_commit_group %156
    %158 = arith.addi %arg17, %c1_i32 : i32
    %159 = arith.cmpi slt, %158, %c2_i32 : i32
    %160 = arith.select %159, %158, %c0_i32 : i32
    %161 = triton_gpu.memdesc_subview %43[%160, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %162 = triton_gpu.async_wait %arg23 {num = 2 : i32}
    %163 = triton_gpu.memdesc_subview %44[%160, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    scf.yield %131, %132, %133, %136, %160, %161, %162, %163, %162, %148, %157 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token
  }
  %102 = triton_gpu.async_wait  {num = 0 : i32}
  triton_gpu.local_dealloc %43 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  triton_gpu.local_dealloc %44 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %103 = tt.splat %arg7 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %104 = arith.cmpi slt, %12, %103 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %105 = tt.load %32, %104, %cst_2 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %106 = arith.sitofp %arg4 : i32 to f32
  %107 = tt.splat %106 : f32 -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %108 = arith.mulf %101#0, %107 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %109 = arith.sitofp %arg5 : i32 to f16
  %110 = tt.splat %109 : f16 -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %111 = arith.mulf %105, %110 : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %112 = tt.expand_dims %111 {axis = 0 : i32} : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>> -> tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %113 = arith.extf %112 : tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %114 = tt.broadcast %113 : tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %115 = arith.addf %108, %114 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %116 = arith.truncf %115 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %117 = tt.splat %arg11 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %118 = arith.muli %117, %13 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %119 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %120 = tt.addptr %119, %118 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %121 = tt.broadcast %120 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %122 = tt.addptr %121, %27 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %123 = arith.andi %37, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %124 = triton_gpu.convert_layout %116 : tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.store %122, %124, %123 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.return
}



//===-------------------------------------------===//
Processing operation : 'arith.subi'(0x55bafa41fcf0) {
  %62 = "arith.subi"(%arg8, %61) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> success : operation was folded
//===-------------------------------------------===//
** Replace : 'arith.subi'(0x55bafa41fcf0)
** Modified: 'tt.splat'(0x55bafa431100)
** Modified: 'tt.splat'(0x55bafa364ff0)
** Erase   : 'arith.subi'(0x55bafa41fcf0)
// *** IR Dump After Successful Folding ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c2_i32 = arith.constant 2 : i32
  %c-1_i32 = arith.constant -1 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %c32_i32 = arith.constant 32 : i32
  %c31_i32 = arith.constant 31 : i32
  %cst_1 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %5 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %7 = arith.addi %6, %3 : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %8 = arith.muli %1, %c32_i32 : i32
  %9 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %10 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %11 = arith.addi %9, %4 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %12 = arith.addi %10, %5 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %13 = tt.expand_dims %7 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %14 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %15 = arith.muli %13, %14 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %16 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.broadcast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %18 = tt.broadcast %16 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = arith.addi %17, %18 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %20 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %22 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %23 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %24 = arith.muli %22, %23 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %11 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %26 = tt.broadcast %24 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = tt.broadcast %25 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = arith.addi %26, %27 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %32 = tt.addptr %31, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %33 = arith.addi %arg8, %c31_i32 : i32
  %34 = arith.divsi %33, %c32_i32 : i32
  %35 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = arith.cmpi slt, %13, %35 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = tt.broadcast %36 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %38 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = arith.cmpi slt, %25, %38 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.broadcast %39 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %41 = arith.muli %arg10, %c32_i32 : i32
  %42 = tt.splat %41 : i32 -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %43 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %44 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %45 = arith.muli %c1_i32, %c0_i32 : i32
  %46 = arith.addi %c0_i32, %45 : i32
  %47 = arith.cmpi slt, %46, %34 : i32
  %48 = arith.addi %c-1_i32, %c1_i32 : i32
  %49 = arith.cmpi slt, %48, %c2_i32 : i32
  %50 = arith.select %49, %48, %c0_i32 : i32
  %c0_i32_3 = arith.constant 0 : i32
  %51 = tt.splat %arg8 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = arith.cmpi slt, %16, %51 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %53 = tt.broadcast %52 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = arith.andi %37, %53 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %55 = triton_gpu.memdesc_subview %43[%50, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %56 = tt.splat %47 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = arith.andi %56, %54 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %58 = triton_gpu.async_copy_global_to_local %21, %55 mask %57 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %59 = triton_gpu.async_commit_group %58
  %60 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %61 = arith.cmpi slt, %22, %60 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = tt.broadcast %61 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = arith.andi %62, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %64 = triton_gpu.memdesc_subview %44[%50, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %65 = tt.splat %47 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %66 = arith.andi %65, %63 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = triton_gpu.async_copy_global_to_local %30, %64 mask %66 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %68 = triton_gpu.async_commit_group %67
  %69 = arith.cmpi sgt, %34, %c1_i32 : i32
  %70 = tt.addptr %21, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = tt.addptr %30, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %72 = arith.addi %50, %c1_i32 : i32
  %73 = arith.cmpi slt, %72, %c2_i32 : i32
  %74 = arith.select %73, %72, %c0_i32 : i32
  %c32_i32_4 = arith.constant 32 : i32
  %75 = arith.subi %arg8, %c32_i32_4 : i32
  %76 = tt.splat %75 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %77 = arith.cmpi slt, %16, %76 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = tt.broadcast %77 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = arith.andi %37, %78 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %80 = triton_gpu.memdesc_subview %43[%74, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %81 = tt.splat %69 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = arith.andi %81, %79 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = triton_gpu.async_copy_global_to_local %70, %80 mask %82 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %84 = triton_gpu.async_commit_group %83
  %85 = tt.splat %75 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = arith.cmpi slt, %22, %85 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %87 = tt.broadcast %86 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = arith.andi %87, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %89 = triton_gpu.memdesc_subview %44[%74, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %90 = tt.splat %69 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %91 = arith.andi %90, %88 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %92 = triton_gpu.async_copy_global_to_local %71, %89 mask %91 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %93 = triton_gpu.async_commit_group %92
  %94 = arith.addi %c-1_i32, %c1_i32 : i32
  %95 = arith.cmpi slt, %94, %c2_i32 : i32
  %96 = arith.select %95, %94, %c0_i32 : i32
  %97 = triton_gpu.memdesc_subview %43[%96, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %98 = triton_gpu.async_wait %68 {num = 2 : i32}
  %99 = triton_gpu.memdesc_subview %44[%96, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %100:11 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %70, %arg15 = %71, %arg16 = %74, %arg17 = %96, %arg18 = %97, %arg19 = %98, %arg20 = %99, %arg21 = %98, %arg22 = %84, %arg23 = %93) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token)  : i32 {
    %c2_i32_5 = arith.constant 2 : i32
    %124 = arith.subi %34, %c2_i32_5 : i32
    %125 = arith.cmpi slt, %arg12, %124 : i32
    %126 = triton_gpu.local_load %arg18 token %arg19 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %127 = triton_gpu.local_load %arg20 token %arg21 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %128 = triton_gpu.convert_layout %126 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %129 = triton_gpu.convert_layout %127 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %130 = tt.dot %128, %129, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %131 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %132 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %133 = arith.addi %arg16, %c1_i32 : i32
    %134 = arith.cmpi slt, %133, %c2_i32 : i32
    %135 = arith.select %134, %133, %c0_i32 : i32
    %c2_i32_6 = arith.constant 2 : i32
    %136 = arith.addi %arg12, %c2_i32_6 : i32
    %137 = arith.muli %136, %c32_i32 : i32
    %138 = arith.subi %arg8, %137 : i32
    %139 = tt.splat %138 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %140 = arith.cmpi slt, %16, %139 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %141 = tt.broadcast %140 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %142 = arith.andi %37, %141 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %143 = triton_gpu.memdesc_subview %43[%135, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %144 = tt.splat %125 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %145 = arith.andi %144, %142 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %146 = triton_gpu.async_copy_global_to_local %131, %143 mask %145 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %147 = triton_gpu.async_commit_group %146
    %148 = tt.splat %138 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = arith.cmpi slt, %22, %148 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %150 = tt.broadcast %149 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %151 = arith.andi %150, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %152 = triton_gpu.memdesc_subview %44[%135, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %153 = tt.splat %125 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %154 = arith.andi %153, %151 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %155 = triton_gpu.async_copy_global_to_local %132, %152 mask %154 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %156 = triton_gpu.async_commit_group %155
    %157 = arith.addi %arg17, %c1_i32 : i32
    %158 = arith.cmpi slt, %157, %c2_i32 : i32
    %159 = arith.select %158, %157, %c0_i32 : i32
    %160 = triton_gpu.memdesc_subview %43[%159, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %161 = triton_gpu.async_wait %arg23 {num = 2 : i32}
    %162 = triton_gpu.memdesc_subview %44[%159, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    scf.yield %130, %131, %132, %135, %159, %160, %161, %162, %161, %147, %156 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token
  }
  %101 = triton_gpu.async_wait  {num = 0 : i32}
  triton_gpu.local_dealloc %43 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  triton_gpu.local_dealloc %44 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %102 = tt.splat %arg7 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %103 = arith.cmpi slt, %12, %102 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %104 = tt.load %32, %103, %cst_2 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %105 = arith.sitofp %arg4 : i32 to f32
  %106 = tt.splat %105 : f32 -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %107 = arith.mulf %100#0, %106 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %108 = arith.sitofp %arg5 : i32 to f16
  %109 = tt.splat %108 : f16 -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %110 = arith.mulf %104, %109 : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %111 = tt.expand_dims %110 {axis = 0 : i32} : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>> -> tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %112 = arith.extf %111 : tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %113 = tt.broadcast %112 : tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %114 = arith.addf %107, %113 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %115 = arith.truncf %114 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %116 = tt.splat %arg11 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %117 = arith.muli %116, %13 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %118 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %119 = tt.addptr %118, %117 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %120 = tt.broadcast %119 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %121 = tt.addptr %120, %27 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %122 = arith.andi %37, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %123 = triton_gpu.convert_layout %115 : tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.store %121, %123, %122 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.return
}



//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa364ff0) {
  %62 = "tt.splat"(%arg8) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa431100) {
  %71 = "tt.splat"(%arg8) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.constant'(0x55bafa3b9e50) {
  %61 = "arith.constant"() <{value = 0 : i32}> : () -> i32

  ** Erase   : 'arith.constant'(0x55bafa3b9e50)
} -> success : operation is trivially dead
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa3ceec0) {
  %57 = "arith.cmpi"(%56, %44) <{predicate = 2 : i64}> : (i32, i32) -> i1

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.addi'(0x55bafa3cee10) {
  %56 = "arith.addi"(%3, %55) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> success : operation was folded
//===-------------------------------------------===//
** Modified: 'arith.addi'(0x55bafa3cee10)
// *** IR Dump After Successful Folding ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c2_i32 = arith.constant 2 : i32
  %c-1_i32 = arith.constant -1 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %c32_i32 = arith.constant 32 : i32
  %c31_i32 = arith.constant 31 : i32
  %cst_1 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %5 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %7 = arith.addi %6, %3 : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %8 = arith.muli %1, %c32_i32 : i32
  %9 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %10 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %11 = arith.addi %9, %4 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %12 = arith.addi %10, %5 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %13 = tt.expand_dims %7 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %14 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %15 = arith.muli %13, %14 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %16 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.broadcast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %18 = tt.broadcast %16 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = arith.addi %17, %18 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %20 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %22 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %23 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %24 = arith.muli %22, %23 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %11 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %26 = tt.broadcast %24 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = tt.broadcast %25 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = arith.addi %26, %27 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %32 = tt.addptr %31, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %33 = arith.addi %arg8, %c31_i32 : i32
  %34 = arith.divsi %33, %c32_i32 : i32
  %35 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = arith.cmpi slt, %13, %35 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = tt.broadcast %36 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %38 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = arith.cmpi slt, %25, %38 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.broadcast %39 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %41 = arith.muli %arg10, %c32_i32 : i32
  %42 = tt.splat %41 : i32 -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %43 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %44 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %45 = arith.muli %c1_i32, %c0_i32 : i32
  %46 = arith.addi %45, %c0_i32 : i32
  %47 = arith.cmpi slt, %46, %34 : i32
  %48 = arith.addi %c-1_i32, %c1_i32 : i32
  %49 = arith.cmpi slt, %48, %c2_i32 : i32
  %50 = arith.select %49, %48, %c0_i32 : i32
  %51 = tt.splat %arg8 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = arith.cmpi slt, %16, %51 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %53 = tt.broadcast %52 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = arith.andi %37, %53 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %55 = triton_gpu.memdesc_subview %43[%50, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %56 = tt.splat %47 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = arith.andi %56, %54 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %58 = triton_gpu.async_copy_global_to_local %21, %55 mask %57 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %59 = triton_gpu.async_commit_group %58
  %60 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %61 = arith.cmpi slt, %22, %60 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = tt.broadcast %61 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = arith.andi %62, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %64 = triton_gpu.memdesc_subview %44[%50, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %65 = tt.splat %47 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %66 = arith.andi %65, %63 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = triton_gpu.async_copy_global_to_local %30, %64 mask %66 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %68 = triton_gpu.async_commit_group %67
  %69 = arith.cmpi sgt, %34, %c1_i32 : i32
  %70 = tt.addptr %21, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = tt.addptr %30, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %72 = arith.addi %50, %c1_i32 : i32
  %73 = arith.cmpi slt, %72, %c2_i32 : i32
  %74 = arith.select %73, %72, %c0_i32 : i32
  %c32_i32_3 = arith.constant 32 : i32
  %75 = arith.subi %arg8, %c32_i32_3 : i32
  %76 = tt.splat %75 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %77 = arith.cmpi slt, %16, %76 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = tt.broadcast %77 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = arith.andi %37, %78 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %80 = triton_gpu.memdesc_subview %43[%74, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %81 = tt.splat %69 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = arith.andi %81, %79 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = triton_gpu.async_copy_global_to_local %70, %80 mask %82 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %84 = triton_gpu.async_commit_group %83
  %85 = tt.splat %75 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = arith.cmpi slt, %22, %85 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %87 = tt.broadcast %86 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = arith.andi %87, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %89 = triton_gpu.memdesc_subview %44[%74, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %90 = tt.splat %69 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %91 = arith.andi %90, %88 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %92 = triton_gpu.async_copy_global_to_local %71, %89 mask %91 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %93 = triton_gpu.async_commit_group %92
  %94 = arith.addi %c-1_i32, %c1_i32 : i32
  %95 = arith.cmpi slt, %94, %c2_i32 : i32
  %96 = arith.select %95, %94, %c0_i32 : i32
  %97 = triton_gpu.memdesc_subview %43[%96, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %98 = triton_gpu.async_wait %68 {num = 2 : i32}
  %99 = triton_gpu.memdesc_subview %44[%96, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %100:11 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %70, %arg15 = %71, %arg16 = %74, %arg17 = %96, %arg18 = %97, %arg19 = %98, %arg20 = %99, %arg21 = %98, %arg22 = %84, %arg23 = %93) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token)  : i32 {
    %c2_i32_4 = arith.constant 2 : i32
    %124 = arith.subi %34, %c2_i32_4 : i32
    %125 = arith.cmpi slt, %arg12, %124 : i32
    %126 = triton_gpu.local_load %arg18 token %arg19 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %127 = triton_gpu.local_load %arg20 token %arg21 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %128 = triton_gpu.convert_layout %126 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %129 = triton_gpu.convert_layout %127 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %130 = tt.dot %128, %129, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %131 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %132 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %133 = arith.addi %arg16, %c1_i32 : i32
    %134 = arith.cmpi slt, %133, %c2_i32 : i32
    %135 = arith.select %134, %133, %c0_i32 : i32
    %c2_i32_5 = arith.constant 2 : i32
    %136 = arith.addi %arg12, %c2_i32_5 : i32
    %137 = arith.muli %136, %c32_i32 : i32
    %138 = arith.subi %arg8, %137 : i32
    %139 = tt.splat %138 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %140 = arith.cmpi slt, %16, %139 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %141 = tt.broadcast %140 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %142 = arith.andi %37, %141 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %143 = triton_gpu.memdesc_subview %43[%135, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %144 = tt.splat %125 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %145 = arith.andi %144, %142 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %146 = triton_gpu.async_copy_global_to_local %131, %143 mask %145 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %147 = triton_gpu.async_commit_group %146
    %148 = tt.splat %138 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = arith.cmpi slt, %22, %148 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %150 = tt.broadcast %149 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %151 = arith.andi %150, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %152 = triton_gpu.memdesc_subview %44[%135, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %153 = tt.splat %125 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %154 = arith.andi %153, %151 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %155 = triton_gpu.async_copy_global_to_local %132, %152 mask %154 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %156 = triton_gpu.async_commit_group %155
    %157 = arith.addi %arg17, %c1_i32 : i32
    %158 = arith.cmpi slt, %157, %c2_i32 : i32
    %159 = arith.select %158, %157, %c0_i32 : i32
    %160 = triton_gpu.memdesc_subview %43[%159, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %161 = triton_gpu.async_wait %arg23 {num = 2 : i32}
    %162 = triton_gpu.memdesc_subview %44[%159, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    scf.yield %130, %131, %132, %135, %159, %160, %161, %162, %161, %147, %156 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token
  }
  %101 = triton_gpu.async_wait  {num = 0 : i32}
  triton_gpu.local_dealloc %43 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  triton_gpu.local_dealloc %44 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %102 = tt.splat %arg7 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %103 = arith.cmpi slt, %12, %102 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %104 = tt.load %32, %103, %cst_2 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %105 = arith.sitofp %arg4 : i32 to f32
  %106 = tt.splat %105 : f32 -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %107 = arith.mulf %100#0, %106 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %108 = arith.sitofp %arg5 : i32 to f16
  %109 = tt.splat %108 : f16 -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %110 = arith.mulf %104, %109 : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %111 = tt.expand_dims %110 {axis = 0 : i32} : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>> -> tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %112 = arith.extf %111 : tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %113 = tt.broadcast %112 : tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %114 = arith.addf %107, %113 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %115 = arith.truncf %114 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %116 = tt.splat %arg11 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %117 = arith.muli %116, %13 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %118 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %119 = tt.addptr %118, %117 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %120 = tt.broadcast %119 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %121 = tt.addptr %120, %27 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %122 = arith.andi %37, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %123 = triton_gpu.convert_layout %115 : tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.store %121, %123, %122 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.return
}



//===-------------------------------------------===//
Processing operation : 'arith.addi'(0x55bafa3cee10) {
  %56 = "arith.addi"(%55, %3) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> success : operation was folded
//===-------------------------------------------===//
** Replace : 'arith.addi'(0x55bafa3cee10)
** Modified: 'arith.cmpi'(0x55bafa3ceec0)
** Erase   : 'arith.addi'(0x55bafa3cee10)
// *** IR Dump After Successful Folding ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c2_i32 = arith.constant 2 : i32
  %c-1_i32 = arith.constant -1 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %c32_i32 = arith.constant 32 : i32
  %c31_i32 = arith.constant 31 : i32
  %cst_1 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %5 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %7 = arith.addi %6, %3 : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %8 = arith.muli %1, %c32_i32 : i32
  %9 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %10 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %11 = arith.addi %9, %4 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %12 = arith.addi %10, %5 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %13 = tt.expand_dims %7 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %14 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %15 = arith.muli %13, %14 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %16 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.broadcast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %18 = tt.broadcast %16 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = arith.addi %17, %18 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %20 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %22 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %23 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %24 = arith.muli %22, %23 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %11 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %26 = tt.broadcast %24 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = tt.broadcast %25 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = arith.addi %26, %27 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %32 = tt.addptr %31, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %33 = arith.addi %arg8, %c31_i32 : i32
  %34 = arith.divsi %33, %c32_i32 : i32
  %35 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = arith.cmpi slt, %13, %35 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = tt.broadcast %36 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %38 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = arith.cmpi slt, %25, %38 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.broadcast %39 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %41 = arith.muli %arg10, %c32_i32 : i32
  %42 = tt.splat %41 : i32 -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %43 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %44 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %45 = arith.muli %c1_i32, %c0_i32 : i32
  %46 = arith.cmpi slt, %45, %34 : i32
  %47 = arith.addi %c-1_i32, %c1_i32 : i32
  %48 = arith.cmpi slt, %47, %c2_i32 : i32
  %49 = arith.select %48, %47, %c0_i32 : i32
  %50 = tt.splat %arg8 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %51 = arith.cmpi slt, %16, %50 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = tt.broadcast %51 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %53 = arith.andi %37, %52 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = triton_gpu.memdesc_subview %43[%49, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %55 = tt.splat %46 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = arith.andi %55, %53 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = triton_gpu.async_copy_global_to_local %21, %54 mask %56 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %58 = triton_gpu.async_commit_group %57
  %59 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = arith.cmpi slt, %22, %59 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %61 = tt.broadcast %60 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = arith.andi %61, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = triton_gpu.memdesc_subview %44[%49, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %64 = tt.splat %46 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = arith.andi %64, %62 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %66 = triton_gpu.async_copy_global_to_local %30, %63 mask %65 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %67 = triton_gpu.async_commit_group %66
  %68 = arith.cmpi sgt, %34, %c1_i32 : i32
  %69 = tt.addptr %21, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = tt.addptr %30, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = arith.addi %49, %c1_i32 : i32
  %72 = arith.cmpi slt, %71, %c2_i32 : i32
  %73 = arith.select %72, %71, %c0_i32 : i32
  %c32_i32_3 = arith.constant 32 : i32
  %74 = arith.subi %arg8, %c32_i32_3 : i32
  %75 = tt.splat %74 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %76 = arith.cmpi slt, %16, %75 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %77 = tt.broadcast %76 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = arith.andi %37, %77 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = triton_gpu.memdesc_subview %43[%73, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %80 = tt.splat %68 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = arith.andi %80, %78 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = triton_gpu.async_copy_global_to_local %69, %79 mask %81 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %83 = triton_gpu.async_commit_group %82
  %84 = tt.splat %74 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %85 = arith.cmpi slt, %22, %84 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = tt.broadcast %85 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %87 = arith.andi %86, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = triton_gpu.memdesc_subview %44[%73, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %89 = tt.splat %68 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = arith.andi %89, %87 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %91 = triton_gpu.async_copy_global_to_local %70, %88 mask %90 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %92 = triton_gpu.async_commit_group %91
  %93 = arith.addi %c-1_i32, %c1_i32 : i32
  %94 = arith.cmpi slt, %93, %c2_i32 : i32
  %95 = arith.select %94, %93, %c0_i32 : i32
  %96 = triton_gpu.memdesc_subview %43[%95, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %97 = triton_gpu.async_wait %67 {num = 2 : i32}
  %98 = triton_gpu.memdesc_subview %44[%95, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %99:11 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %69, %arg15 = %70, %arg16 = %73, %arg17 = %95, %arg18 = %96, %arg19 = %97, %arg20 = %98, %arg21 = %97, %arg22 = %83, %arg23 = %92) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token)  : i32 {
    %c2_i32_4 = arith.constant 2 : i32
    %123 = arith.subi %34, %c2_i32_4 : i32
    %124 = arith.cmpi slt, %arg12, %123 : i32
    %125 = triton_gpu.local_load %arg18 token %arg19 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %126 = triton_gpu.local_load %arg20 token %arg21 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %127 = triton_gpu.convert_layout %125 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %128 = triton_gpu.convert_layout %126 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %129 = tt.dot %127, %128, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %130 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %131 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %132 = arith.addi %arg16, %c1_i32 : i32
    %133 = arith.cmpi slt, %132, %c2_i32 : i32
    %134 = arith.select %133, %132, %c0_i32 : i32
    %c2_i32_5 = arith.constant 2 : i32
    %135 = arith.addi %arg12, %c2_i32_5 : i32
    %136 = arith.muli %135, %c32_i32 : i32
    %137 = arith.subi %arg8, %136 : i32
    %138 = tt.splat %137 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %139 = arith.cmpi slt, %16, %138 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %140 = tt.broadcast %139 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %141 = arith.andi %37, %140 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %142 = triton_gpu.memdesc_subview %43[%134, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %143 = tt.splat %124 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %144 = arith.andi %143, %141 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %145 = triton_gpu.async_copy_global_to_local %130, %142 mask %144 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %146 = triton_gpu.async_commit_group %145
    %147 = tt.splat %137 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %148 = arith.cmpi slt, %22, %147 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = tt.broadcast %148 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %150 = arith.andi %149, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %151 = triton_gpu.memdesc_subview %44[%134, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %152 = tt.splat %124 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %153 = arith.andi %152, %150 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %154 = triton_gpu.async_copy_global_to_local %131, %151 mask %153 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %155 = triton_gpu.async_commit_group %154
    %156 = arith.addi %arg17, %c1_i32 : i32
    %157 = arith.cmpi slt, %156, %c2_i32 : i32
    %158 = arith.select %157, %156, %c0_i32 : i32
    %159 = triton_gpu.memdesc_subview %43[%158, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %160 = triton_gpu.async_wait %arg23 {num = 2 : i32}
    %161 = triton_gpu.memdesc_subview %44[%158, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    scf.yield %129, %130, %131, %134, %158, %159, %160, %161, %160, %146, %155 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token
  }
  %100 = triton_gpu.async_wait  {num = 0 : i32}
  triton_gpu.local_dealloc %43 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  triton_gpu.local_dealloc %44 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %101 = tt.splat %arg7 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %102 = arith.cmpi slt, %12, %101 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %103 = tt.load %32, %102, %cst_2 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %104 = arith.sitofp %arg4 : i32 to f32
  %105 = tt.splat %104 : f32 -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %106 = arith.mulf %99#0, %105 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %107 = arith.sitofp %arg5 : i32 to f16
  %108 = tt.splat %107 : f16 -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %109 = arith.mulf %103, %108 : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %110 = tt.expand_dims %109 {axis = 0 : i32} : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>> -> tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %111 = arith.extf %110 : tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %112 = tt.broadcast %111 : tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %113 = arith.addf %106, %112 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %114 = arith.truncf %113 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %115 = tt.splat %arg11 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %116 = arith.muli %115, %13 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %117 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %118 = tt.addptr %117, %116 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %119 = tt.broadcast %118 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %120 = tt.addptr %119, %27 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %121 = arith.andi %37, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %122 = triton_gpu.convert_layout %114 : tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.store %120, %122, %121 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.return
}



//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa3ceec0) {
  %56 = "arith.cmpi"(%55, %44) <{predicate = 2 : i64}> : (i32, i32) -> i1

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.muli'(0x55bafa4306f0) {
  %55 = "arith.muli"(%4, %3) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> success : operation was folded
//===-------------------------------------------===//
** Replace : 'arith.muli'(0x55bafa4306f0)
** Modified: 'arith.cmpi'(0x55bafa3ceec0)
** Erase   : 'arith.muli'(0x55bafa4306f0)
// *** IR Dump After Successful Folding ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c2_i32 = arith.constant 2 : i32
  %c-1_i32 = arith.constant -1 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %c32_i32 = arith.constant 32 : i32
  %c31_i32 = arith.constant 31 : i32
  %cst_1 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %5 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %7 = arith.addi %6, %3 : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %8 = arith.muli %1, %c32_i32 : i32
  %9 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %10 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %11 = arith.addi %9, %4 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %12 = arith.addi %10, %5 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %13 = tt.expand_dims %7 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %14 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %15 = arith.muli %13, %14 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %16 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.broadcast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %18 = tt.broadcast %16 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = arith.addi %17, %18 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %20 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %22 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %23 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %24 = arith.muli %22, %23 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %11 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %26 = tt.broadcast %24 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = tt.broadcast %25 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = arith.addi %26, %27 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %32 = tt.addptr %31, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %33 = arith.addi %arg8, %c31_i32 : i32
  %34 = arith.divsi %33, %c32_i32 : i32
  %35 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = arith.cmpi slt, %13, %35 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = tt.broadcast %36 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %38 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = arith.cmpi slt, %25, %38 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.broadcast %39 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %41 = arith.muli %arg10, %c32_i32 : i32
  %42 = tt.splat %41 : i32 -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %43 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %44 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %45 = arith.cmpi slt, %c0_i32, %34 : i32
  %46 = arith.addi %c-1_i32, %c1_i32 : i32
  %47 = arith.cmpi slt, %46, %c2_i32 : i32
  %48 = arith.select %47, %46, %c0_i32 : i32
  %49 = tt.splat %arg8 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %50 = arith.cmpi slt, %16, %49 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %51 = tt.broadcast %50 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = arith.andi %37, %51 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %53 = triton_gpu.memdesc_subview %43[%48, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %54 = tt.splat %45 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %55 = arith.andi %54, %52 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = triton_gpu.async_copy_global_to_local %21, %53 mask %55 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %57 = triton_gpu.async_commit_group %56
  %58 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = arith.cmpi slt, %22, %58 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = tt.broadcast %59 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %61 = arith.andi %60, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = triton_gpu.memdesc_subview %44[%48, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %63 = tt.splat %45 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %64 = arith.andi %63, %61 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = triton_gpu.async_copy_global_to_local %30, %62 mask %64 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %66 = triton_gpu.async_commit_group %65
  %67 = arith.cmpi sgt, %34, %c1_i32 : i32
  %68 = tt.addptr %21, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = tt.addptr %30, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = arith.addi %48, %c1_i32 : i32
  %71 = arith.cmpi slt, %70, %c2_i32 : i32
  %72 = arith.select %71, %70, %c0_i32 : i32
  %c32_i32_3 = arith.constant 32 : i32
  %73 = arith.subi %arg8, %c32_i32_3 : i32
  %74 = tt.splat %73 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = arith.cmpi slt, %16, %74 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %76 = tt.broadcast %75 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %77 = arith.andi %37, %76 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = triton_gpu.memdesc_subview %43[%72, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %79 = tt.splat %67 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %80 = arith.andi %79, %77 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = triton_gpu.async_copy_global_to_local %68, %78 mask %80 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %82 = triton_gpu.async_commit_group %81
  %83 = tt.splat %73 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = arith.cmpi slt, %22, %83 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %85 = tt.broadcast %84 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = arith.andi %85, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %87 = triton_gpu.memdesc_subview %44[%72, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %88 = tt.splat %67 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %89 = arith.andi %88, %86 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = triton_gpu.async_copy_global_to_local %69, %87 mask %89 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %91 = triton_gpu.async_commit_group %90
  %92 = arith.addi %c-1_i32, %c1_i32 : i32
  %93 = arith.cmpi slt, %92, %c2_i32 : i32
  %94 = arith.select %93, %92, %c0_i32 : i32
  %95 = triton_gpu.memdesc_subview %43[%94, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %96 = triton_gpu.async_wait %66 {num = 2 : i32}
  %97 = triton_gpu.memdesc_subview %44[%94, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %98:11 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %68, %arg15 = %69, %arg16 = %72, %arg17 = %94, %arg18 = %95, %arg19 = %96, %arg20 = %97, %arg21 = %96, %arg22 = %82, %arg23 = %91) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token)  : i32 {
    %c2_i32_4 = arith.constant 2 : i32
    %122 = arith.subi %34, %c2_i32_4 : i32
    %123 = arith.cmpi slt, %arg12, %122 : i32
    %124 = triton_gpu.local_load %arg18 token %arg19 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %125 = triton_gpu.local_load %arg20 token %arg21 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %126 = triton_gpu.convert_layout %124 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %127 = triton_gpu.convert_layout %125 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %128 = tt.dot %126, %127, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %129 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %130 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %131 = arith.addi %arg16, %c1_i32 : i32
    %132 = arith.cmpi slt, %131, %c2_i32 : i32
    %133 = arith.select %132, %131, %c0_i32 : i32
    %c2_i32_5 = arith.constant 2 : i32
    %134 = arith.addi %arg12, %c2_i32_5 : i32
    %135 = arith.muli %134, %c32_i32 : i32
    %136 = arith.subi %arg8, %135 : i32
    %137 = tt.splat %136 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %138 = arith.cmpi slt, %16, %137 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %139 = tt.broadcast %138 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %140 = arith.andi %37, %139 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %141 = triton_gpu.memdesc_subview %43[%133, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %142 = tt.splat %123 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %143 = arith.andi %142, %140 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %144 = triton_gpu.async_copy_global_to_local %129, %141 mask %143 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %145 = triton_gpu.async_commit_group %144
    %146 = tt.splat %136 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %147 = arith.cmpi slt, %22, %146 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %148 = tt.broadcast %147 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = arith.andi %148, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %150 = triton_gpu.memdesc_subview %44[%133, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %151 = tt.splat %123 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %152 = arith.andi %151, %149 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %153 = triton_gpu.async_copy_global_to_local %130, %150 mask %152 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %154 = triton_gpu.async_commit_group %153
    %155 = arith.addi %arg17, %c1_i32 : i32
    %156 = arith.cmpi slt, %155, %c2_i32 : i32
    %157 = arith.select %156, %155, %c0_i32 : i32
    %158 = triton_gpu.memdesc_subview %43[%157, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %159 = triton_gpu.async_wait %arg23 {num = 2 : i32}
    %160 = triton_gpu.memdesc_subview %44[%157, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    scf.yield %128, %129, %130, %133, %157, %158, %159, %160, %159, %145, %154 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token
  }
  %99 = triton_gpu.async_wait  {num = 0 : i32}
  triton_gpu.local_dealloc %43 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  triton_gpu.local_dealloc %44 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %100 = tt.splat %arg7 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %101 = arith.cmpi slt, %12, %100 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %102 = tt.load %32, %101, %cst_2 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %103 = arith.sitofp %arg4 : i32 to f32
  %104 = tt.splat %103 : f32 -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %105 = arith.mulf %98#0, %104 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %106 = arith.sitofp %arg5 : i32 to f16
  %107 = tt.splat %106 : f16 -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %108 = arith.mulf %102, %107 : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %109 = tt.expand_dims %108 {axis = 0 : i32} : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>> -> tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %110 = arith.extf %109 : tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %111 = tt.broadcast %110 : tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %112 = arith.addf %105, %111 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %113 = arith.truncf %112 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %114 = tt.splat %arg11 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %115 = arith.muli %114, %13 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %116 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %117 = tt.addptr %116, %115 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %118 = tt.broadcast %117 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %119 = tt.addptr %118, %27 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %120 = arith.andi %37, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %121 = triton_gpu.convert_layout %113 : tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.store %119, %121, %120 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.return
}



//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa3ceec0) {
  %55 = "arith.cmpi"(%3, %44) <{predicate = 2 : i64}> : (i32, i32) -> i1

} -> success : operation was folded
//===-------------------------------------------===//
** Modified: 'arith.cmpi'(0x55bafa3ceec0)
// *** IR Dump After Successful Folding ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c2_i32 = arith.constant 2 : i32
  %c-1_i32 = arith.constant -1 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %c32_i32 = arith.constant 32 : i32
  %c31_i32 = arith.constant 31 : i32
  %cst_1 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %5 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %7 = arith.addi %6, %3 : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %8 = arith.muli %1, %c32_i32 : i32
  %9 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %10 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %11 = arith.addi %9, %4 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %12 = arith.addi %10, %5 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %13 = tt.expand_dims %7 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %14 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %15 = arith.muli %13, %14 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %16 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.broadcast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %18 = tt.broadcast %16 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = arith.addi %17, %18 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %20 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %22 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %23 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %24 = arith.muli %22, %23 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %11 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %26 = tt.broadcast %24 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = tt.broadcast %25 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = arith.addi %26, %27 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %32 = tt.addptr %31, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %33 = arith.addi %arg8, %c31_i32 : i32
  %34 = arith.divsi %33, %c32_i32 : i32
  %35 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = arith.cmpi slt, %13, %35 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = tt.broadcast %36 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %38 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = arith.cmpi slt, %25, %38 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.broadcast %39 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %41 = arith.muli %arg10, %c32_i32 : i32
  %42 = tt.splat %41 : i32 -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %43 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %44 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %45 = arith.cmpi sgt, %34, %c0_i32 : i32
  %46 = arith.addi %c-1_i32, %c1_i32 : i32
  %47 = arith.cmpi slt, %46, %c2_i32 : i32
  %48 = arith.select %47, %46, %c0_i32 : i32
  %49 = tt.splat %arg8 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %50 = arith.cmpi slt, %16, %49 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %51 = tt.broadcast %50 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = arith.andi %37, %51 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %53 = triton_gpu.memdesc_subview %43[%48, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %54 = tt.splat %45 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %55 = arith.andi %54, %52 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = triton_gpu.async_copy_global_to_local %21, %53 mask %55 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %57 = triton_gpu.async_commit_group %56
  %58 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = arith.cmpi slt, %22, %58 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = tt.broadcast %59 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %61 = arith.andi %60, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = triton_gpu.memdesc_subview %44[%48, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %63 = tt.splat %45 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %64 = arith.andi %63, %61 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = triton_gpu.async_copy_global_to_local %30, %62 mask %64 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %66 = triton_gpu.async_commit_group %65
  %67 = arith.cmpi sgt, %34, %c1_i32 : i32
  %68 = tt.addptr %21, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = tt.addptr %30, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = arith.addi %48, %c1_i32 : i32
  %71 = arith.cmpi slt, %70, %c2_i32 : i32
  %72 = arith.select %71, %70, %c0_i32 : i32
  %c32_i32_3 = arith.constant 32 : i32
  %73 = arith.subi %arg8, %c32_i32_3 : i32
  %74 = tt.splat %73 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = arith.cmpi slt, %16, %74 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %76 = tt.broadcast %75 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %77 = arith.andi %37, %76 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = triton_gpu.memdesc_subview %43[%72, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %79 = tt.splat %67 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %80 = arith.andi %79, %77 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = triton_gpu.async_copy_global_to_local %68, %78 mask %80 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %82 = triton_gpu.async_commit_group %81
  %83 = tt.splat %73 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = arith.cmpi slt, %22, %83 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %85 = tt.broadcast %84 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = arith.andi %85, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %87 = triton_gpu.memdesc_subview %44[%72, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %88 = tt.splat %67 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %89 = arith.andi %88, %86 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = triton_gpu.async_copy_global_to_local %69, %87 mask %89 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %91 = triton_gpu.async_commit_group %90
  %92 = arith.addi %c-1_i32, %c1_i32 : i32
  %93 = arith.cmpi slt, %92, %c2_i32 : i32
  %94 = arith.select %93, %92, %c0_i32 : i32
  %95 = triton_gpu.memdesc_subview %43[%94, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %96 = triton_gpu.async_wait %66 {num = 2 : i32}
  %97 = triton_gpu.memdesc_subview %44[%94, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %98:11 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %68, %arg15 = %69, %arg16 = %72, %arg17 = %94, %arg18 = %95, %arg19 = %96, %arg20 = %97, %arg21 = %96, %arg22 = %82, %arg23 = %91) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token)  : i32 {
    %c2_i32_4 = arith.constant 2 : i32
    %122 = arith.subi %34, %c2_i32_4 : i32
    %123 = arith.cmpi slt, %arg12, %122 : i32
    %124 = triton_gpu.local_load %arg18 token %arg19 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %125 = triton_gpu.local_load %arg20 token %arg21 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %126 = triton_gpu.convert_layout %124 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %127 = triton_gpu.convert_layout %125 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %128 = tt.dot %126, %127, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %129 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %130 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %131 = arith.addi %arg16, %c1_i32 : i32
    %132 = arith.cmpi slt, %131, %c2_i32 : i32
    %133 = arith.select %132, %131, %c0_i32 : i32
    %c2_i32_5 = arith.constant 2 : i32
    %134 = arith.addi %arg12, %c2_i32_5 : i32
    %135 = arith.muli %134, %c32_i32 : i32
    %136 = arith.subi %arg8, %135 : i32
    %137 = tt.splat %136 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %138 = arith.cmpi slt, %16, %137 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %139 = tt.broadcast %138 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %140 = arith.andi %37, %139 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %141 = triton_gpu.memdesc_subview %43[%133, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %142 = tt.splat %123 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %143 = arith.andi %142, %140 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %144 = triton_gpu.async_copy_global_to_local %129, %141 mask %143 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %145 = triton_gpu.async_commit_group %144
    %146 = tt.splat %136 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %147 = arith.cmpi slt, %22, %146 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %148 = tt.broadcast %147 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = arith.andi %148, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %150 = triton_gpu.memdesc_subview %44[%133, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %151 = tt.splat %123 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %152 = arith.andi %151, %149 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %153 = triton_gpu.async_copy_global_to_local %130, %150 mask %152 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %154 = triton_gpu.async_commit_group %153
    %155 = arith.addi %arg17, %c1_i32 : i32
    %156 = arith.cmpi slt, %155, %c2_i32 : i32
    %157 = arith.select %156, %155, %c0_i32 : i32
    %158 = triton_gpu.memdesc_subview %43[%157, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %159 = triton_gpu.async_wait %arg23 {num = 2 : i32}
    %160 = triton_gpu.memdesc_subview %44[%157, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    scf.yield %128, %129, %130, %133, %157, %158, %159, %160, %159, %145, %154 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token
  }
  %99 = triton_gpu.async_wait  {num = 0 : i32}
  triton_gpu.local_dealloc %43 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  triton_gpu.local_dealloc %44 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %100 = tt.splat %arg7 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %101 = arith.cmpi slt, %12, %100 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %102 = tt.load %32, %101, %cst_2 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %103 = arith.sitofp %arg4 : i32 to f32
  %104 = tt.splat %103 : f32 -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %105 = arith.mulf %98#0, %104 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %106 = arith.sitofp %arg5 : i32 to f16
  %107 = tt.splat %106 : f16 -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %108 = arith.mulf %102, %107 : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %109 = tt.expand_dims %108 {axis = 0 : i32} : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>> -> tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %110 = arith.extf %109 : tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %111 = tt.broadcast %110 : tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %112 = arith.addf %105, %111 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %113 = arith.truncf %112 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %114 = tt.splat %arg11 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %115 = arith.muli %114, %13 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %116 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %117 = tt.addptr %116, %115 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %118 = tt.broadcast %117 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %119 = tt.addptr %118, %27 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %120 = arith.andi %37, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %121 = triton_gpu.convert_layout %113 : tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.store %119, %121, %120 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.return
}



//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa3ceec0) {
  %55 = "arith.cmpi"(%44, %3) <{predicate = 4 : i64}> : (i32, i32) -> i1

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.memdesc_subview'(0x55bafa4272b0) {
  %72 = "triton_gpu.memdesc_subview"(%54, %58, %3, %3) : (!tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, i32, i32, i32) -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.memdesc_subview'(0x55bafa3885c0) {
  %98 = "triton_gpu.memdesc_subview"(%54, %82, %3, %3) : (!tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, i32, i32, i32) -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.memdesc_subview'(0x55bafa428200) {
  %108 = "triton_gpu.memdesc_subview"(%54, %105, %3, %3) : (!tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, i32, i32, i32) -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.memdesc_subview'(0x55bafa432900) {
  %163 = "triton_gpu.memdesc_subview"(%54, %145, %3, %3) : (!tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, i32, i32, i32) -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.memdesc_subview'(0x55bafa41df90) {
  %173 = "triton_gpu.memdesc_subview"(%54, %170, %3, %3) : (!tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, i32, i32, i32) -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.memdesc_subview'(0x55bafa364a60) {
  %63 = "triton_gpu.memdesc_subview"(%53, %58, %3, %3) : (!tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, i32, i32, i32) -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.memdesc_subview'(0x55bafa424940) {
  %89 = "triton_gpu.memdesc_subview"(%53, %82, %3, %3) : (!tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, i32, i32, i32) -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.memdesc_subview'(0x55bafa428080) {
  %106 = "triton_gpu.memdesc_subview"(%53, %105, %3, %3) : (!tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, i32, i32, i32) -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.memdesc_subview'(0x55bafa4322b0) {
  %154 = "triton_gpu.memdesc_subview"(%53, %145, %3, %3) : (!tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, i32, i32, i32) -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.memdesc_subview'(0x55bafa41de10) {
  %171 = "triton_gpu.memdesc_subview"(%53, %170, %3, %3) : (!tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, i32, i32, i32) -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.constant'(0x55bafa427410) {
  %0 = "arith.constant"() <{value = 2 : i32}> : () -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.addi'(0x55bafa33b640) {
  %56 = "arith.addi"(%1, %4) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> success : operation was folded
//===-------------------------------------------===//
** Insert  : 'arith.constant'(0x55bafa3b9e50)
** Replace : 'arith.addi'(0x55bafa33b640)
** Modified: 'arith.select'(0x55bafa424bf0)
** Modified: 'arith.cmpi'(0x55bafa423430)
** Erase   : 'arith.addi'(0x55bafa33b640)
// *** IR Dump After Successful Folding ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c2_i32 = arith.constant 2 : i32
  %c-1_i32 = arith.constant -1 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %c32_i32 = arith.constant 32 : i32
  %c31_i32 = arith.constant 31 : i32
  %cst_1 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %5 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %7 = arith.addi %6, %3 : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %8 = arith.muli %1, %c32_i32 : i32
  %9 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %10 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %11 = arith.addi %9, %4 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %12 = arith.addi %10, %5 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %13 = tt.expand_dims %7 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %14 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %15 = arith.muli %13, %14 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %16 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.broadcast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %18 = tt.broadcast %16 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = arith.addi %17, %18 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %20 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %22 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %23 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %24 = arith.muli %22, %23 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %11 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %26 = tt.broadcast %24 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = tt.broadcast %25 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = arith.addi %26, %27 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %32 = tt.addptr %31, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %33 = arith.addi %arg8, %c31_i32 : i32
  %34 = arith.divsi %33, %c32_i32 : i32
  %35 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = arith.cmpi slt, %13, %35 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = tt.broadcast %36 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %38 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = arith.cmpi slt, %25, %38 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.broadcast %39 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %41 = arith.muli %arg10, %c32_i32 : i32
  %42 = tt.splat %41 : i32 -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %43 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %44 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %45 = arith.cmpi sgt, %34, %c0_i32 : i32
  %c0_i32_3 = arith.constant 0 : i32
  %46 = arith.cmpi slt, %c0_i32_3, %c2_i32 : i32
  %47 = arith.select %46, %c0_i32_3, %c0_i32 : i32
  %48 = tt.splat %arg8 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %49 = arith.cmpi slt, %16, %48 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %50 = tt.broadcast %49 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %51 = arith.andi %37, %50 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = triton_gpu.memdesc_subview %43[%47, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %53 = tt.splat %45 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = arith.andi %53, %51 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %55 = triton_gpu.async_copy_global_to_local %21, %52 mask %54 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %56 = triton_gpu.async_commit_group %55
  %57 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %58 = arith.cmpi slt, %22, %57 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = tt.broadcast %58 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = arith.andi %59, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %61 = triton_gpu.memdesc_subview %44[%47, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %62 = tt.splat %45 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = arith.andi %62, %60 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %64 = triton_gpu.async_copy_global_to_local %30, %61 mask %63 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %65 = triton_gpu.async_commit_group %64
  %66 = arith.cmpi sgt, %34, %c1_i32 : i32
  %67 = tt.addptr %21, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %68 = tt.addptr %30, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = arith.addi %47, %c1_i32 : i32
  %70 = arith.cmpi slt, %69, %c2_i32 : i32
  %71 = arith.select %70, %69, %c0_i32 : i32
  %c32_i32_4 = arith.constant 32 : i32
  %72 = arith.subi %arg8, %c32_i32_4 : i32
  %73 = tt.splat %72 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %74 = arith.cmpi slt, %16, %73 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = tt.broadcast %74 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %76 = arith.andi %37, %75 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %77 = triton_gpu.memdesc_subview %43[%71, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %78 = tt.splat %66 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = arith.andi %78, %76 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %80 = triton_gpu.async_copy_global_to_local %67, %77 mask %79 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %81 = triton_gpu.async_commit_group %80
  %82 = tt.splat %72 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = arith.cmpi slt, %22, %82 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = tt.broadcast %83 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %85 = arith.andi %84, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = triton_gpu.memdesc_subview %44[%71, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %87 = tt.splat %66 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = arith.andi %87, %85 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %89 = triton_gpu.async_copy_global_to_local %68, %86 mask %88 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %90 = triton_gpu.async_commit_group %89
  %91 = arith.addi %c-1_i32, %c1_i32 : i32
  %92 = arith.cmpi slt, %91, %c2_i32 : i32
  %93 = arith.select %92, %91, %c0_i32 : i32
  %94 = triton_gpu.memdesc_subview %43[%93, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %95 = triton_gpu.async_wait %65 {num = 2 : i32}
  %96 = triton_gpu.memdesc_subview %44[%93, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %97:11 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %67, %arg15 = %68, %arg16 = %71, %arg17 = %93, %arg18 = %94, %arg19 = %95, %arg20 = %96, %arg21 = %95, %arg22 = %81, %arg23 = %90) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token)  : i32 {
    %c2_i32_5 = arith.constant 2 : i32
    %121 = arith.subi %34, %c2_i32_5 : i32
    %122 = arith.cmpi slt, %arg12, %121 : i32
    %123 = triton_gpu.local_load %arg18 token %arg19 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %124 = triton_gpu.local_load %arg20 token %arg21 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %125 = triton_gpu.convert_layout %123 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %126 = triton_gpu.convert_layout %124 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %127 = tt.dot %125, %126, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %128 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %129 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %130 = arith.addi %arg16, %c1_i32 : i32
    %131 = arith.cmpi slt, %130, %c2_i32 : i32
    %132 = arith.select %131, %130, %c0_i32 : i32
    %c2_i32_6 = arith.constant 2 : i32
    %133 = arith.addi %arg12, %c2_i32_6 : i32
    %134 = arith.muli %133, %c32_i32 : i32
    %135 = arith.subi %arg8, %134 : i32
    %136 = tt.splat %135 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %137 = arith.cmpi slt, %16, %136 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %138 = tt.broadcast %137 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %139 = arith.andi %37, %138 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %140 = triton_gpu.memdesc_subview %43[%132, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %141 = tt.splat %122 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %142 = arith.andi %141, %139 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %143 = triton_gpu.async_copy_global_to_local %128, %140 mask %142 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %144 = triton_gpu.async_commit_group %143
    %145 = tt.splat %135 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %146 = arith.cmpi slt, %22, %145 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %147 = tt.broadcast %146 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %148 = arith.andi %147, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = triton_gpu.memdesc_subview %44[%132, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %150 = tt.splat %122 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %151 = arith.andi %150, %148 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %152 = triton_gpu.async_copy_global_to_local %129, %149 mask %151 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %153 = triton_gpu.async_commit_group %152
    %154 = arith.addi %arg17, %c1_i32 : i32
    %155 = arith.cmpi slt, %154, %c2_i32 : i32
    %156 = arith.select %155, %154, %c0_i32 : i32
    %157 = triton_gpu.memdesc_subview %43[%156, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %158 = triton_gpu.async_wait %arg23 {num = 2 : i32}
    %159 = triton_gpu.memdesc_subview %44[%156, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    scf.yield %127, %128, %129, %132, %156, %157, %158, %159, %158, %144, %153 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token
  }
  %98 = triton_gpu.async_wait  {num = 0 : i32}
  triton_gpu.local_dealloc %43 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  triton_gpu.local_dealloc %44 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %99 = tt.splat %arg7 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %100 = arith.cmpi slt, %12, %99 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %101 = tt.load %32, %100, %cst_2 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %102 = arith.sitofp %arg4 : i32 to f32
  %103 = tt.splat %102 : f32 -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %104 = arith.mulf %97#0, %103 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %105 = arith.sitofp %arg5 : i32 to f16
  %106 = tt.splat %105 : f16 -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %107 = arith.mulf %101, %106 : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %108 = tt.expand_dims %107 {axis = 0 : i32} : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>> -> tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %109 = arith.extf %108 : tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %110 = tt.broadcast %109 : tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %111 = arith.addf %104, %110 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %112 = arith.truncf %111 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %113 = tt.splat %arg11 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %114 = arith.muli %113, %13 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %115 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %116 = tt.addptr %115, %114 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %117 = tt.broadcast %116 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %118 = tt.addptr %117, %27 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %119 = arith.andi %37, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %120 = triton_gpu.convert_layout %112 : tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.store %118, %120, %119 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.return
}



//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa423430) {
  %57 = "arith.cmpi"(%56, %0) <{predicate = 2 : i64}> : (i32, i32) -> i1

} -> success : operation was folded
//===-------------------------------------------===//
** Insert  : 'arith.constant'(0x55bafa4271c0)
** Replace : 'arith.cmpi'(0x55bafa423430)
** Modified: 'arith.select'(0x55bafa424bf0)
** Erase   : 'arith.cmpi'(0x55bafa423430)
// *** IR Dump After Successful Folding ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c2_i32 = arith.constant 2 : i32
  %c-1_i32 = arith.constant -1 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %c32_i32 = arith.constant 32 : i32
  %c31_i32 = arith.constant 31 : i32
  %cst_1 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %5 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %7 = arith.addi %6, %3 : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %8 = arith.muli %1, %c32_i32 : i32
  %9 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %10 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %11 = arith.addi %9, %4 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %12 = arith.addi %10, %5 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %13 = tt.expand_dims %7 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %14 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %15 = arith.muli %13, %14 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %16 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.broadcast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %18 = tt.broadcast %16 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = arith.addi %17, %18 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %20 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %22 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %23 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %24 = arith.muli %22, %23 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %11 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %26 = tt.broadcast %24 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = tt.broadcast %25 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = arith.addi %26, %27 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %32 = tt.addptr %31, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %33 = arith.addi %arg8, %c31_i32 : i32
  %34 = arith.divsi %33, %c32_i32 : i32
  %35 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = arith.cmpi slt, %13, %35 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = tt.broadcast %36 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %38 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = arith.cmpi slt, %25, %38 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.broadcast %39 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %41 = arith.muli %arg10, %c32_i32 : i32
  %42 = tt.splat %41 : i32 -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %43 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %44 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %45 = arith.cmpi sgt, %34, %c0_i32 : i32
  %c0_i32_3 = arith.constant 0 : i32
  %true = arith.constant true
  %46 = arith.select %true, %c0_i32_3, %c0_i32 : i32
  %47 = tt.splat %arg8 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = arith.cmpi slt, %16, %47 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %49 = tt.broadcast %48 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %50 = arith.andi %37, %49 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %51 = triton_gpu.memdesc_subview %43[%46, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %52 = tt.splat %45 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %53 = arith.andi %52, %50 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = triton_gpu.async_copy_global_to_local %21, %51 mask %53 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %55 = triton_gpu.async_commit_group %54
  %56 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = arith.cmpi slt, %22, %56 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %58 = tt.broadcast %57 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = arith.andi %58, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = triton_gpu.memdesc_subview %44[%46, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %61 = tt.splat %45 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = arith.andi %61, %59 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = triton_gpu.async_copy_global_to_local %30, %60 mask %62 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %64 = triton_gpu.async_commit_group %63
  %65 = arith.cmpi sgt, %34, %c1_i32 : i32
  %66 = tt.addptr %21, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = tt.addptr %30, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %68 = arith.addi %46, %c1_i32 : i32
  %69 = arith.cmpi slt, %68, %c2_i32 : i32
  %70 = arith.select %69, %68, %c0_i32 : i32
  %c32_i32_4 = arith.constant 32 : i32
  %71 = arith.subi %arg8, %c32_i32_4 : i32
  %72 = tt.splat %71 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %73 = arith.cmpi slt, %16, %72 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %74 = tt.broadcast %73 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = arith.andi %37, %74 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %76 = triton_gpu.memdesc_subview %43[%70, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %77 = tt.splat %65 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = arith.andi %77, %75 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = triton_gpu.async_copy_global_to_local %66, %76 mask %78 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %80 = triton_gpu.async_commit_group %79
  %81 = tt.splat %71 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = arith.cmpi slt, %22, %81 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = tt.broadcast %82 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = arith.andi %83, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %85 = triton_gpu.memdesc_subview %44[%70, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %86 = tt.splat %65 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %87 = arith.andi %86, %84 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = triton_gpu.async_copy_global_to_local %67, %85 mask %87 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %89 = triton_gpu.async_commit_group %88
  %90 = arith.addi %c-1_i32, %c1_i32 : i32
  %91 = arith.cmpi slt, %90, %c2_i32 : i32
  %92 = arith.select %91, %90, %c0_i32 : i32
  %93 = triton_gpu.memdesc_subview %43[%92, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %94 = triton_gpu.async_wait %64 {num = 2 : i32}
  %95 = triton_gpu.memdesc_subview %44[%92, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %96:11 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %66, %arg15 = %67, %arg16 = %70, %arg17 = %92, %arg18 = %93, %arg19 = %94, %arg20 = %95, %arg21 = %94, %arg22 = %80, %arg23 = %89) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token)  : i32 {
    %c2_i32_5 = arith.constant 2 : i32
    %120 = arith.subi %34, %c2_i32_5 : i32
    %121 = arith.cmpi slt, %arg12, %120 : i32
    %122 = triton_gpu.local_load %arg18 token %arg19 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %123 = triton_gpu.local_load %arg20 token %arg21 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %124 = triton_gpu.convert_layout %122 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %125 = triton_gpu.convert_layout %123 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %126 = tt.dot %124, %125, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %127 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %128 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %129 = arith.addi %arg16, %c1_i32 : i32
    %130 = arith.cmpi slt, %129, %c2_i32 : i32
    %131 = arith.select %130, %129, %c0_i32 : i32
    %c2_i32_6 = arith.constant 2 : i32
    %132 = arith.addi %arg12, %c2_i32_6 : i32
    %133 = arith.muli %132, %c32_i32 : i32
    %134 = arith.subi %arg8, %133 : i32
    %135 = tt.splat %134 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %136 = arith.cmpi slt, %16, %135 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %137 = tt.broadcast %136 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %138 = arith.andi %37, %137 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %139 = triton_gpu.memdesc_subview %43[%131, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %140 = tt.splat %121 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %141 = arith.andi %140, %138 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %142 = triton_gpu.async_copy_global_to_local %127, %139 mask %141 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %143 = triton_gpu.async_commit_group %142
    %144 = tt.splat %134 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %145 = arith.cmpi slt, %22, %144 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %146 = tt.broadcast %145 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %147 = arith.andi %146, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %148 = triton_gpu.memdesc_subview %44[%131, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %149 = tt.splat %121 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %150 = arith.andi %149, %147 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %151 = triton_gpu.async_copy_global_to_local %128, %148 mask %150 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %152 = triton_gpu.async_commit_group %151
    %153 = arith.addi %arg17, %c1_i32 : i32
    %154 = arith.cmpi slt, %153, %c2_i32 : i32
    %155 = arith.select %154, %153, %c0_i32 : i32
    %156 = triton_gpu.memdesc_subview %43[%155, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %157 = triton_gpu.async_wait %arg23 {num = 2 : i32}
    %158 = triton_gpu.memdesc_subview %44[%155, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    scf.yield %126, %127, %128, %131, %155, %156, %157, %158, %157, %143, %152 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token
  }
  %97 = triton_gpu.async_wait  {num = 0 : i32}
  triton_gpu.local_dealloc %43 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  triton_gpu.local_dealloc %44 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %98 = tt.splat %arg7 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %99 = arith.cmpi slt, %12, %98 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %100 = tt.load %32, %99, %cst_2 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %101 = arith.sitofp %arg4 : i32 to f32
  %102 = tt.splat %101 : f32 -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %103 = arith.mulf %96#0, %102 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %104 = arith.sitofp %arg5 : i32 to f16
  %105 = tt.splat %104 : f16 -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %106 = arith.mulf %100, %105 : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %107 = tt.expand_dims %106 {axis = 0 : i32} : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>> -> tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %108 = arith.extf %107 : tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %109 = tt.broadcast %108 : tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %110 = arith.addf %103, %109 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %111 = arith.truncf %110 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %112 = tt.splat %arg11 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %113 = arith.muli %112, %13 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %114 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %115 = tt.addptr %114, %113 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %116 = tt.broadcast %115 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %117 = tt.addptr %116, %27 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %118 = arith.andi %37, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %119 = triton_gpu.convert_layout %111 : tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.store %117, %119, %118 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.return
}



//===-------------------------------------------===//
Processing operation : 'arith.constant'(0x55bafa4271c0) {
  %57 = "arith.constant"() <{value = true}> : () -> i1

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.constant'(0x55bafa3b9e50) {
  %56 = "arith.constant"() <{value = 0 : i32}> : () -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.addi'(0x55bafa424130) {
  %80 = "arith.addi"(%58, %4) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.addi'(0x55bafa427dc0) {
  %103 = "arith.addi"(%1, %4) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> success : operation was folded
//===-------------------------------------------===//
** Insert  : 'arith.constant'(0x55bafa4273a0)
** Replace : 'arith.addi'(0x55bafa427dc0)
** Modified: 'arith.select'(0x55bafa427f20)
** Modified: 'arith.cmpi'(0x55bafa427e70)
** Erase   : 'arith.addi'(0x55bafa427dc0)
// *** IR Dump After Successful Folding ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c2_i32 = arith.constant 2 : i32
  %c-1_i32 = arith.constant -1 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %c32_i32 = arith.constant 32 : i32
  %c31_i32 = arith.constant 31 : i32
  %cst_1 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %5 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %7 = arith.addi %6, %3 : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %8 = arith.muli %1, %c32_i32 : i32
  %9 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %10 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %11 = arith.addi %9, %4 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %12 = arith.addi %10, %5 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %13 = tt.expand_dims %7 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %14 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %15 = arith.muli %13, %14 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %16 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.broadcast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %18 = tt.broadcast %16 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = arith.addi %17, %18 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %20 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %22 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %23 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %24 = arith.muli %22, %23 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %11 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %26 = tt.broadcast %24 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = tt.broadcast %25 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = arith.addi %26, %27 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %32 = tt.addptr %31, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %33 = arith.addi %arg8, %c31_i32 : i32
  %34 = arith.divsi %33, %c32_i32 : i32
  %35 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = arith.cmpi slt, %13, %35 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = tt.broadcast %36 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %38 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = arith.cmpi slt, %25, %38 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.broadcast %39 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %41 = arith.muli %arg10, %c32_i32 : i32
  %42 = tt.splat %41 : i32 -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %43 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %44 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %45 = arith.cmpi sgt, %34, %c0_i32 : i32
  %c0_i32_3 = arith.constant 0 : i32
  %true = arith.constant true
  %46 = arith.select %true, %c0_i32_3, %c0_i32 : i32
  %47 = tt.splat %arg8 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = arith.cmpi slt, %16, %47 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %49 = tt.broadcast %48 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %50 = arith.andi %37, %49 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %51 = triton_gpu.memdesc_subview %43[%46, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %52 = tt.splat %45 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %53 = arith.andi %52, %50 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = triton_gpu.async_copy_global_to_local %21, %51 mask %53 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %55 = triton_gpu.async_commit_group %54
  %56 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = arith.cmpi slt, %22, %56 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %58 = tt.broadcast %57 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = arith.andi %58, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = triton_gpu.memdesc_subview %44[%46, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %61 = tt.splat %45 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = arith.andi %61, %59 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = triton_gpu.async_copy_global_to_local %30, %60 mask %62 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %64 = triton_gpu.async_commit_group %63
  %65 = arith.cmpi sgt, %34, %c1_i32 : i32
  %66 = tt.addptr %21, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = tt.addptr %30, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %68 = arith.addi %46, %c1_i32 : i32
  %69 = arith.cmpi slt, %68, %c2_i32 : i32
  %70 = arith.select %69, %68, %c0_i32 : i32
  %c32_i32_4 = arith.constant 32 : i32
  %71 = arith.subi %arg8, %c32_i32_4 : i32
  %72 = tt.splat %71 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %73 = arith.cmpi slt, %16, %72 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %74 = tt.broadcast %73 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = arith.andi %37, %74 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %76 = triton_gpu.memdesc_subview %43[%70, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %77 = tt.splat %65 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = arith.andi %77, %75 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = triton_gpu.async_copy_global_to_local %66, %76 mask %78 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %80 = triton_gpu.async_commit_group %79
  %81 = tt.splat %71 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = arith.cmpi slt, %22, %81 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = tt.broadcast %82 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = arith.andi %83, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %85 = triton_gpu.memdesc_subview %44[%70, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %86 = tt.splat %65 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %87 = arith.andi %86, %84 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = triton_gpu.async_copy_global_to_local %67, %85 mask %87 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %89 = triton_gpu.async_commit_group %88
  %c0_i32_5 = arith.constant 0 : i32
  %90 = arith.cmpi slt, %c0_i32_5, %c2_i32 : i32
  %91 = arith.select %90, %c0_i32_5, %c0_i32 : i32
  %92 = triton_gpu.memdesc_subview %43[%91, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %93 = triton_gpu.async_wait %64 {num = 2 : i32}
  %94 = triton_gpu.memdesc_subview %44[%91, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %95:11 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %66, %arg15 = %67, %arg16 = %70, %arg17 = %91, %arg18 = %92, %arg19 = %93, %arg20 = %94, %arg21 = %93, %arg22 = %80, %arg23 = %89) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token)  : i32 {
    %c2_i32_6 = arith.constant 2 : i32
    %119 = arith.subi %34, %c2_i32_6 : i32
    %120 = arith.cmpi slt, %arg12, %119 : i32
    %121 = triton_gpu.local_load %arg18 token %arg19 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %122 = triton_gpu.local_load %arg20 token %arg21 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %123 = triton_gpu.convert_layout %121 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %124 = triton_gpu.convert_layout %122 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %125 = tt.dot %123, %124, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %126 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %127 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %128 = arith.addi %arg16, %c1_i32 : i32
    %129 = arith.cmpi slt, %128, %c2_i32 : i32
    %130 = arith.select %129, %128, %c0_i32 : i32
    %c2_i32_7 = arith.constant 2 : i32
    %131 = arith.addi %arg12, %c2_i32_7 : i32
    %132 = arith.muli %131, %c32_i32 : i32
    %133 = arith.subi %arg8, %132 : i32
    %134 = tt.splat %133 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %135 = arith.cmpi slt, %16, %134 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %136 = tt.broadcast %135 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %137 = arith.andi %37, %136 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %138 = triton_gpu.memdesc_subview %43[%130, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %139 = tt.splat %120 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %140 = arith.andi %139, %137 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %141 = triton_gpu.async_copy_global_to_local %126, %138 mask %140 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %142 = triton_gpu.async_commit_group %141
    %143 = tt.splat %133 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %144 = arith.cmpi slt, %22, %143 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %145 = tt.broadcast %144 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %146 = arith.andi %145, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %147 = triton_gpu.memdesc_subview %44[%130, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %148 = tt.splat %120 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = arith.andi %148, %146 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %150 = triton_gpu.async_copy_global_to_local %127, %147 mask %149 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %151 = triton_gpu.async_commit_group %150
    %152 = arith.addi %arg17, %c1_i32 : i32
    %153 = arith.cmpi slt, %152, %c2_i32 : i32
    %154 = arith.select %153, %152, %c0_i32 : i32
    %155 = triton_gpu.memdesc_subview %43[%154, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %156 = triton_gpu.async_wait %arg23 {num = 2 : i32}
    %157 = triton_gpu.memdesc_subview %44[%154, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    scf.yield %125, %126, %127, %130, %154, %155, %156, %157, %156, %142, %151 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token
  }
  %96 = triton_gpu.async_wait  {num = 0 : i32}
  triton_gpu.local_dealloc %43 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  triton_gpu.local_dealloc %44 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %97 = tt.splat %arg7 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %98 = arith.cmpi slt, %12, %97 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %99 = tt.load %32, %98, %cst_2 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %100 = arith.sitofp %arg4 : i32 to f32
  %101 = tt.splat %100 : f32 -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %102 = arith.mulf %95#0, %101 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %103 = arith.sitofp %arg5 : i32 to f16
  %104 = tt.splat %103 : f16 -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %105 = arith.mulf %99, %104 : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %106 = tt.expand_dims %105 {axis = 0 : i32} : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>> -> tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %107 = arith.extf %106 : tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %108 = tt.broadcast %107 : tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %109 = arith.addf %102, %108 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %110 = arith.truncf %109 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %111 = tt.splat %arg11 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %112 = arith.muli %111, %13 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %113 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %114 = tt.addptr %113, %112 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %115 = tt.broadcast %114 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %116 = tt.addptr %115, %27 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %117 = arith.andi %37, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %118 = triton_gpu.convert_layout %110 : tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.store %116, %118, %117 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.return
}



//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa427e70) {
  %104 = "arith.cmpi"(%103, %0) <{predicate = 2 : i64}> : (i32, i32) -> i1

} -> success : operation was folded
//===-------------------------------------------===//
** Insert  : 'arith.constant'(0x55bafa41dd80)
** Replace : 'arith.cmpi'(0x55bafa427e70)
** Modified: 'arith.select'(0x55bafa427f20)
** Erase   : 'arith.cmpi'(0x55bafa427e70)
// *** IR Dump After Successful Folding ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c2_i32 = arith.constant 2 : i32
  %c-1_i32 = arith.constant -1 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %c32_i32 = arith.constant 32 : i32
  %c31_i32 = arith.constant 31 : i32
  %cst_1 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %5 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %7 = arith.addi %6, %3 : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %8 = arith.muli %1, %c32_i32 : i32
  %9 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %10 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %11 = arith.addi %9, %4 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %12 = arith.addi %10, %5 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %13 = tt.expand_dims %7 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %14 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %15 = arith.muli %13, %14 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %16 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.broadcast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %18 = tt.broadcast %16 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = arith.addi %17, %18 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %20 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %22 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %23 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %24 = arith.muli %22, %23 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %11 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %26 = tt.broadcast %24 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = tt.broadcast %25 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = arith.addi %26, %27 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %32 = tt.addptr %31, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %33 = arith.addi %arg8, %c31_i32 : i32
  %34 = arith.divsi %33, %c32_i32 : i32
  %35 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = arith.cmpi slt, %13, %35 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = tt.broadcast %36 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %38 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = arith.cmpi slt, %25, %38 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.broadcast %39 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %41 = arith.muli %arg10, %c32_i32 : i32
  %42 = tt.splat %41 : i32 -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %43 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %44 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %45 = arith.cmpi sgt, %34, %c0_i32 : i32
  %c0_i32_3 = arith.constant 0 : i32
  %true = arith.constant true
  %46 = arith.select %true, %c0_i32_3, %c0_i32 : i32
  %47 = tt.splat %arg8 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = arith.cmpi slt, %16, %47 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %49 = tt.broadcast %48 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %50 = arith.andi %37, %49 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %51 = triton_gpu.memdesc_subview %43[%46, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %52 = tt.splat %45 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %53 = arith.andi %52, %50 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = triton_gpu.async_copy_global_to_local %21, %51 mask %53 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %55 = triton_gpu.async_commit_group %54
  %56 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = arith.cmpi slt, %22, %56 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %58 = tt.broadcast %57 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = arith.andi %58, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = triton_gpu.memdesc_subview %44[%46, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %61 = tt.splat %45 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = arith.andi %61, %59 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = triton_gpu.async_copy_global_to_local %30, %60 mask %62 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %64 = triton_gpu.async_commit_group %63
  %65 = arith.cmpi sgt, %34, %c1_i32 : i32
  %66 = tt.addptr %21, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = tt.addptr %30, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %68 = arith.addi %46, %c1_i32 : i32
  %69 = arith.cmpi slt, %68, %c2_i32 : i32
  %70 = arith.select %69, %68, %c0_i32 : i32
  %c32_i32_4 = arith.constant 32 : i32
  %71 = arith.subi %arg8, %c32_i32_4 : i32
  %72 = tt.splat %71 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %73 = arith.cmpi slt, %16, %72 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %74 = tt.broadcast %73 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = arith.andi %37, %74 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %76 = triton_gpu.memdesc_subview %43[%70, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %77 = tt.splat %65 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = arith.andi %77, %75 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = triton_gpu.async_copy_global_to_local %66, %76 mask %78 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %80 = triton_gpu.async_commit_group %79
  %81 = tt.splat %71 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = arith.cmpi slt, %22, %81 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = tt.broadcast %82 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = arith.andi %83, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %85 = triton_gpu.memdesc_subview %44[%70, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %86 = tt.splat %65 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %87 = arith.andi %86, %84 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = triton_gpu.async_copy_global_to_local %67, %85 mask %87 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %89 = triton_gpu.async_commit_group %88
  %c0_i32_5 = arith.constant 0 : i32
  %true_6 = arith.constant true
  %90 = arith.select %true_6, %c0_i32_5, %c0_i32 : i32
  %91 = triton_gpu.memdesc_subview %43[%90, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %92 = triton_gpu.async_wait %64 {num = 2 : i32}
  %93 = triton_gpu.memdesc_subview %44[%90, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %94:11 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %66, %arg15 = %67, %arg16 = %70, %arg17 = %90, %arg18 = %91, %arg19 = %92, %arg20 = %93, %arg21 = %92, %arg22 = %80, %arg23 = %89) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token)  : i32 {
    %c2_i32_7 = arith.constant 2 : i32
    %118 = arith.subi %34, %c2_i32_7 : i32
    %119 = arith.cmpi slt, %arg12, %118 : i32
    %120 = triton_gpu.local_load %arg18 token %arg19 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %121 = triton_gpu.local_load %arg20 token %arg21 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %122 = triton_gpu.convert_layout %120 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %123 = triton_gpu.convert_layout %121 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %124 = tt.dot %122, %123, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %125 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %126 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %127 = arith.addi %arg16, %c1_i32 : i32
    %128 = arith.cmpi slt, %127, %c2_i32 : i32
    %129 = arith.select %128, %127, %c0_i32 : i32
    %c2_i32_8 = arith.constant 2 : i32
    %130 = arith.addi %arg12, %c2_i32_8 : i32
    %131 = arith.muli %130, %c32_i32 : i32
    %132 = arith.subi %arg8, %131 : i32
    %133 = tt.splat %132 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %134 = arith.cmpi slt, %16, %133 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %135 = tt.broadcast %134 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %136 = arith.andi %37, %135 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %137 = triton_gpu.memdesc_subview %43[%129, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %138 = tt.splat %119 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %139 = arith.andi %138, %136 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %140 = triton_gpu.async_copy_global_to_local %125, %137 mask %139 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %141 = triton_gpu.async_commit_group %140
    %142 = tt.splat %132 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %143 = arith.cmpi slt, %22, %142 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %144 = tt.broadcast %143 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %145 = arith.andi %144, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %146 = triton_gpu.memdesc_subview %44[%129, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %147 = tt.splat %119 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %148 = arith.andi %147, %145 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = triton_gpu.async_copy_global_to_local %126, %146 mask %148 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %150 = triton_gpu.async_commit_group %149
    %151 = arith.addi %arg17, %c1_i32 : i32
    %152 = arith.cmpi slt, %151, %c2_i32 : i32
    %153 = arith.select %152, %151, %c0_i32 : i32
    %154 = triton_gpu.memdesc_subview %43[%153, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %155 = triton_gpu.async_wait %arg23 {num = 2 : i32}
    %156 = triton_gpu.memdesc_subview %44[%153, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    scf.yield %124, %125, %126, %129, %153, %154, %155, %156, %155, %141, %150 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token
  }
  %95 = triton_gpu.async_wait  {num = 0 : i32}
  triton_gpu.local_dealloc %43 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  triton_gpu.local_dealloc %44 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %96 = tt.splat %arg7 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %97 = arith.cmpi slt, %12, %96 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %98 = tt.load %32, %97, %cst_2 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %99 = arith.sitofp %arg4 : i32 to f32
  %100 = tt.splat %99 : f32 -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %101 = arith.mulf %94#0, %100 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %102 = arith.sitofp %arg5 : i32 to f16
  %103 = tt.splat %102 : f16 -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %104 = arith.mulf %98, %103 : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %105 = tt.expand_dims %104 {axis = 0 : i32} : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>> -> tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %106 = arith.extf %105 : tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %107 = tt.broadcast %106 : tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %108 = arith.addf %101, %107 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %109 = arith.truncf %108 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %110 = tt.splat %arg11 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %111 = arith.muli %110, %13 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %112 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %113 = tt.addptr %112, %111 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %114 = tt.broadcast %113 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %115 = tt.addptr %114, %27 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %116 = arith.andi %37, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %117 = triton_gpu.convert_layout %109 : tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.store %115, %117, %116 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.return
}



//===-------------------------------------------===//
Processing operation : 'arith.constant'(0x55bafa41dd80) {
  %104 = "arith.constant"() <{value = true}> : () -> i1

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.constant'(0x55bafa4273a0) {
  %103 = "arith.constant"() <{value = 0 : i32}> : () -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.addi'(0x55bafa431ad0) {
  %143 = "arith.addi"(%arg16, %4) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.addi'(0x55bafa41db50) {
  %168 = "arith.addi"(%arg17, %4) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.select'(0x55bafa424bf0) {
  %58 = "arith.select"(%57, %56, %3) : (i1, i32, i32) -> i32

} -> success : operation was folded
//===-------------------------------------------===//
** Replace : 'arith.select'(0x55bafa424bf0)
** Modified: 'arith.addi'(0x55bafa424130)
** Modified: 'triton_gpu.memdesc_subview'(0x55bafa4272b0)
** Modified: 'triton_gpu.memdesc_subview'(0x55bafa364a60)
** Erase   : 'arith.select'(0x55bafa424bf0)
// *** IR Dump After Successful Folding ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c2_i32 = arith.constant 2 : i32
  %c-1_i32 = arith.constant -1 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %c32_i32 = arith.constant 32 : i32
  %c31_i32 = arith.constant 31 : i32
  %cst_1 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %5 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %7 = arith.addi %6, %3 : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %8 = arith.muli %1, %c32_i32 : i32
  %9 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %10 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %11 = arith.addi %9, %4 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %12 = arith.addi %10, %5 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %13 = tt.expand_dims %7 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %14 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %15 = arith.muli %13, %14 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %16 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.broadcast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %18 = tt.broadcast %16 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = arith.addi %17, %18 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %20 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %22 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %23 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %24 = arith.muli %22, %23 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %11 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %26 = tt.broadcast %24 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = tt.broadcast %25 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = arith.addi %26, %27 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %32 = tt.addptr %31, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %33 = arith.addi %arg8, %c31_i32 : i32
  %34 = arith.divsi %33, %c32_i32 : i32
  %35 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = arith.cmpi slt, %13, %35 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = tt.broadcast %36 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %38 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = arith.cmpi slt, %25, %38 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.broadcast %39 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %41 = arith.muli %arg10, %c32_i32 : i32
  %42 = tt.splat %41 : i32 -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %43 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %44 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %45 = arith.cmpi sgt, %34, %c0_i32 : i32
  %c0_i32_3 = arith.constant 0 : i32
  %true = arith.constant true
  %46 = tt.splat %arg8 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %47 = arith.cmpi slt, %16, %46 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = tt.broadcast %47 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %49 = arith.andi %37, %48 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %50 = triton_gpu.memdesc_subview %43[%c0_i32_3, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %51 = tt.splat %45 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = arith.andi %51, %49 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %53 = triton_gpu.async_copy_global_to_local %21, %50 mask %52 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %54 = triton_gpu.async_commit_group %53
  %55 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = arith.cmpi slt, %22, %55 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = tt.broadcast %56 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %58 = arith.andi %57, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = triton_gpu.memdesc_subview %44[%c0_i32_3, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %60 = tt.splat %45 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %61 = arith.andi %60, %58 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = triton_gpu.async_copy_global_to_local %30, %59 mask %61 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %63 = triton_gpu.async_commit_group %62
  %64 = arith.cmpi sgt, %34, %c1_i32 : i32
  %65 = tt.addptr %21, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %66 = tt.addptr %30, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = arith.addi %c0_i32_3, %c1_i32 : i32
  %68 = arith.cmpi slt, %67, %c2_i32 : i32
  %69 = arith.select %68, %67, %c0_i32 : i32
  %c32_i32_4 = arith.constant 32 : i32
  %70 = arith.subi %arg8, %c32_i32_4 : i32
  %71 = tt.splat %70 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %72 = arith.cmpi slt, %16, %71 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %73 = tt.broadcast %72 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %74 = arith.andi %37, %73 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = triton_gpu.memdesc_subview %43[%69, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %76 = tt.splat %64 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %77 = arith.andi %76, %74 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = triton_gpu.async_copy_global_to_local %65, %75 mask %77 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %79 = triton_gpu.async_commit_group %78
  %80 = tt.splat %70 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = arith.cmpi slt, %22, %80 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = tt.broadcast %81 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = arith.andi %82, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = triton_gpu.memdesc_subview %44[%69, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %85 = tt.splat %64 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = arith.andi %85, %83 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %87 = triton_gpu.async_copy_global_to_local %66, %84 mask %86 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %88 = triton_gpu.async_commit_group %87
  %c0_i32_5 = arith.constant 0 : i32
  %true_6 = arith.constant true
  %89 = arith.select %true_6, %c0_i32_5, %c0_i32 : i32
  %90 = triton_gpu.memdesc_subview %43[%89, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %91 = triton_gpu.async_wait %63 {num = 2 : i32}
  %92 = triton_gpu.memdesc_subview %44[%89, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %93:11 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %65, %arg15 = %66, %arg16 = %69, %arg17 = %89, %arg18 = %90, %arg19 = %91, %arg20 = %92, %arg21 = %91, %arg22 = %79, %arg23 = %88) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token)  : i32 {
    %c2_i32_7 = arith.constant 2 : i32
    %117 = arith.subi %34, %c2_i32_7 : i32
    %118 = arith.cmpi slt, %arg12, %117 : i32
    %119 = triton_gpu.local_load %arg18 token %arg19 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %120 = triton_gpu.local_load %arg20 token %arg21 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %121 = triton_gpu.convert_layout %119 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %122 = triton_gpu.convert_layout %120 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %123 = tt.dot %121, %122, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %124 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %125 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %126 = arith.addi %arg16, %c1_i32 : i32
    %127 = arith.cmpi slt, %126, %c2_i32 : i32
    %128 = arith.select %127, %126, %c0_i32 : i32
    %c2_i32_8 = arith.constant 2 : i32
    %129 = arith.addi %arg12, %c2_i32_8 : i32
    %130 = arith.muli %129, %c32_i32 : i32
    %131 = arith.subi %arg8, %130 : i32
    %132 = tt.splat %131 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %133 = arith.cmpi slt, %16, %132 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %134 = tt.broadcast %133 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %135 = arith.andi %37, %134 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %136 = triton_gpu.memdesc_subview %43[%128, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %137 = tt.splat %118 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %138 = arith.andi %137, %135 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %139 = triton_gpu.async_copy_global_to_local %124, %136 mask %138 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %140 = triton_gpu.async_commit_group %139
    %141 = tt.splat %131 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %142 = arith.cmpi slt, %22, %141 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %143 = tt.broadcast %142 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %144 = arith.andi %143, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %145 = triton_gpu.memdesc_subview %44[%128, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %146 = tt.splat %118 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %147 = arith.andi %146, %144 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %148 = triton_gpu.async_copy_global_to_local %125, %145 mask %147 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %149 = triton_gpu.async_commit_group %148
    %150 = arith.addi %arg17, %c1_i32 : i32
    %151 = arith.cmpi slt, %150, %c2_i32 : i32
    %152 = arith.select %151, %150, %c0_i32 : i32
    %153 = triton_gpu.memdesc_subview %43[%152, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %154 = triton_gpu.async_wait %arg23 {num = 2 : i32}
    %155 = triton_gpu.memdesc_subview %44[%152, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    scf.yield %123, %124, %125, %128, %152, %153, %154, %155, %154, %140, %149 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token
  }
  %94 = triton_gpu.async_wait  {num = 0 : i32}
  triton_gpu.local_dealloc %43 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  triton_gpu.local_dealloc %44 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %95 = tt.splat %arg7 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %96 = arith.cmpi slt, %12, %95 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %97 = tt.load %32, %96, %cst_2 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %98 = arith.sitofp %arg4 : i32 to f32
  %99 = tt.splat %98 : f32 -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %100 = arith.mulf %93#0, %99 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %101 = arith.sitofp %arg5 : i32 to f16
  %102 = tt.splat %101 : f16 -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %103 = arith.mulf %97, %102 : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %104 = tt.expand_dims %103 {axis = 0 : i32} : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>> -> tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %105 = arith.extf %104 : tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %106 = tt.broadcast %105 : tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %107 = arith.addf %100, %106 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %108 = arith.truncf %107 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %109 = tt.splat %arg11 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %110 = arith.muli %109, %13 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %111 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %112 = tt.addptr %111, %110 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %113 = tt.broadcast %112 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %114 = tt.addptr %113, %27 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %115 = arith.andi %37, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %116 = triton_gpu.convert_layout %108 : tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.store %114, %116, %115 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.return
}



//===-------------------------------------------===//
Processing operation : 'arith.constant'(0x55bafa4271c0) {
  %57 = "arith.constant"() <{value = true}> : () -> i1

  ** Erase   : 'arith.constant'(0x55bafa4271c0)
} -> success : operation is trivially dead
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.memdesc_subview'(0x55bafa364a60) {
  %61 = "triton_gpu.memdesc_subview"(%53, %56, %3, %3) : (!tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, i32, i32, i32) -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.memdesc_subview'(0x55bafa4272b0) {
  %70 = "triton_gpu.memdesc_subview"(%54, %56, %3, %3) : (!tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, i32, i32, i32) -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.addi'(0x55bafa424130) {
  %78 = "arith.addi"(%56, %4) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> success : operation was folded
//===-------------------------------------------===//
** Insert  : 'arith.constant'(0x55bafa4271c0)
** Replace : 'arith.addi'(0x55bafa424130)
** Modified: 'arith.select'(0x55bafa424290)
** Modified: 'arith.cmpi'(0x55bafa4241e0)
** Erase   : 'arith.addi'(0x55bafa424130)
// *** IR Dump After Successful Folding ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c2_i32 = arith.constant 2 : i32
  %c-1_i32 = arith.constant -1 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %c32_i32 = arith.constant 32 : i32
  %c31_i32 = arith.constant 31 : i32
  %cst_1 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %5 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %7 = arith.addi %6, %3 : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %8 = arith.muli %1, %c32_i32 : i32
  %9 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %10 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %11 = arith.addi %9, %4 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %12 = arith.addi %10, %5 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %13 = tt.expand_dims %7 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %14 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %15 = arith.muli %13, %14 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %16 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.broadcast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %18 = tt.broadcast %16 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = arith.addi %17, %18 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %20 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %22 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %23 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %24 = arith.muli %22, %23 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %11 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %26 = tt.broadcast %24 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = tt.broadcast %25 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = arith.addi %26, %27 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %32 = tt.addptr %31, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %33 = arith.addi %arg8, %c31_i32 : i32
  %34 = arith.divsi %33, %c32_i32 : i32
  %35 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = arith.cmpi slt, %13, %35 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = tt.broadcast %36 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %38 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = arith.cmpi slt, %25, %38 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.broadcast %39 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %41 = arith.muli %arg10, %c32_i32 : i32
  %42 = tt.splat %41 : i32 -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %43 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %44 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %45 = arith.cmpi sgt, %34, %c0_i32 : i32
  %c0_i32_3 = arith.constant 0 : i32
  %46 = tt.splat %arg8 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %47 = arith.cmpi slt, %16, %46 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = tt.broadcast %47 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %49 = arith.andi %37, %48 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %50 = triton_gpu.memdesc_subview %43[%c0_i32_3, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %51 = tt.splat %45 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = arith.andi %51, %49 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %53 = triton_gpu.async_copy_global_to_local %21, %50 mask %52 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %54 = triton_gpu.async_commit_group %53
  %55 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = arith.cmpi slt, %22, %55 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = tt.broadcast %56 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %58 = arith.andi %57, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = triton_gpu.memdesc_subview %44[%c0_i32_3, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %60 = tt.splat %45 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %61 = arith.andi %60, %58 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = triton_gpu.async_copy_global_to_local %30, %59 mask %61 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %63 = triton_gpu.async_commit_group %62
  %64 = arith.cmpi sgt, %34, %c1_i32 : i32
  %65 = tt.addptr %21, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %66 = tt.addptr %30, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %c1_i32_4 = arith.constant 1 : i32
  %67 = arith.cmpi slt, %c1_i32_4, %c2_i32 : i32
  %68 = arith.select %67, %c1_i32_4, %c0_i32 : i32
  %c32_i32_5 = arith.constant 32 : i32
  %69 = arith.subi %arg8, %c32_i32_5 : i32
  %70 = tt.splat %69 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = arith.cmpi slt, %16, %70 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %72 = tt.broadcast %71 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %73 = arith.andi %37, %72 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %74 = triton_gpu.memdesc_subview %43[%68, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %75 = tt.splat %64 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %76 = arith.andi %75, %73 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %77 = triton_gpu.async_copy_global_to_local %65, %74 mask %76 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %78 = triton_gpu.async_commit_group %77
  %79 = tt.splat %69 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %80 = arith.cmpi slt, %22, %79 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = tt.broadcast %80 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = arith.andi %81, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = triton_gpu.memdesc_subview %44[%68, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %84 = tt.splat %64 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %85 = arith.andi %84, %82 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = triton_gpu.async_copy_global_to_local %66, %83 mask %85 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %87 = triton_gpu.async_commit_group %86
  %c0_i32_6 = arith.constant 0 : i32
  %true = arith.constant true
  %88 = arith.select %true, %c0_i32_6, %c0_i32 : i32
  %89 = triton_gpu.memdesc_subview %43[%88, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %90 = triton_gpu.async_wait %63 {num = 2 : i32}
  %91 = triton_gpu.memdesc_subview %44[%88, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %92:11 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %65, %arg15 = %66, %arg16 = %68, %arg17 = %88, %arg18 = %89, %arg19 = %90, %arg20 = %91, %arg21 = %90, %arg22 = %78, %arg23 = %87) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token)  : i32 {
    %c2_i32_7 = arith.constant 2 : i32
    %116 = arith.subi %34, %c2_i32_7 : i32
    %117 = arith.cmpi slt, %arg12, %116 : i32
    %118 = triton_gpu.local_load %arg18 token %arg19 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %119 = triton_gpu.local_load %arg20 token %arg21 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %120 = triton_gpu.convert_layout %118 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %121 = triton_gpu.convert_layout %119 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %122 = tt.dot %120, %121, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %123 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %124 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %125 = arith.addi %arg16, %c1_i32 : i32
    %126 = arith.cmpi slt, %125, %c2_i32 : i32
    %127 = arith.select %126, %125, %c0_i32 : i32
    %c2_i32_8 = arith.constant 2 : i32
    %128 = arith.addi %arg12, %c2_i32_8 : i32
    %129 = arith.muli %128, %c32_i32 : i32
    %130 = arith.subi %arg8, %129 : i32
    %131 = tt.splat %130 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %132 = arith.cmpi slt, %16, %131 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %133 = tt.broadcast %132 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %134 = arith.andi %37, %133 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %135 = triton_gpu.memdesc_subview %43[%127, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %136 = tt.splat %117 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %137 = arith.andi %136, %134 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %138 = triton_gpu.async_copy_global_to_local %123, %135 mask %137 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %139 = triton_gpu.async_commit_group %138
    %140 = tt.splat %130 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %141 = arith.cmpi slt, %22, %140 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %142 = tt.broadcast %141 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %143 = arith.andi %142, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %144 = triton_gpu.memdesc_subview %44[%127, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %145 = tt.splat %117 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %146 = arith.andi %145, %143 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %147 = triton_gpu.async_copy_global_to_local %124, %144 mask %146 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %148 = triton_gpu.async_commit_group %147
    %149 = arith.addi %arg17, %c1_i32 : i32
    %150 = arith.cmpi slt, %149, %c2_i32 : i32
    %151 = arith.select %150, %149, %c0_i32 : i32
    %152 = triton_gpu.memdesc_subview %43[%151, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %153 = triton_gpu.async_wait %arg23 {num = 2 : i32}
    %154 = triton_gpu.memdesc_subview %44[%151, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    scf.yield %122, %123, %124, %127, %151, %152, %153, %154, %153, %139, %148 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token
  }
  %93 = triton_gpu.async_wait  {num = 0 : i32}
  triton_gpu.local_dealloc %43 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  triton_gpu.local_dealloc %44 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %94 = tt.splat %arg7 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %95 = arith.cmpi slt, %12, %94 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %96 = tt.load %32, %95, %cst_2 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %97 = arith.sitofp %arg4 : i32 to f32
  %98 = tt.splat %97 : f32 -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %99 = arith.mulf %92#0, %98 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %100 = arith.sitofp %arg5 : i32 to f16
  %101 = tt.splat %100 : f16 -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %102 = arith.mulf %96, %101 : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %103 = tt.expand_dims %102 {axis = 0 : i32} : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>> -> tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %104 = arith.extf %103 : tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %105 = tt.broadcast %104 : tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %106 = arith.addf %99, %105 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %107 = arith.truncf %106 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %108 = tt.splat %arg11 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %109 = arith.muli %108, %13 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %110 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %111 = tt.addptr %110, %109 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %112 = tt.broadcast %111 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %113 = tt.addptr %112, %27 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %114 = arith.andi %37, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %115 = triton_gpu.convert_layout %107 : tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.store %113, %115, %114 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.return
}



//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa4241e0) {
  %79 = "arith.cmpi"(%78, %0) <{predicate = 2 : i64}> : (i32, i32) -> i1

} -> success : operation was folded
//===-------------------------------------------===//
** Insert  : 'arith.constant'(0x55bafa42bd50)
** Replace : 'arith.cmpi'(0x55bafa4241e0)
** Modified: 'arith.select'(0x55bafa424290)
** Erase   : 'arith.cmpi'(0x55bafa4241e0)
// *** IR Dump After Successful Folding ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c2_i32 = arith.constant 2 : i32
  %c-1_i32 = arith.constant -1 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %c32_i32 = arith.constant 32 : i32
  %c31_i32 = arith.constant 31 : i32
  %cst_1 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %5 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %7 = arith.addi %6, %3 : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %8 = arith.muli %1, %c32_i32 : i32
  %9 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %10 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %11 = arith.addi %9, %4 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %12 = arith.addi %10, %5 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %13 = tt.expand_dims %7 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %14 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %15 = arith.muli %13, %14 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %16 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.broadcast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %18 = tt.broadcast %16 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = arith.addi %17, %18 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %20 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %22 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %23 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %24 = arith.muli %22, %23 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %11 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %26 = tt.broadcast %24 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = tt.broadcast %25 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = arith.addi %26, %27 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %32 = tt.addptr %31, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %33 = arith.addi %arg8, %c31_i32 : i32
  %34 = arith.divsi %33, %c32_i32 : i32
  %35 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = arith.cmpi slt, %13, %35 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = tt.broadcast %36 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %38 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = arith.cmpi slt, %25, %38 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.broadcast %39 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %41 = arith.muli %arg10, %c32_i32 : i32
  %42 = tt.splat %41 : i32 -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %43 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %44 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %45 = arith.cmpi sgt, %34, %c0_i32 : i32
  %c0_i32_3 = arith.constant 0 : i32
  %46 = tt.splat %arg8 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %47 = arith.cmpi slt, %16, %46 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = tt.broadcast %47 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %49 = arith.andi %37, %48 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %50 = triton_gpu.memdesc_subview %43[%c0_i32_3, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %51 = tt.splat %45 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = arith.andi %51, %49 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %53 = triton_gpu.async_copy_global_to_local %21, %50 mask %52 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %54 = triton_gpu.async_commit_group %53
  %55 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = arith.cmpi slt, %22, %55 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = tt.broadcast %56 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %58 = arith.andi %57, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = triton_gpu.memdesc_subview %44[%c0_i32_3, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %60 = tt.splat %45 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %61 = arith.andi %60, %58 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = triton_gpu.async_copy_global_to_local %30, %59 mask %61 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %63 = triton_gpu.async_commit_group %62
  %64 = arith.cmpi sgt, %34, %c1_i32 : i32
  %65 = tt.addptr %21, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %66 = tt.addptr %30, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %c1_i32_4 = arith.constant 1 : i32
  %true = arith.constant true
  %67 = arith.select %true, %c1_i32_4, %c0_i32 : i32
  %c32_i32_5 = arith.constant 32 : i32
  %68 = arith.subi %arg8, %c32_i32_5 : i32
  %69 = tt.splat %68 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = arith.cmpi slt, %16, %69 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = tt.broadcast %70 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %72 = arith.andi %37, %71 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %73 = triton_gpu.memdesc_subview %43[%67, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %74 = tt.splat %64 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = arith.andi %74, %72 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %76 = triton_gpu.async_copy_global_to_local %65, %73 mask %75 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %77 = triton_gpu.async_commit_group %76
  %78 = tt.splat %68 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = arith.cmpi slt, %22, %78 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %80 = tt.broadcast %79 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = arith.andi %80, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %82 = triton_gpu.memdesc_subview %44[%67, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %83 = tt.splat %64 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = arith.andi %83, %81 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %85 = triton_gpu.async_copy_global_to_local %66, %82 mask %84 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %86 = triton_gpu.async_commit_group %85
  %c0_i32_6 = arith.constant 0 : i32
  %true_7 = arith.constant true
  %87 = arith.select %true_7, %c0_i32_6, %c0_i32 : i32
  %88 = triton_gpu.memdesc_subview %43[%87, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %89 = triton_gpu.async_wait %63 {num = 2 : i32}
  %90 = triton_gpu.memdesc_subview %44[%87, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %91:11 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %65, %arg15 = %66, %arg16 = %67, %arg17 = %87, %arg18 = %88, %arg19 = %89, %arg20 = %90, %arg21 = %89, %arg22 = %77, %arg23 = %86) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token)  : i32 {
    %c2_i32_8 = arith.constant 2 : i32
    %115 = arith.subi %34, %c2_i32_8 : i32
    %116 = arith.cmpi slt, %arg12, %115 : i32
    %117 = triton_gpu.local_load %arg18 token %arg19 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %118 = triton_gpu.local_load %arg20 token %arg21 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %119 = triton_gpu.convert_layout %117 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %120 = triton_gpu.convert_layout %118 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %121 = tt.dot %119, %120, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %122 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %123 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %124 = arith.addi %arg16, %c1_i32 : i32
    %125 = arith.cmpi slt, %124, %c2_i32 : i32
    %126 = arith.select %125, %124, %c0_i32 : i32
    %c2_i32_9 = arith.constant 2 : i32
    %127 = arith.addi %arg12, %c2_i32_9 : i32
    %128 = arith.muli %127, %c32_i32 : i32
    %129 = arith.subi %arg8, %128 : i32
    %130 = tt.splat %129 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %131 = arith.cmpi slt, %16, %130 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %132 = tt.broadcast %131 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %133 = arith.andi %37, %132 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %134 = triton_gpu.memdesc_subview %43[%126, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %135 = tt.splat %116 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %136 = arith.andi %135, %133 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %137 = triton_gpu.async_copy_global_to_local %122, %134 mask %136 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %138 = triton_gpu.async_commit_group %137
    %139 = tt.splat %129 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %140 = arith.cmpi slt, %22, %139 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %141 = tt.broadcast %140 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %142 = arith.andi %141, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %143 = triton_gpu.memdesc_subview %44[%126, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %144 = tt.splat %116 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %145 = arith.andi %144, %142 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %146 = triton_gpu.async_copy_global_to_local %123, %143 mask %145 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %147 = triton_gpu.async_commit_group %146
    %148 = arith.addi %arg17, %c1_i32 : i32
    %149 = arith.cmpi slt, %148, %c2_i32 : i32
    %150 = arith.select %149, %148, %c0_i32 : i32
    %151 = triton_gpu.memdesc_subview %43[%150, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %152 = triton_gpu.async_wait %arg23 {num = 2 : i32}
    %153 = triton_gpu.memdesc_subview %44[%150, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    scf.yield %121, %122, %123, %126, %150, %151, %152, %153, %152, %138, %147 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token
  }
  %92 = triton_gpu.async_wait  {num = 0 : i32}
  triton_gpu.local_dealloc %43 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  triton_gpu.local_dealloc %44 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %93 = tt.splat %arg7 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %94 = arith.cmpi slt, %12, %93 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %95 = tt.load %32, %94, %cst_2 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %96 = arith.sitofp %arg4 : i32 to f32
  %97 = tt.splat %96 : f32 -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %98 = arith.mulf %91#0, %97 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %99 = arith.sitofp %arg5 : i32 to f16
  %100 = tt.splat %99 : f16 -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %101 = arith.mulf %95, %100 : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %102 = tt.expand_dims %101 {axis = 0 : i32} : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>> -> tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %103 = arith.extf %102 : tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %104 = tt.broadcast %103 : tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %105 = arith.addf %98, %104 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %106 = arith.truncf %105 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %107 = tt.splat %arg11 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %108 = arith.muli %107, %13 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %109 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %110 = tt.addptr %109, %108 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %111 = tt.broadcast %110 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %112 = tt.addptr %111, %27 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %113 = arith.andi %37, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %114 = triton_gpu.convert_layout %106 : tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.store %112, %114, %113 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.return
}



//===-------------------------------------------===//
Processing operation : 'arith.constant'(0x55bafa42bd50) {
  %79 = "arith.constant"() <{value = true}> : () -> i1

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.constant'(0x55bafa4271c0) {
  %78 = "arith.constant"() <{value = 1 : i32}> : () -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.select'(0x55bafa424290) {
  %80 = "arith.select"(%79, %78, %3) : (i1, i32, i32) -> i32

} -> success : operation was folded
//===-------------------------------------------===//
** Replace : 'arith.select'(0x55bafa424290)
** Modified: 'scf.for'(0x55bafa4332b8)
** Modified: 'triton_gpu.memdesc_subview'(0x55bafa3885c0)
** Modified: 'triton_gpu.memdesc_subview'(0x55bafa424940)
** Erase   : 'arith.select'(0x55bafa424290)
// *** IR Dump After Successful Folding ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c2_i32 = arith.constant 2 : i32
  %c-1_i32 = arith.constant -1 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %c32_i32 = arith.constant 32 : i32
  %c31_i32 = arith.constant 31 : i32
  %cst_1 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %5 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %7 = arith.addi %6, %3 : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %8 = arith.muli %1, %c32_i32 : i32
  %9 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %10 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %11 = arith.addi %9, %4 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %12 = arith.addi %10, %5 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %13 = tt.expand_dims %7 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %14 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %15 = arith.muli %13, %14 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %16 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.broadcast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %18 = tt.broadcast %16 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = arith.addi %17, %18 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %20 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %22 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %23 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %24 = arith.muli %22, %23 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %11 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %26 = tt.broadcast %24 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = tt.broadcast %25 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = arith.addi %26, %27 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %32 = tt.addptr %31, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %33 = arith.addi %arg8, %c31_i32 : i32
  %34 = arith.divsi %33, %c32_i32 : i32
  %35 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = arith.cmpi slt, %13, %35 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = tt.broadcast %36 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %38 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = arith.cmpi slt, %25, %38 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.broadcast %39 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %41 = arith.muli %arg10, %c32_i32 : i32
  %42 = tt.splat %41 : i32 -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %43 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %44 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %45 = arith.cmpi sgt, %34, %c0_i32 : i32
  %c0_i32_3 = arith.constant 0 : i32
  %46 = tt.splat %arg8 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %47 = arith.cmpi slt, %16, %46 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = tt.broadcast %47 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %49 = arith.andi %37, %48 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %50 = triton_gpu.memdesc_subview %43[%c0_i32_3, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %51 = tt.splat %45 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = arith.andi %51, %49 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %53 = triton_gpu.async_copy_global_to_local %21, %50 mask %52 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %54 = triton_gpu.async_commit_group %53
  %55 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = arith.cmpi slt, %22, %55 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = tt.broadcast %56 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %58 = arith.andi %57, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = triton_gpu.memdesc_subview %44[%c0_i32_3, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %60 = tt.splat %45 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %61 = arith.andi %60, %58 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = triton_gpu.async_copy_global_to_local %30, %59 mask %61 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %63 = triton_gpu.async_commit_group %62
  %64 = arith.cmpi sgt, %34, %c1_i32 : i32
  %65 = tt.addptr %21, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %66 = tt.addptr %30, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %c1_i32_4 = arith.constant 1 : i32
  %true = arith.constant true
  %c32_i32_5 = arith.constant 32 : i32
  %67 = arith.subi %arg8, %c32_i32_5 : i32
  %68 = tt.splat %67 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = arith.cmpi slt, %16, %68 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = tt.broadcast %69 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = arith.andi %37, %70 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %72 = triton_gpu.memdesc_subview %43[%c1_i32_4, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %73 = tt.splat %64 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %74 = arith.andi %73, %71 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = triton_gpu.async_copy_global_to_local %65, %72 mask %74 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %76 = triton_gpu.async_commit_group %75
  %77 = tt.splat %67 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = arith.cmpi slt, %22, %77 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = tt.broadcast %78 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %80 = arith.andi %79, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = triton_gpu.memdesc_subview %44[%c1_i32_4, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %82 = tt.splat %64 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = arith.andi %82, %80 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = triton_gpu.async_copy_global_to_local %66, %81 mask %83 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %85 = triton_gpu.async_commit_group %84
  %c0_i32_6 = arith.constant 0 : i32
  %true_7 = arith.constant true
  %86 = arith.select %true_7, %c0_i32_6, %c0_i32 : i32
  %87 = triton_gpu.memdesc_subview %43[%86, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %88 = triton_gpu.async_wait %63 {num = 2 : i32}
  %89 = triton_gpu.memdesc_subview %44[%86, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %90:11 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %65, %arg15 = %66, %arg16 = %c1_i32_4, %arg17 = %86, %arg18 = %87, %arg19 = %88, %arg20 = %89, %arg21 = %88, %arg22 = %76, %arg23 = %85) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token)  : i32 {
    %c2_i32_8 = arith.constant 2 : i32
    %114 = arith.subi %34, %c2_i32_8 : i32
    %115 = arith.cmpi slt, %arg12, %114 : i32
    %116 = triton_gpu.local_load %arg18 token %arg19 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %117 = triton_gpu.local_load %arg20 token %arg21 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %118 = triton_gpu.convert_layout %116 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %119 = triton_gpu.convert_layout %117 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %120 = tt.dot %118, %119, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %121 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %122 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %123 = arith.addi %arg16, %c1_i32 : i32
    %124 = arith.cmpi slt, %123, %c2_i32 : i32
    %125 = arith.select %124, %123, %c0_i32 : i32
    %c2_i32_9 = arith.constant 2 : i32
    %126 = arith.addi %arg12, %c2_i32_9 : i32
    %127 = arith.muli %126, %c32_i32 : i32
    %128 = arith.subi %arg8, %127 : i32
    %129 = tt.splat %128 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %130 = arith.cmpi slt, %16, %129 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %131 = tt.broadcast %130 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %132 = arith.andi %37, %131 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %133 = triton_gpu.memdesc_subview %43[%125, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %134 = tt.splat %115 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %135 = arith.andi %134, %132 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %136 = triton_gpu.async_copy_global_to_local %121, %133 mask %135 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %137 = triton_gpu.async_commit_group %136
    %138 = tt.splat %128 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %139 = arith.cmpi slt, %22, %138 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %140 = tt.broadcast %139 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %141 = arith.andi %140, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %142 = triton_gpu.memdesc_subview %44[%125, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %143 = tt.splat %115 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %144 = arith.andi %143, %141 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %145 = triton_gpu.async_copy_global_to_local %122, %142 mask %144 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %146 = triton_gpu.async_commit_group %145
    %147 = arith.addi %arg17, %c1_i32 : i32
    %148 = arith.cmpi slt, %147, %c2_i32 : i32
    %149 = arith.select %148, %147, %c0_i32 : i32
    %150 = triton_gpu.memdesc_subview %43[%149, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %151 = triton_gpu.async_wait %arg23 {num = 2 : i32}
    %152 = triton_gpu.memdesc_subview %44[%149, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    scf.yield %120, %121, %122, %125, %149, %150, %151, %152, %151, %137, %146 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token
  }
  %91 = triton_gpu.async_wait  {num = 0 : i32}
  triton_gpu.local_dealloc %43 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  triton_gpu.local_dealloc %44 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %92 = tt.splat %arg7 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %93 = arith.cmpi slt, %12, %92 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %94 = tt.load %32, %93, %cst_2 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %95 = arith.sitofp %arg4 : i32 to f32
  %96 = tt.splat %95 : f32 -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %97 = arith.mulf %90#0, %96 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %98 = arith.sitofp %arg5 : i32 to f16
  %99 = tt.splat %98 : f16 -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %100 = arith.mulf %94, %99 : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %101 = tt.expand_dims %100 {axis = 0 : i32} : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>> -> tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %102 = arith.extf %101 : tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %103 = tt.broadcast %102 : tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %104 = arith.addf %97, %103 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %105 = arith.truncf %104 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %106 = tt.splat %arg11 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %107 = arith.muli %106, %13 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %108 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %109 = tt.addptr %108, %107 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %110 = tt.broadcast %109 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %111 = tt.addptr %110, %27 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %112 = arith.andi %37, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %113 = triton_gpu.convert_layout %105 : tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.store %111, %113, %112 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.return
}



//===-------------------------------------------===//
Processing operation : 'arith.constant'(0x55bafa42bd50) {
  %79 = "arith.constant"() <{value = true}> : () -> i1

  ** Erase   : 'arith.constant'(0x55bafa42bd50)
} -> success : operation is trivially dead
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.memdesc_subview'(0x55bafa424940) {
  %85 = "triton_gpu.memdesc_subview"(%53, %78, %3, %3) : (!tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, i32, i32, i32) -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.memdesc_subview'(0x55bafa3885c0) {
  %94 = "triton_gpu.memdesc_subview"(%54, %78, %3, %3) : (!tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, i32, i32, i32) -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.select'(0x55bafa427f20) {
  %101 = "arith.select"(%100, %99, %3) : (i1, i32, i32) -> i32

} -> success : operation was folded
//===-------------------------------------------===//
** Replace : 'arith.select'(0x55bafa427f20)
** Modified: 'scf.for'(0x55bafa4332b8)
** Modified: 'triton_gpu.memdesc_subview'(0x55bafa428200)
** Modified: 'triton_gpu.memdesc_subview'(0x55bafa428080)
** Erase   : 'arith.select'(0x55bafa427f20)
// *** IR Dump After Successful Folding ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c2_i32 = arith.constant 2 : i32
  %c-1_i32 = arith.constant -1 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %c32_i32 = arith.constant 32 : i32
  %c31_i32 = arith.constant 31 : i32
  %cst_1 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %5 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %7 = arith.addi %6, %3 : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %8 = arith.muli %1, %c32_i32 : i32
  %9 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %10 = tt.splat %8 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %11 = arith.addi %9, %4 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
  %12 = arith.addi %10, %5 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %13 = tt.expand_dims %7 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %14 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %15 = arith.muli %13, %14 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %16 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.broadcast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %18 = tt.broadcast %16 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = arith.addi %17, %18 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %20 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %22 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %23 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %24 = arith.muli %22, %23 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %11 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %26 = tt.broadcast %24 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = tt.broadcast %25 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = arith.addi %26, %27 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %32 = tt.addptr %31, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %33 = arith.addi %arg8, %c31_i32 : i32
  %34 = arith.divsi %33, %c32_i32 : i32
  %35 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = arith.cmpi slt, %13, %35 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = tt.broadcast %36 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %38 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = arith.cmpi slt, %25, %38 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.broadcast %39 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %41 = arith.muli %arg10, %c32_i32 : i32
  %42 = tt.splat %41 : i32 -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %43 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %44 = triton_gpu.local_alloc  : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %45 = arith.cmpi sgt, %34, %c0_i32 : i32
  %c0_i32_3 = arith.constant 0 : i32
  %46 = tt.splat %arg8 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %47 = arith.cmpi slt, %16, %46 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = tt.broadcast %47 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %49 = arith.andi %37, %48 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %50 = triton_gpu.memdesc_subview %43[%c0_i32_3, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %51 = tt.splat %45 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = arith.andi %51, %49 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %53 = triton_gpu.async_copy_global_to_local %21, %50 mask %52 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %54 = triton_gpu.async_commit_group %53
  %55 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = arith.cmpi slt, %22, %55 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = tt.broadcast %56 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %58 = arith.andi %57, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = triton_gpu.memdesc_subview %44[%c0_i32_3, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %60 = tt.splat %45 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %61 = arith.andi %60, %58 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = triton_gpu.async_copy_global_to_local %30, %59 mask %61 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %63 = triton_gpu.async_commit_group %62
  %64 = arith.cmpi sgt, %34, %c1_i32 : i32
  %65 = tt.addptr %21, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %66 = tt.addptr %30, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %c1_i32_4 = arith.constant 1 : i32
  %c32_i32_5 = arith.constant 32 : i32
  %67 = arith.subi %arg8, %c32_i32_5 : i32
  %68 = tt.splat %67 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = arith.cmpi slt, %16, %68 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %70 = tt.broadcast %69 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = arith.andi %37, %70 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %72 = triton_gpu.memdesc_subview %43[%c1_i32_4, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %73 = tt.splat %64 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %74 = arith.andi %73, %71 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = triton_gpu.async_copy_global_to_local %65, %72 mask %74 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %76 = triton_gpu.async_commit_group %75
  %77 = tt.splat %67 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %78 = arith.cmpi slt, %22, %77 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = tt.broadcast %78 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %80 = arith.andi %79, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = triton_gpu.memdesc_subview %44[%c1_i32_4, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %82 = tt.splat %64 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = arith.andi %82, %80 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = triton_gpu.async_copy_global_to_local %66, %81 mask %83 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %85 = triton_gpu.async_commit_group %84
  %c0_i32_6 = arith.constant 0 : i32
  %true = arith.constant true
  %86 = triton_gpu.memdesc_subview %43[%c0_i32_6, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %87 = triton_gpu.async_wait %63 {num = 2 : i32}
  %88 = triton_gpu.memdesc_subview %44[%c0_i32_6, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %89:11 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst, %arg14 = %65, %arg15 = %66, %arg16 = %c1_i32_4, %arg17 = %c0_i32_6, %arg18 = %86, %arg19 = %87, %arg20 = %88, %arg21 = %87, %arg22 = %76, %arg23 = %85) -> (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token)  : i32 {
    %c2_i32_7 = arith.constant 2 : i32
    %113 = arith.subi %34, %c2_i32_7 : i32
    %114 = arith.cmpi slt, %arg12, %113 : i32
    %115 = triton_gpu.local_load %arg18 token %arg19 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %116 = triton_gpu.local_load %arg20 token %arg21 : !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %117 = triton_gpu.convert_layout %115 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %118 = triton_gpu.convert_layout %116 : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %119 = tt.dot %117, %118, %arg13 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %120 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %121 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %122 = arith.addi %arg16, %c1_i32 : i32
    %123 = arith.cmpi slt, %122, %c2_i32 : i32
    %124 = arith.select %123, %122, %c0_i32 : i32
    %c2_i32_8 = arith.constant 2 : i32
    %125 = arith.addi %arg12, %c2_i32_8 : i32
    %126 = arith.muli %125, %c32_i32 : i32
    %127 = arith.subi %arg8, %126 : i32
    %128 = tt.splat %127 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %129 = arith.cmpi slt, %16, %128 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %130 = tt.broadcast %129 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %131 = arith.andi %37, %130 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %132 = triton_gpu.memdesc_subview %43[%124, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %133 = tt.splat %114 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %134 = arith.andi %133, %131 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %135 = triton_gpu.async_copy_global_to_local %120, %132 mask %134 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %136 = triton_gpu.async_commit_group %135
    %137 = tt.splat %127 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %138 = arith.cmpi slt, %22, %137 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %139 = tt.broadcast %138 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %140 = arith.andi %139, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %141 = triton_gpu.memdesc_subview %44[%124, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %142 = tt.splat %114 : i1 -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %143 = arith.andi %142, %140 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %144 = triton_gpu.async_copy_global_to_local %121, %141 mask %143 other %cst_0 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %145 = triton_gpu.async_commit_group %144
    %146 = arith.addi %arg17, %c1_i32 : i32
    %147 = arith.cmpi slt, %146, %c2_i32 : i32
    %148 = arith.select %147, %146, %c0_i32 : i32
    %149 = triton_gpu.memdesc_subview %43[%148, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    %150 = triton_gpu.async_wait %arg23 {num = 2 : i32}
    %151 = triton_gpu.memdesc_subview %44[%148, %c0_i32, %c0_i32] : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable> -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
    scf.yield %119, %120, %121, %124, %148, %149, %150, %151, %150, %136, %145 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token
  }
  %90 = triton_gpu.async_wait  {num = 0 : i32}
  triton_gpu.local_dealloc %43 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  triton_gpu.local_dealloc %44 : !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>
  %91 = tt.splat %arg7 : i32 -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %92 = arith.cmpi slt, %12, %91 : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %93 = tt.load %32, %92, %cst_2 : tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %94 = arith.sitofp %arg4 : i32 to f32
  %95 = tt.splat %94 : f32 -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %96 = arith.mulf %89#0, %95 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %97 = arith.sitofp %arg5 : i32 to f16
  %98 = tt.splat %97 : f16 -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %99 = arith.mulf %93, %98 : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>
  %100 = tt.expand_dims %99 {axis = 0 : i32} : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>> -> tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %101 = arith.extf %100 : tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %102 = tt.broadcast %101 : tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %103 = arith.addf %96, %102 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %104 = arith.truncf %103 : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
  %105 = tt.splat %arg11 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %106 = arith.muli %105, %13 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %107 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %108 = tt.addptr %107, %106 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %109 = tt.broadcast %108 : tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %110 = tt.addptr %109, %27 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %111 = arith.andi %37, %40 : tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %112 = triton_gpu.convert_layout %104 : tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.store %110, %112, %111 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
  tt.return
}



//===-------------------------------------------===//
Processing operation : 'arith.constant'(0x55bafa41dd80) {
  %100 = "arith.constant"() <{value = true}> : () -> i1

  ** Erase   : 'arith.constant'(0x55bafa41dd80)
} -> success : operation is trivially dead
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.memdesc_subview'(0x55bafa428080) {
  %100 = "triton_gpu.memdesc_subview"(%53, %99, %3, %3) : (!tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, i32, i32, i32) -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.memdesc_subview'(0x55bafa428200) {
  %102 = "triton_gpu.memdesc_subview"(%54, %99, %3, %3) : (!tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, i32, i32, i32) -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.select'(0x55bafa431c30) {
  %139 = "arith.select"(%138, %137, %3) : (i1, i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'scf.for'(0x55bafa4332b8) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.select'(0x55bafa41dcb0) {
  %164 = "arith.select"(%163, %162, %3) : (i1, i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.constant'(0x55bafa42cc40) {
  %1 = "arith.constant"() <{value = -1 : i32}> : () -> i32

  ** Erase   : 'arith.constant'(0x55bafa42cc40)
} -> success : operation is trivially dead
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.local_alloc'(0x55bafa3ced40) {
  %53 = "triton_gpu.local_alloc"() : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.local_alloc'(0x55bafa347860) {
  %52 = "triton_gpu.local_alloc"() : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa418c10) {
  %51 = "tt.splat"(%50) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.muli'(0x55bafa418b00) {
  %50 = "arith.muli"(%arg10, %5) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.broadcast'(0x55bafa418a10) {
  %49 = "tt.broadcast"(%48) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa418920) {
  %48 = "arith.cmpi"(%34, %47) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa418810) {
  %47 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.broadcast'(0x55bafa418720) {
  %46 = "tt.broadcast"(%45) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa4181b0) {
  %45 = "arith.cmpi"(%22, %44) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa4180a0) {
  %44 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.divsi'(0x55bafa417f90) {
  %43 = "arith.divsi"(%42, %5) : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.addi'(0x55bafa417e80) {
  %42 = "arith.addi"(%arg8, %6) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.addptr'(0x55bafa417d70) {
  %41 = "tt.addptr"(%40, %21) : (tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa417c80) {
  %40 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.addptr'(0x55bafa417b70) {
  %39 = "tt.addptr"(%38, %37) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa417a80) {
  %38 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.addi'(0x55bafa416d30) {
  %37 = "arith.addi"(%35, %36) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.broadcast'(0x55bafa416c40) {
  %36 = "tt.broadcast"(%34) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.broadcast'(0x55bafa416b50) {
  %35 = "tt.broadcast"(%33) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.expand_dims'(0x55bafa416a60) {
  %34 = "tt.expand_dims"(%20) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.muli'(0x55bafa416950) {
  %33 = "arith.muli"(%31, %32) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa416860) {
  %32 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.expand_dims'(0x55bafa416770) {
  %31 = "tt.expand_dims"(%12) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.addptr'(0x55bafa416660) {
  %30 = "tt.addptr"(%29, %28) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa416570) {
  %29 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.addi'(0x55bafa416460) {
  %28 = "arith.addi"(%26, %27) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.broadcast'(0x55bafa416370) {
  %27 = "tt.broadcast"(%25) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.broadcast'(0x55bafa416280) {
  %26 = "tt.broadcast"(%24) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.expand_dims'(0x55bafa416190) {
  %25 = "tt.expand_dims"(%13) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.muli'(0x55bafa415c00) {
  %24 = "arith.muli"(%22, %23) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa415b10) {
  %23 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.expand_dims'(0x55bafa415a20) {
  %22 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.addi'(0x55bafa415910) {
  %21 = "arith.addi"(%19, %14) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.addi'(0x55bafa415800) {
  %20 = "arith.addi"(%18, %13) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa415710) {
  %19 = "tt.splat"(%17) : (i32) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa415620) {
  %18 = "tt.splat"(%17) : (i32) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.muli'(0x55bafa415550) {
  %17 = "arith.muli"(%10, %5) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.addi'(0x55bafa410230) {
  %16 = "arith.addi"(%15, %12) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa410140) {
  %15 = "tt.splat"(%11) : (i32) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.make_range'(0x55bafa410070) {
  %14 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.make_range'(0x55bafa414e60) {
  %13 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.make_range'(0x55bafa414490) {
  %12 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.muli'(0x55bafa413180) {
  %11 = "arith.muli"(%9, %5) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.get_program_id'(0x55bafa4130e0) {
  %10 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.get_program_id'(0x55bafa350f40) {
  %9 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.constant'(0x55bafa412fb0) {
  %8 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>}> : () -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.constant'(0x55bafa412180) {
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.constant'(0x55bafa411c10) {
  %6 = "arith.constant"() <{value = 31 : i32}> : () -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.constant'(0x55bafa4116c0) {
  %5 = "arith.constant"() <{value = 32 : i32}> : () -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.constant'(0x55bafa4115f0) {
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.constant'(0x55bafa410c20) {
  %3 = "arith.constant"() <{value = 1 : i32}> : () -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.constant'(0x55bafa3d7ef0) {
  %2 = "arith.constant"() <{value = 0 : i32}> : () -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.func'(0x55bafa4174f0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.constant'(0x55bafa3d7db0) {
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>}> : () -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//
** Replace : 'arith.constant'(0x55bafa3b9e50)
** Modified: 'triton_gpu.memdesc_subview'(0x55bafa364a60)
** Modified: 'triton_gpu.memdesc_subview'(0x55bafa4272b0)
** Erase   : 'arith.constant'(0x55bafa3b9e50)
** Replace : 'arith.constant'(0x55bafa4271c0)
** Modified: 'triton_gpu.memdesc_subview'(0x55bafa424940)
** Modified: 'triton_gpu.memdesc_subview'(0x55bafa3885c0)
** Modified: 'scf.for'(0x55bafa4332b8)
** Erase   : 'arith.constant'(0x55bafa4271c0)
** Replace : 'arith.constant'(0x55bafa430680)
** Modified: 'arith.subi'(0x55bafa424410)
** Erase   : 'arith.constant'(0x55bafa430680)
** Replace : 'arith.constant'(0x55bafa4273a0)
** Modified: 'triton_gpu.memdesc_subview'(0x55bafa428080)
** Modified: 'triton_gpu.memdesc_subview'(0x55bafa428200)
** Modified: 'scf.for'(0x55bafa4332b8)
** Erase   : 'arith.constant'(0x55bafa4273a0)
** Replace : 'arith.constant'(0x55bafa353050)
** Modified: 'arith.subi'(0x55bafa4335b0)
** Erase   : 'arith.constant'(0x55bafa353050)
** Replace : 'arith.constant'(0x55bafa423b80)
** Modified: 'arith.addi'(0x55bafa431ed0)
** Erase   : 'arith.constant'(0x55bafa423b80)

//===-------------------------------------------===//
Processing operation : 'tt.return'(0x55bafa41c8e0) {
  "tt.return"() : () -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.store'(0x55bafa41c810) {
  "tt.store"(%119, %121, %120) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.convert_layout'(0x55bafa41c730) {
  %121 = "triton_gpu.convert_layout"(%113) : (tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.andi'(0x55bafa41c620) {
  %120 = "arith.andi"(%46, %49) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.addptr'(0x55bafa41c510) {
  %119 = "tt.addptr"(%118, %36) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.broadcast'(0x55bafa41c440) {
  %118 = "tt.broadcast"(%117) : (tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.addptr'(0x55bafa41c390) {
  %117 = "tt.addptr"(%116, %115) : (tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa41c300) {
  %116 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.muli'(0x55bafa41c250) {
  %115 = "arith.muli"(%114, %22) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa41c1c0) {
  %114 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.truncf'(0x55bafa41c120) {
  %113 = "arith.truncf"(%112) : (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>) -> tensor<32x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.addf'(0x55bafa41c070) {
  %112 = "arith.addf"(%105, %111) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>) -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.broadcast'(0x55bafa41bfe0) {
  %111 = "tt.broadcast"(%110) : (tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>) -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.extf'(0x55bafa41bf50) {
  %110 = "arith.extf"(%109) : (tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>) -> tensor<1x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.expand_dims'(0x55bafa41bec0) {
  %109 = "tt.expand_dims"(%108) <{axis = 0 : i32}> : (tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>) -> tensor<1x32xf16, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.mulf'(0x55bafa41be10) {
  %108 = "arith.mulf"(%102, %107) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>) -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa41bd80) {
  %107 = "tt.splat"(%106) : (f16) -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.sitofp'(0x55bafa41a070) {
  %106 = "arith.sitofp"(%arg5) : (i32) -> f16

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.mulf'(0x55bafa41b850) {
  %105 = "arith.mulf"(%98#0, %104) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>) -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa41b7c0) {
  %104 = "tt.splat"(%103) : (f32) -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.sitofp'(0x55bafa41b730) {
  %103 = "arith.sitofp"(%arg4) : (i32) -> f32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.load'(0x55bafa41b630) {
  %102 = "tt.load"(%41, %101, %8) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi1, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>) -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa41b580) {
  %101 = "arith.cmpi"(%21, %100) <{predicate = 2 : i64}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>) -> tensor<32xi1, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa41b4f0) {
  %100 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.local_dealloc'(0x55bafa428560) {
  "triton_gpu.local_dealloc"(%53) : (!tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.local_dealloc'(0x55bafa3b9eb0) {
  "triton_gpu.local_dealloc"(%52) : (!tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.async_wait'(0x55bafa41a110) {
  %99 = "triton_gpu.async_wait"() <{num = 0 : i32}> : () -> !triton_gpu.async.token

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'scf.yield'(0x55bafa425fe0) {
  "scf.yield"(%128, %129, %130, %133, %157, %158, %159, %160, %159, %145, %154) : (tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token, !triton_gpu.async.token, !triton_gpu.async.token) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.memdesc_subview'(0x55bafa41df90) {
  %160 = "triton_gpu.memdesc_subview"(%53, %157, %2, %2) : (!tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, i32, i32, i32) -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.async_wait'(0x55bafa419c00) {
  %159 = "triton_gpu.async_wait"(%arg23) <{num = 2 : i32}> : (!triton_gpu.async.token) -> !triton_gpu.async.token

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.memdesc_subview'(0x55bafa41de10) {
  %158 = "triton_gpu.memdesc_subview"(%52, %157, %2, %2) : (!tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, i32, i32, i32) -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.select'(0x55bafa41dcb0) {
  %157 = "arith.select"(%156, %155, %2) : (i1, i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa41dc00) {
  %156 = "arith.cmpi"(%155, %0) <{predicate = 2 : i64}> : (i32, i32) -> i1

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.addi'(0x55bafa41db50) {
  %155 = "arith.addi"(%arg17, %3) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.async_commit_group'(0x55bafa41dac0) {
  %154 = "triton_gpu.async_commit_group"(%153) : (!triton_gpu.async.token) -> !triton_gpu.async.token

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.async_copy_global_to_local'(0x55bafa41d870) {
  %153 = "triton_gpu.async_copy_global_to_local"(%130, %150, %152, %4) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> !triton_gpu.async.token

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.andi'(0x55bafa41da10) {
  %152 = "arith.andi"(%151, %149) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa41d980) {
  %151 = "tt.splat"(%123) : (i1) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.memdesc_subview'(0x55bafa432900) {
  %150 = "triton_gpu.memdesc_subview"(%53, %133, %2, %2) : (!tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, i32, i32, i32) -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.andi'(0x55bafa432850) {
  %149 = "arith.andi"(%148, %49) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.broadcast'(0x55bafa4327c0) {
  %148 = "tt.broadcast"(%147) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa432710) {
  %147 = "arith.cmpi"(%31, %146) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa432680) {
  %146 = "tt.splat"(%136) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.async_commit_group'(0x55bafa4325f0) {
  %145 = "triton_gpu.async_commit_group"(%144) : (!triton_gpu.async.token) -> !triton_gpu.async.token

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.async_copy_global_to_local'(0x55bafa4323a0) {
  %144 = "triton_gpu.async_copy_global_to_local"(%129, %141, %143, %4) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> !triton_gpu.async.token

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.andi'(0x55bafa432540) {
  %143 = "arith.andi"(%142, %140) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa4324b0) {
  %142 = "tt.splat"(%123) : (i1) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.memdesc_subview'(0x55bafa4322b0) {
  %141 = "triton_gpu.memdesc_subview"(%52, %133, %2, %2) : (!tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, i32, i32, i32) -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.andi'(0x55bafa432200) {
  %140 = "arith.andi"(%46, %139) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.broadcast'(0x55bafa432170) {
  %139 = "tt.broadcast"(%138) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa4320c0) {
  %138 = "arith.cmpi"(%25, %137) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa432030) {
  %137 = "tt.splat"(%136) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.subi'(0x55bafa431f80) {
  %136 = "arith.subi"(%arg8, %135) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.muli'(0x55bafa431d00) {
  %135 = "arith.muli"(%134, %5) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.addi'(0x55bafa431ed0) {
  %134 = "arith.addi"(%arg12, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.select'(0x55bafa431c30) {
  %133 = "arith.select"(%132, %131, %2) : (i1, i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa431b80) {
  %132 = "arith.cmpi"(%131, %0) <{predicate = 2 : i64}> : (i32, i32) -> i1

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.addi'(0x55bafa431ad0) {
  %131 = "arith.addi"(%arg16, %3) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.addptr'(0x55bafa433cc0) {
  %130 = "tt.addptr"(%arg15, %51) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.addptr'(0x55bafa433c10) {
  %129 = "tt.addptr"(%arg14, %7) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.dot'(0x55bafa40c2a0) {
  %128 = "tt.dot"(%126, %127, %arg13) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>, tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>) -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.convert_layout'(0x55bafa433b80) {
  %127 = "triton_gpu.convert_layout"(%125) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.convert_layout'(0x55bafa433af0) {
  %126 = "triton_gpu.convert_layout"(%124) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.local_load'(0x55bafa433a40) {
  %125 = "triton_gpu.local_load"(%arg20, %arg21) : (!tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.local_load'(0x55bafa433990) {
  %124 = "triton_gpu.local_load"(%arg18, %arg19) : (!tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, !triton_gpu.async.token) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa433660) {
  %123 = "arith.cmpi"(%arg12, %122) <{predicate = 2 : i64}> : (i32, i32) -> i1

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.subi'(0x55bafa4335b0) {
  %122 = "arith.subi"(%43, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.async_wait'(0x55bafa41fa50) {
  %96 = "triton_gpu.async_wait"(%72) <{num = 2 : i32}> : (!triton_gpu.async.token) -> !triton_gpu.async.token

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.memdesc_subview'(0x55bafa428200) {
  %97 = "triton_gpu.memdesc_subview"(%53, %2, %2, %2) : (!tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, i32, i32, i32) -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.memdesc_subview'(0x55bafa428080) {
  %95 = "triton_gpu.memdesc_subview"(%52, %2, %2, %2) : (!tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, i32, i32, i32) -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.async_commit_group'(0x55bafa427d30) {
  %94 = "triton_gpu.async_commit_group"(%93) : (!triton_gpu.async.token) -> !triton_gpu.async.token

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.async_copy_global_to_local'(0x55bafa427ae0) {
  %93 = "triton_gpu.async_copy_global_to_local"(%75, %90, %92, %4) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> !triton_gpu.async.token

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.andi'(0x55bafa427c80) {
  %92 = "arith.andi"(%91, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa427bf0) {
  %91 = "tt.splat"(%73) : (i1) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.andi'(0x55bafa427a30) {
  %89 = "arith.andi"(%88, %49) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.broadcast'(0x55bafa4279a0) {
  %88 = "tt.broadcast"(%87) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa4278f0) {
  %87 = "arith.cmpi"(%31, %86) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa427860) {
  %86 = "tt.splat"(%76) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.async_commit_group'(0x55bafa4277d0) {
  %85 = "triton_gpu.async_commit_group"(%84) : (!triton_gpu.async.token) -> !triton_gpu.async.token

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.async_copy_global_to_local'(0x55bafa427580) {
  %84 = "triton_gpu.async_copy_global_to_local"(%74, %81, %83, %4) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> !triton_gpu.async.token

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.andi'(0x55bafa427720) {
  %83 = "arith.andi"(%82, %80) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa427690) {
  %82 = "tt.splat"(%73) : (i1) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.andi'(0x55bafa424690) {
  %80 = "arith.andi"(%46, %79) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.broadcast'(0x55bafa424600) {
  %79 = "tt.broadcast"(%78) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa424550) {
  %78 = "arith.cmpi"(%25, %77) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa4244c0) {
  %77 = "tt.splat"(%76) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.subi'(0x55bafa424410) {
  %76 = "arith.subi"(%arg8, %5) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'scf.for'(0x55bafa4332b8) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.memdesc_subview'(0x55bafa3885c0) {
  %90 = "triton_gpu.memdesc_subview"(%53, %3, %2, %2) : (!tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, i32, i32, i32) -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.memdesc_subview'(0x55bafa424940) {
  %81 = "triton_gpu.memdesc_subview"(%52, %3, %2, %2) : (!tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, i32, i32, i32) -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.addptr'(0x55bafa424080) {
  %75 = "tt.addptr"(%39, %51) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.addptr'(0x55bafa423fd0) {
  %74 = "tt.addptr"(%30, %7) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa423d50) {
  %73 = "arith.cmpi"(%43, %3) <{predicate = 4 : i64}> : (i32, i32) -> i1

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.async_commit_group'(0x55bafa423af0) {
  %72 = "triton_gpu.async_commit_group"(%71) : (!triton_gpu.async.token) -> !triton_gpu.async.token

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.async_copy_global_to_local'(0x55bafa42c3a0) {
  %71 = "triton_gpu.async_copy_global_to_local"(%39, %68, %70, %4) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> !triton_gpu.async.token

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.andi'(0x55bafa423a40) {
  %70 = "arith.andi"(%69, %67) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa42c4b0) {
  %69 = "tt.splat"(%54) : (i1) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.andi'(0x55bafa42c2f0) {
  %67 = "arith.andi"(%66, %49) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.broadcast'(0x55bafa42c260) {
  %66 = "tt.broadcast"(%65) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa42c1b0) {
  %65 = "arith.cmpi"(%31, %64) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa431100) {
  %64 = "tt.splat"(%arg8) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.async_commit_group'(0x55bafa431070) {
  %63 = "triton_gpu.async_commit_group"(%62) : (!triton_gpu.async.token) -> !triton_gpu.async.token

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.async_copy_global_to_local'(0x55bafa43a1b0) {
  %62 = "triton_gpu.async_copy_global_to_local"(%30, %59, %61, %4) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> !triton_gpu.async.token

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.andi'(0x55bafa430fc0) {
  %61 = "arith.andi"(%60, %58) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa42bcc0) {
  %60 = "tt.splat"(%54) : (i1) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.andi'(0x55bafa42bc10) {
  %58 = "arith.andi"(%46, %57) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.broadcast'(0x55bafa41a180) {
  %57 = "tt.broadcast"(%56) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa41fda0) {
  %56 = "arith.cmpi"(%25, %55) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa364ff0) {
  %55 = "tt.splat"(%arg8) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.memdesc_subview'(0x55bafa4272b0) {
  %68 = "triton_gpu.memdesc_subview"(%53, %2, %2, %2) : (!tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, i32, i32, i32) -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.memdesc_subview'(0x55bafa364a60) {
  %59 = "triton_gpu.memdesc_subview"(%52, %2, %2, %2) : (!tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>, i32, i32, i32) -> !tt.memdesc<32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa3ceec0) {
  %54 = "arith.cmpi"(%43, %2) <{predicate = 4 : i64}> : (i32, i32) -> i1

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.local_alloc'(0x55bafa3ced40) {
  %53 = "triton_gpu.local_alloc"() : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'triton_gpu.local_alloc'(0x55bafa347860) {
  %52 = "triton_gpu.local_alloc"() : () -> !tt.memdesc<2x32x32xf16, #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0], hasLeadingOffset = false}>, #triton_gpu.shared_memory, mutable>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa418c10) {
  %51 = "tt.splat"(%50) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.muli'(0x55bafa418b00) {
  %50 = "arith.muli"(%arg10, %5) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.broadcast'(0x55bafa418a10) {
  %49 = "tt.broadcast"(%48) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa418920) {
  %48 = "arith.cmpi"(%34, %47) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa418810) {
  %47 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.broadcast'(0x55bafa418720) {
  %46 = "tt.broadcast"(%45) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.cmpi'(0x55bafa4181b0) {
  %45 = "arith.cmpi"(%22, %44) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa4180a0) {
  %44 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.divsi'(0x55bafa417f90) {
  %43 = "arith.divsi"(%42, %5) : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.addi'(0x55bafa417e80) {
  %42 = "arith.addi"(%arg8, %6) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.addptr'(0x55bafa417d70) {
  %41 = "tt.addptr"(%40, %21) : (tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa417c80) {
  %40 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.addptr'(0x55bafa417b70) {
  %39 = "tt.addptr"(%38, %37) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa417a80) {
  %38 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.addi'(0x55bafa416d30) {
  %37 = "arith.addi"(%35, %36) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.broadcast'(0x55bafa416c40) {
  %36 = "tt.broadcast"(%34) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.broadcast'(0x55bafa416b50) {
  %35 = "tt.broadcast"(%33) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.expand_dims'(0x55bafa416a60) {
  %34 = "tt.expand_dims"(%20) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.muli'(0x55bafa416950) {
  %33 = "arith.muli"(%31, %32) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa416860) {
  %32 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.expand_dims'(0x55bafa416770) {
  %31 = "tt.expand_dims"(%12) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.addptr'(0x55bafa416660) {
  %30 = "tt.addptr"(%29, %28) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa416570) {
  %29 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.addi'(0x55bafa416460) {
  %28 = "arith.addi"(%26, %27) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.broadcast'(0x55bafa416370) {
  %27 = "tt.broadcast"(%25) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.broadcast'(0x55bafa416280) {
  %26 = "tt.broadcast"(%24) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.expand_dims'(0x55bafa416190) {
  %25 = "tt.expand_dims"(%13) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.muli'(0x55bafa415c00) {
  %24 = "arith.muli"(%22, %23) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa415b10) {
  %23 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.expand_dims'(0x55bafa415a20) {
  %22 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.addi'(0x55bafa415910) {
  %21 = "arith.addi"(%19, %14) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.addi'(0x55bafa415800) {
  %20 = "arith.addi"(%18, %13) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa415710) {
  %19 = "tt.splat"(%17) : (i32) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa415620) {
  %18 = "tt.splat"(%17) : (i32) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.muli'(0x55bafa415550) {
  %17 = "arith.muli"(%10, %5) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.addi'(0x55bafa410230) {
  %16 = "arith.addi"(%15, %12) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.splat'(0x55bafa410140) {
  %15 = "tt.splat"(%11) : (i32) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.make_range'(0x55bafa410070) {
  %14 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.make_range'(0x55bafa414e60) {
  %13 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.make_range'(0x55bafa414490) {
  %12 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.muli'(0x55bafa413180) {
  %11 = "arith.muli"(%9, %5) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.get_program_id'(0x55bafa4130e0) {
  %10 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.get_program_id'(0x55bafa350f40) {
  %9 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.constant'(0x55bafa412fb0) {
  %8 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>}> : () -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.constant'(0x55bafa412180) {
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.constant'(0x55bafa411c10) {
  %6 = "arith.constant"() <{value = 31 : i32}> : () -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.constant'(0x55bafa4116c0) {
  %5 = "arith.constant"() <{value = 32 : i32}> : () -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.constant'(0x55bafa4115f0) {
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.constant'(0x55bafa410c20) {
  %3 = "arith.constant"() <{value = 1 : i32}> : () -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.constant'(0x55bafa3d7ef0) {
  %2 = "arith.constant"() <{value = 0 : i32}> : () -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.constant'(0x55bafa3d7db0) {
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>}> : () -> tensor<32x32xf32, #triton_gpu.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tt.func'(0x55bafa4174f0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'arith.constant'(0x55bafa427410) {
  %0 = "arith.constant"() <{value = 2 : i32}> : () -> i32

} -> failure : pattern failed to match
//===-------------------------------------------===//
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::PreservedAnalyses::AllAnalysesType)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::StorageUserTrait::IsMutable<mlir::TypeID::get<mlir::detail::StorageUserTrait::IsMutable>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::triton::gpu::TritonGPU_AttrTrait::Trait<mlir::TypeID::get<mlir::triton::gpu::TritonGPU_AttrTrait::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::triton::gpu::DistributedEncodingTrait::Trait<mlir::TypeID::get<mlir::triton::gpu::DistributedEncodingTrait::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::triton::gpu::MmaEncodingTrait::Trait<mlir::TypeID::get<mlir::triton::gpu::MmaEncodingTrait::Trait>()::Empty>)
