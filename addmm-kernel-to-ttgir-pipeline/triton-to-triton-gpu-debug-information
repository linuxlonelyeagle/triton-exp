Args: triton-opt addmm_kernel.ttir -convert-triton-to-tritongpu=target=cuda -debug 
Load new dialect in Context builtin
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ShapedType)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::MemRefLayoutAttrInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::TypedAttr)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ElementsAttr)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DistinctAttr)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BytecodeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpAsmOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionKindInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ConditionallySpeculatable)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::MemoryEffectOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ResourceBlobManagerDialectInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpAsmDialectInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BytecodeDialectInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::AffineBinaryOpExprStorage)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::AffineConstantExprStorage)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::AffineDimExprStorage)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::AffineMapStorage)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::IntegerSetStorage)
Load new dialect in Context builtin
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ZeroOperands<mlir::TypeID::get<mlir::OpTrait::ZeroOperands>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneRegion<mlir::TypeID::get<mlir::OpTrait::OneRegion>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ZeroResults<mlir::TypeID::get<mlir::OpTrait::ZeroResults>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ZeroSuccessors<mlir::TypeID::get<mlir::OpTrait::ZeroSuccessors>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NoRegionArguments<mlir::TypeID::get<mlir::OpTrait::NoRegionArguments>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NoTerminator<mlir::TypeID::get<mlir::OpTrait::NoTerminator>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SingleBlock<mlir::TypeID::get<mlir::OpTrait::SingleBlock>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OpInvariants<mlir::TypeID::get<mlir::OpTrait::OpInvariants>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BytecodeOpInterface::Trait<mlir::TypeID::get<mlir::BytecodeOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AffineScope<mlir::TypeID::get<mlir::OpTrait::AffineScope>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::IsIsolatedFromAbove<mlir::TypeID::get<mlir::OpTrait::IsIsolatedFromAbove>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SymbolTable<mlir::TypeID::get<mlir::OpTrait::SymbolTable>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolOpInterface::Trait<mlir::TypeID::get<mlir::SymbolOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpAsmOpInterface::Trait<mlir::TypeID::get<mlir::OpAsmOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionKindInterface::Trait<mlir::TypeID::get<mlir::RegionKindInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasOnlyGraphRegion<mlir::TypeID::get<mlir::OpTrait::HasOnlyGraphRegion>()::Empty>)
Load new dialect in Context tt
Load new dialect in Context arith
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithFastMathInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::VectorUnrollOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::InferTypeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::InferIntRangeInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithIntegerOverflowFlagsInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CastOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithRoundingModeInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SelectLikeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DialectInlinerInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ConvertToLLVMPatternInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::bufferization::BufferDeallocationOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::bufferization::BufferizableOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ValueBoundsOpInterface)
Load new dialect in Context math
Load new dialect in Context scf
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionBranchTerminatorOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionBranchOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::LoopLikeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DestinationStyleOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ParallelCombiningOpInterface)
Load new dialect in Context cf
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BranchOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CallOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolUserOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CallableOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::FunctionOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::TensorOrMemDesc)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AutomaticAllocationScope<mlir::TypeID::get<mlir::OpTrait::AutomaticAllocationScope>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CallableOpInterface::Trait<mlir::TypeID::get<mlir::CallableOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::FunctionOpInterface::Trait<mlir::TypeID::get<mlir::FunctionOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::TensorSizeTrait<mlir::TypeID::get<mlir::OpTrait::TensorSizeTrait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::VerifyTensorLayoutsTrait<mlir::TypeID::get<mlir::OpTrait::VerifyTensorLayoutsTrait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ZeroRegions<mlir::TypeID::get<mlir::OpTrait::ZeroRegions>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneResult<mlir::TypeID::get<mlir::OpTrait::OneResult>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::Type>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::Type>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ConstantLike<mlir::TypeID::get<mlir::OpTrait::ConstantLike>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ConditionallySpeculatable::Trait<mlir::TypeID::get<mlir::ConditionallySpeculatable::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AlwaysSpeculatableImplTrait<mlir::TypeID::get<mlir::OpTrait::AlwaysSpeculatableImplTrait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::MemoryEffectOpInterface::Trait<mlir::TypeID::get<mlir::MemoryEffectOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::InferIntRangeInterface::Trait<mlir::TypeID::get<mlir::InferIntRangeInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::InferTypeOpInterface::Trait<mlir::TypeID::get<mlir::InferTypeOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::detail::ConstantOpGenericAdaptorBase::Properties)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::IntegerType>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::IntegerType>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::triton::detail::GetProgramIdOpGenericAdaptorBase::Properties)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NOperands<2>::Impl<mlir::TypeID::get<mlir::OpTrait::NOperands<2>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::IsCommutative<mlir::TypeID::get<mlir::OpTrait::IsCommutative>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithIntegerOverflowFlagsInterface::Trait<mlir::TypeID::get<mlir::arith::ArithIntegerOverflowFlagsInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SameOperandsAndResultType<mlir::TypeID::get<mlir::OpTrait::SameOperandsAndResultType>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::VectorUnrollOpInterface::Trait<mlir::TypeID::get<mlir::VectorUnrollOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::Elementwise<mlir::TypeID::get<mlir::OpTrait::Elementwise>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::Scalarizable<mlir::TypeID::get<mlir::OpTrait::Scalarizable>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::Vectorizable<mlir::TypeID::get<mlir::OpTrait::Vectorizable>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::Tensorizable<mlir::TypeID::get<mlir::OpTrait::Tensorizable>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneOperand<mlir::TypeID::get<mlir::OpTrait::OneOperand>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SameOperandsAndResultElementType<mlir::TypeID::get<mlir::OpTrait::SameOperandsAndResultElementType>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SameOperandsAndResultEncoding<mlir::TypeID::get<mlir::OpTrait::SameOperandsAndResultEncoding>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SameOperandsAndResultShape<mlir::TypeID::get<mlir::OpTrait::SameOperandsAndResultShape>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SameTypeOperands<mlir::TypeID::get<mlir::OpTrait::SameTypeOperands>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::detail::CmpIOpGenericAdaptorBase::Properties)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::VariadicResults<mlir::TypeID::get<mlir::OpTrait::VariadicResults>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AtLeastNOperands<3>::Impl<mlir::TypeID::get<mlir::OpTrait::AtLeastNOperands<3>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SingleBlockImplicitTerminator<mlir::scf::YieldOp>::Impl<mlir::TypeID::get<mlir::OpTrait::SingleBlockImplicitTerminator<mlir::scf::YieldOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::LoopLikeOpInterface::Trait<mlir::TypeID::get<mlir::LoopLikeOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionBranchOpInterface::Trait<mlir::TypeID::get<mlir::RegionBranchOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasRecursiveMemoryEffects<mlir::TypeID::get<mlir::OpTrait::HasRecursiveMemoryEffects>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::IsIdempotent<mlir::TypeID::get<mlir::OpTrait::IsIdempotent>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AtLeastNOperands<1>::Impl<mlir::TypeID::get<mlir::OpTrait::AtLeastNOperands<1>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AttrSizedOperandSegments<mlir::TypeID::get<mlir::OpTrait::AttrSizedOperandSegments>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SameLoadStoreOperandsAndResultShape<mlir::TypeID::get<mlir::OpTrait::SameLoadStoreOperandsAndResultShape>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SameLoadStoreOperandsAndResultEncoding<mlir::TypeID::get<mlir::OpTrait::SameLoadStoreOperandsAndResultEncoding>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::triton::detail::LoadOpGenericAdaptorBase::Properties)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NOperands<3>::Impl<mlir::TypeID::get<mlir::OpTrait::NOperands<3>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::DotLike<mlir::TypeID::get<mlir::OpTrait::DotLike>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::VariadicOperands<mlir::TypeID::get<mlir::OpTrait::VariadicOperands>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasParent<mlir::scf::ExecuteRegionOp, mlir::scf::ForOp, mlir::scf::IfOp, mlir::scf::IndexSwitchOp, mlir::scf::WhileOp>::Impl<mlir::TypeID::get<mlir::OpTrait::HasParent<mlir::scf::ExecuteRegionOp, mlir::scf::ForOp, mlir::scf::IfOp, mlir::scf::IndexSwitchOp, mlir::scf::WhileOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionBranchTerminatorOpInterface::Trait<mlir::TypeID::get<mlir::RegionBranchTerminatorOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ReturnLike<mlir::TypeID::get<mlir::OpTrait::ReturnLike>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::IsTerminator<mlir::TypeID::get<mlir::OpTrait::IsTerminator>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CastOpInterface::Trait<mlir::TypeID::get<mlir::CastOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithFastMathInterface::Trait<mlir::TypeID::get<mlir::arith::ArithFastMathInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithRoundingModeInterface::Trait<mlir::TypeID::get<mlir::arith::ArithRoundingModeInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AtLeastNOperands<2>::Impl<mlir::TypeID::get<mlir::OpTrait::AtLeastNOperands<2>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SameLoadStoreOperandsShape<mlir::TypeID::get<mlir::OpTrait::SameLoadStoreOperandsShape>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SameLoadStoreOperandsEncoding<mlir::TypeID::get<mlir::OpTrait::SameLoadStoreOperandsEncoding>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasParent<mlir::triton::FuncOp>::Impl<mlir::TypeID::get<mlir::OpTrait::HasParent<mlir::triton::FuncOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ValueSemantics<mlir::TypeID::get<mlir::ValueSemantics>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ShapedType::Trait<mlir::TypeID::get<mlir::ShapedType::Trait>()::Empty>)
Load new dialect in Context triton_gpu
Load new dialect in Context gpu
ImplicitTypeIDRegistry::lookupOrInsert(mlir::gpu::AsyncTokenType)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::gpu::MMAMatrixType)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::gpu::SparseDnTensorHandleType)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::gpu::SparseSpMatHandleType)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::gpu::SparseSpGEMMOpHandleType)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::gpu::AsyncOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DataLayoutOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DeviceMappingAttrInterface)
Load new dialect in Context tensor
Load new dialect in Context affine
Load new dialect in Context ub
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ub::PoisonAttrInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineMapAccessInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineDmaStartOp)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineDmaWaitOp)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineReadOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineWriteOpInterface)
Load new dialect in Context complex
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ReifyRankedShapedTypeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ShapedDimOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OffsetSizeAndStrideOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::transform::FindPayloadReplacementOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SubsetOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SubsetInsertionOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SubsetExtractionOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::TilingInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::triton::gpu::TritonGPU_AttrTrait)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::triton::gpu::DistributedEncodingTrait)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::triton::gpu::MmaEncodingTrait)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::triton::DialectInferLayoutInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::OpToOpPassAdaptor)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::VerifiableTensorEncoding)

//===-------------------------------------------===//
Legalizing operation : 'builtin.module'(0x555d5bea1220) {
  * Fold {
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DialectFoldInterface)
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.func'(0x555d5be9ac40) {
} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.constant'(0x555d5be8d620) {
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.constant'(0x555d5be8fc20) {
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'arith.constant -> ()' {
Trying to match "{anonymous}::ArithConstantPattern"
    ** Insert  : 'arith.constant'(0x555d5becd390)
    ** Replace : 'arith.constant'(0x555d5be8fc20)
"{anonymous}::ArithConstantPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'arith.constant'(0x555d5becd390) {
      %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_2 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_3 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %4 = tt.splat %2 : i32 -> tensor<32xi32>
  %5 = arith.addi %4, %3 : tensor<32xi32>
  %6 = arith.muli %1, %c32_i32 : i32
  %7 = tt.splat %6 : i32 -> tensor<32xi32>
  %8 = arith.addi %7, %3 : tensor<32xi32>
  %9 = tt.expand_dims %5 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %10 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %11 = arith.muli %9, %10 : tensor<32x1xi32>
  %12 = tt.expand_dims %3 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %13 = tt.broadcast %11 : tensor<32x1xi32> -> tensor<32x32xi32>
  %14 = tt.broadcast %12 : tensor<1x32xi32> -> tensor<32x32xi32>
  %15 = arith.addi %13, %14 : tensor<32x32xi32>
  %16 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %17 = tt.addptr %16, %15 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %18 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %19 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %20 = arith.muli %18, %19 : tensor<32x1xi32>
  %21 = tt.expand_dims %8 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %22 = tt.broadcast %20 : tensor<32x1xi32> -> tensor<32x32xi32>
  %23 = tt.broadcast %21 : tensor<1x32xi32> -> tensor<32x32xi32>
  %24 = arith.addi %22, %23 : tensor<32x32xi32>
  %25 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %26 = tt.addptr %25, %24 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %27 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %28 = tt.addptr %27, %8 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %29 = arith.addi %arg8, %c31_i32 : i32
  %30 = arith.divsi %29, %c32_i32 : i32
  %31 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %32 = arith.cmpi slt, %9, %31 : tensor<32x1xi32>
  %33 = tt.broadcast %32 : tensor<32x1xi1> -> tensor<32x32xi1>
  %34 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %35 = arith.cmpi slt, %21, %34 : tensor<1x32xi32>
  %36 = tt.broadcast %35 : tensor<1x32xi1> -> tensor<32x32xi1>
  %37 = arith.muli %arg10, %c32_i32 : i32
  %38 = tt.splat %37 : i32 -> tensor<32x32xi32>
  %39:3 = scf.for %arg12 = %c0_i32 to %30 step %c1_i32 iter_args(%arg13 = %cst_3, %arg14 = %17, %arg15 = %26) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %67 = arith.muli %arg12, %c32_i32 : i32
    %68 = arith.subi %arg8, %67 : i32
    %69 = tt.splat %68 : i32 -> tensor<1x32xi32>
    %70 = arith.cmpi slt, %12, %69 : tensor<1x32xi32>
    %71 = tt.broadcast %70 : tensor<1x32xi1> -> tensor<32x32xi1>
    %72 = arith.andi %33, %71 : tensor<32x32xi1>
    %73 = tt.load %arg14, %72, %cst_1 : tensor<32x32x!tt.ptr<f16>>
    %74 = tt.splat %68 : i32 -> tensor<32x1xi32>
    %75 = arith.cmpi slt, %18, %74 : tensor<32x1xi32>
    %76 = tt.broadcast %75 : tensor<32x1xi1> -> tensor<32x32xi1>
    %77 = arith.andi %76, %36 : tensor<32x32xi1>
    %78 = tt.load %arg15, %77, %cst_1 : tensor<32x32x!tt.ptr<f16>>
    %79 = tt.dot %73, %78, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %80 = tt.addptr %arg14, %cst_2 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %81 = tt.addptr %arg15, %38 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %79, %80, %81 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %40 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %41 = arith.cmpi slt, %8, %40 : tensor<32xi32>
  %42 = tt.load %28, %41, %cst_0 : tensor<32x!tt.ptr<f16>>
  %43 = arith.sitofp %arg4 : i32 to f32
  %44 = tt.splat %43 : f32 -> tensor<32x32xf32>
  %45 = arith.mulf %39#0, %44 : tensor<32x32xf32>
  %46 = arith.sitofp %arg5 : i32 to f16
  %47 = tt.splat %46 : f16 -> tensor<32xf16>
  %48 = arith.mulf %42, %47 : tensor<32xf16>
  %49 = tt.expand_dims %48 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %50 = arith.extf %49 : tensor<1x32xf16> to tensor<1x32xf32>
  %51 = tt.broadcast %50 : tensor<1x32xf32> -> tensor<32x32xf32>
  %52 = arith.addf %45, %51 : tensor<32x32xf32>
  %53 = arith.truncf %52 : tensor<32x32xf32> to tensor<32x32xf16>
  %54 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %55 = arith.muli %54, %9 : tensor<32x1xi32>
  %56 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %57 = tt.addptr %56, %55 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %58 = tt.broadcast %57 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %59 = tt.addptr %58, %23 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %60 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %61 = arith.cmpi slt, %9, %60 : tensor<32x1xi32>
  %62 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %63 = arith.cmpi slt, %21, %62 : tensor<1x32xi32>
  %64 = tt.broadcast %61 : tensor<32x1xi1> -> tensor<32x32xi1>
  %65 = tt.broadcast %63 : tensor<1x32xi1> -> tensor<32x32xi1>
  %66 = arith.andi %64, %65 : tensor<32x32xi1>
  tt.store %59, %53, %66 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.constant'(0x555d5be90a40) {
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'arith.constant -> ()' {
Trying to match "{anonymous}::ArithConstantPattern"
    ** Insert  : 'arith.constant'(0x555d5bed34d0)
    ** Replace : 'arith.constant'(0x555d5be90a40)
"{anonymous}::ArithConstantPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'arith.constant'(0x555d5bed34d0) {
      %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_4 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %4 = tt.splat %2 : i32 -> tensor<32xi32>
  %5 = arith.addi %4, %3 : tensor<32xi32>
  %6 = arith.muli %1, %c32_i32 : i32
  %7 = tt.splat %6 : i32 -> tensor<32xi32>
  %8 = arith.addi %7, %3 : tensor<32xi32>
  %9 = tt.expand_dims %5 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %10 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %11 = arith.muli %9, %10 : tensor<32x1xi32>
  %12 = tt.expand_dims %3 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %13 = tt.broadcast %11 : tensor<32x1xi32> -> tensor<32x32xi32>
  %14 = tt.broadcast %12 : tensor<1x32xi32> -> tensor<32x32xi32>
  %15 = arith.addi %13, %14 : tensor<32x32xi32>
  %16 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %17 = tt.addptr %16, %15 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %18 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %19 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %20 = arith.muli %18, %19 : tensor<32x1xi32>
  %21 = tt.expand_dims %8 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %22 = tt.broadcast %20 : tensor<32x1xi32> -> tensor<32x32xi32>
  %23 = tt.broadcast %21 : tensor<1x32xi32> -> tensor<32x32xi32>
  %24 = arith.addi %22, %23 : tensor<32x32xi32>
  %25 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %26 = tt.addptr %25, %24 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %27 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %28 = tt.addptr %27, %8 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %29 = arith.addi %arg8, %c31_i32 : i32
  %30 = arith.divsi %29, %c32_i32 : i32
  %31 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %32 = arith.cmpi slt, %9, %31 : tensor<32x1xi32>
  %33 = tt.broadcast %32 : tensor<32x1xi1> -> tensor<32x32xi1>
  %34 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %35 = arith.cmpi slt, %21, %34 : tensor<1x32xi32>
  %36 = tt.broadcast %35 : tensor<1x32xi1> -> tensor<32x32xi1>
  %37 = arith.muli %arg10, %c32_i32 : i32
  %38 = tt.splat %37 : i32 -> tensor<32x32xi32>
  %39:3 = scf.for %arg12 = %c0_i32 to %30 step %c1_i32 iter_args(%arg13 = %cst_4, %arg14 = %17, %arg15 = %26) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %67 = arith.muli %arg12, %c32_i32 : i32
    %68 = arith.subi %arg8, %67 : i32
    %69 = tt.splat %68 : i32 -> tensor<1x32xi32>
    %70 = arith.cmpi slt, %12, %69 : tensor<1x32xi32>
    %71 = tt.broadcast %70 : tensor<1x32xi1> -> tensor<32x32xi1>
    %72 = arith.andi %33, %71 : tensor<32x32xi1>
    %73 = tt.load %arg14, %72, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %74 = tt.splat %68 : i32 -> tensor<32x1xi32>
    %75 = arith.cmpi slt, %18, %74 : tensor<32x1xi32>
    %76 = tt.broadcast %75 : tensor<32x1xi1> -> tensor<32x32xi1>
    %77 = arith.andi %76, %36 : tensor<32x32xi1>
    %78 = tt.load %arg15, %77, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %79 = tt.dot %73, %78, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %80 = tt.addptr %arg14, %cst_3 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %81 = tt.addptr %arg15, %38 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %79, %80, %81 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %40 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %41 = arith.cmpi slt, %8, %40 : tensor<32xi32>
  %42 = tt.load %28, %41, %cst_0 : tensor<32x!tt.ptr<f16>>
  %43 = arith.sitofp %arg4 : i32 to f32
  %44 = tt.splat %43 : f32 -> tensor<32x32xf32>
  %45 = arith.mulf %39#0, %44 : tensor<32x32xf32>
  %46 = arith.sitofp %arg5 : i32 to f16
  %47 = tt.splat %46 : f16 -> tensor<32xf16>
  %48 = arith.mulf %42, %47 : tensor<32xf16>
  %49 = tt.expand_dims %48 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %50 = arith.extf %49 : tensor<1x32xf16> to tensor<1x32xf32>
  %51 = tt.broadcast %50 : tensor<1x32xf32> -> tensor<32x32xf32>
  %52 = arith.addf %45, %51 : tensor<32x32xf32>
  %53 = arith.truncf %52 : tensor<32x32xf32> to tensor<32x32xf16>
  %54 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %55 = arith.muli %54, %9 : tensor<32x1xi32>
  %56 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %57 = tt.addptr %56, %55 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %58 = tt.broadcast %57 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %59 = tt.addptr %58, %23 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %60 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %61 = arith.cmpi slt, %9, %60 : tensor<32x1xi32>
  %62 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %63 = arith.cmpi slt, %21, %62 : tensor<1x32xi32>
  %64 = tt.broadcast %61 : tensor<32x1xi1> -> tensor<32x32xi1>
  %65 = tt.broadcast %63 : tensor<1x32xi1> -> tensor<32x32xi1>
  %66 = arith.andi %64, %65 : tensor<32x32xi1>
  tt.store %59, %53, %66 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.constant'(0x555d5be918c0) {
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.constant'(0x555d5be91e10) {
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.constant'(0x555d5be92860) {
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'arith.constant -> ()' {
Trying to match "{anonymous}::ArithConstantPattern"
    ** Insert  : 'arith.constant'(0x555d5bed3320)
    ** Replace : 'arith.constant'(0x555d5be92860)
"{anonymous}::ArithConstantPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'arith.constant'(0x555d5bed3320) {
      %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %4 = tt.splat %2 : i32 -> tensor<32xi32>
  %5 = arith.addi %4, %3 : tensor<32xi32>
  %6 = arith.muli %1, %c32_i32 : i32
  %7 = tt.splat %6 : i32 -> tensor<32xi32>
  %8 = arith.addi %7, %3 : tensor<32xi32>
  %9 = tt.expand_dims %5 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %10 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %11 = arith.muli %9, %10 : tensor<32x1xi32>
  %12 = tt.expand_dims %3 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %13 = tt.broadcast %11 : tensor<32x1xi32> -> tensor<32x32xi32>
  %14 = tt.broadcast %12 : tensor<1x32xi32> -> tensor<32x32xi32>
  %15 = arith.addi %13, %14 : tensor<32x32xi32>
  %16 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %17 = tt.addptr %16, %15 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %18 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %19 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %20 = arith.muli %18, %19 : tensor<32x1xi32>
  %21 = tt.expand_dims %8 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %22 = tt.broadcast %20 : tensor<32x1xi32> -> tensor<32x32xi32>
  %23 = tt.broadcast %21 : tensor<1x32xi32> -> tensor<32x32xi32>
  %24 = arith.addi %22, %23 : tensor<32x32xi32>
  %25 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %26 = tt.addptr %25, %24 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %27 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %28 = tt.addptr %27, %8 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %29 = arith.addi %arg8, %c31_i32 : i32
  %30 = arith.divsi %29, %c32_i32 : i32
  %31 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %32 = arith.cmpi slt, %9, %31 : tensor<32x1xi32>
  %33 = tt.broadcast %32 : tensor<32x1xi1> -> tensor<32x32xi1>
  %34 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %35 = arith.cmpi slt, %21, %34 : tensor<1x32xi32>
  %36 = tt.broadcast %35 : tensor<1x32xi1> -> tensor<32x32xi1>
  %37 = arith.muli %arg10, %c32_i32 : i32
  %38 = tt.splat %37 : i32 -> tensor<32x32xi32>
  %39:3 = scf.for %arg12 = %c0_i32 to %30 step %c1_i32 iter_args(%arg13 = %cst_5, %arg14 = %17, %arg15 = %26) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %67 = arith.muli %arg12, %c32_i32 : i32
    %68 = arith.subi %arg8, %67 : i32
    %69 = tt.splat %68 : i32 -> tensor<1x32xi32>
    %70 = arith.cmpi slt, %12, %69 : tensor<1x32xi32>
    %71 = tt.broadcast %70 : tensor<1x32xi1> -> tensor<32x32xi1>
    %72 = arith.andi %33, %71 : tensor<32x32xi1>
    %73 = tt.load %arg14, %72, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %74 = tt.splat %68 : i32 -> tensor<32x1xi32>
    %75 = arith.cmpi slt, %18, %74 : tensor<32x1xi32>
    %76 = tt.broadcast %75 : tensor<32x1xi1> -> tensor<32x32xi1>
    %77 = arith.andi %76, %36 : tensor<32x32xi1>
    %78 = tt.load %arg15, %77, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %79 = tt.dot %73, %78, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %80 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %81 = tt.addptr %arg15, %38 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %79, %80, %81 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %40 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %41 = arith.cmpi slt, %8, %40 : tensor<32xi32>
  %42 = tt.load %28, %41, %cst_0 : tensor<32x!tt.ptr<f16>>
  %43 = arith.sitofp %arg4 : i32 to f32
  %44 = tt.splat %43 : f32 -> tensor<32x32xf32>
  %45 = arith.mulf %39#0, %44 : tensor<32x32xf32>
  %46 = arith.sitofp %arg5 : i32 to f16
  %47 = tt.splat %46 : f16 -> tensor<32xf16>
  %48 = arith.mulf %42, %47 : tensor<32xf16>
  %49 = tt.expand_dims %48 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %50 = arith.extf %49 : tensor<1x32xf16> to tensor<1x32xf32>
  %51 = tt.broadcast %50 : tensor<1x32xf32> -> tensor<32x32xf32>
  %52 = arith.addf %45, %51 : tensor<32x32xf32>
  %53 = arith.truncf %52 : tensor<32x32xf32> to tensor<32x32xf16>
  %54 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %55 = arith.muli %54, %9 : tensor<32x1xi32>
  %56 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %57 = tt.addptr %56, %55 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %58 = tt.broadcast %57 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %59 = tt.addptr %58, %23 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %60 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %61 = arith.cmpi slt, %9, %60 : tensor<32x1xi32>
  %62 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %63 = arith.cmpi slt, %21, %62 : tensor<1x32xi32>
  %64 = tt.broadcast %61 : tensor<32x1xi1> -> tensor<32x32xi1>
  %65 = tt.broadcast %63 : tensor<1x32xi1> -> tensor<32x32xi1>
  %66 = arith.andi %64, %65 : tensor<32x32xi1>
  tt.store %59, %53, %66 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.constant'(0x555d5be94220) {
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'arith.constant -> ()' {
Trying to match "{anonymous}::ArithConstantPattern"
    ** Insert  : 'arith.constant'(0x555d5bed3290)
    ** Replace : 'arith.constant'(0x555d5be94220)
"{anonymous}::ArithConstantPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'arith.constant'(0x555d5bed3290) {
      %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %4 = tt.splat %2 : i32 -> tensor<32xi32>
  %5 = arith.addi %4, %3 : tensor<32xi32>
  %6 = arith.muli %1, %c32_i32 : i32
  %7 = tt.splat %6 : i32 -> tensor<32xi32>
  %8 = arith.addi %7, %3 : tensor<32xi32>
  %9 = tt.expand_dims %5 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %10 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %11 = arith.muli %9, %10 : tensor<32x1xi32>
  %12 = tt.expand_dims %3 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %13 = tt.broadcast %11 : tensor<32x1xi32> -> tensor<32x32xi32>
  %14 = tt.broadcast %12 : tensor<1x32xi32> -> tensor<32x32xi32>
  %15 = arith.addi %13, %14 : tensor<32x32xi32>
  %16 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %17 = tt.addptr %16, %15 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %18 = tt.expand_dims %3 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %19 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %20 = arith.muli %18, %19 : tensor<32x1xi32>
  %21 = tt.expand_dims %8 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %22 = tt.broadcast %20 : tensor<32x1xi32> -> tensor<32x32xi32>
  %23 = tt.broadcast %21 : tensor<1x32xi32> -> tensor<32x32xi32>
  %24 = arith.addi %22, %23 : tensor<32x32xi32>
  %25 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %26 = tt.addptr %25, %24 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %27 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %28 = tt.addptr %27, %8 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %29 = arith.addi %arg8, %c31_i32 : i32
  %30 = arith.divsi %29, %c32_i32 : i32
  %31 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %32 = arith.cmpi slt, %9, %31 : tensor<32x1xi32>
  %33 = tt.broadcast %32 : tensor<32x1xi1> -> tensor<32x32xi1>
  %34 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %35 = arith.cmpi slt, %21, %34 : tensor<1x32xi32>
  %36 = tt.broadcast %35 : tensor<1x32xi1> -> tensor<32x32xi1>
  %37 = arith.muli %arg10, %c32_i32 : i32
  %38 = tt.splat %37 : i32 -> tensor<32x32xi32>
  %39:3 = scf.for %arg12 = %c0_i32 to %30 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %17, %arg15 = %26) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %67 = arith.muli %arg12, %c32_i32 : i32
    %68 = arith.subi %arg8, %67 : i32
    %69 = tt.splat %68 : i32 -> tensor<1x32xi32>
    %70 = arith.cmpi slt, %12, %69 : tensor<1x32xi32>
    %71 = tt.broadcast %70 : tensor<1x32xi1> -> tensor<32x32xi1>
    %72 = arith.andi %33, %71 : tensor<32x32xi1>
    %73 = tt.load %arg14, %72, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %74 = tt.splat %68 : i32 -> tensor<32x1xi32>
    %75 = arith.cmpi slt, %18, %74 : tensor<32x1xi32>
    %76 = tt.broadcast %75 : tensor<32x1xi1> -> tensor<32x32xi1>
    %77 = arith.andi %76, %36 : tensor<32x32xi1>
    %78 = tt.load %arg15, %77, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %79 = tt.dot %73, %78, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %80 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %81 = tt.addptr %arg15, %38 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %79, %80, %81 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %40 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %41 = arith.cmpi slt, %8, %40 : tensor<32xi32>
  %42 = tt.load %28, %41, %cst_0 : tensor<32x!tt.ptr<f16>>
  %43 = arith.sitofp %arg4 : i32 to f32
  %44 = tt.splat %43 : f32 -> tensor<32x32xf32>
  %45 = arith.mulf %39#0, %44 : tensor<32x32xf32>
  %46 = arith.sitofp %arg5 : i32 to f16
  %47 = tt.splat %46 : f16 -> tensor<32xf16>
  %48 = arith.mulf %42, %47 : tensor<32xf16>
  %49 = tt.expand_dims %48 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %50 = arith.extf %49 : tensor<1x32xf16> to tensor<1x32xf32>
  %51 = tt.broadcast %50 : tensor<1x32xf32> -> tensor<32x32xf32>
  %52 = arith.addf %45, %51 : tensor<32x32xf32>
  %53 = arith.truncf %52 : tensor<32x32xf32> to tensor<32x32xf16>
  %54 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %55 = arith.muli %54, %9 : tensor<32x1xi32>
  %56 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %57 = tt.addptr %56, %55 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %58 = tt.broadcast %57 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %59 = tt.addptr %58, %23 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %60 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %61 = arith.cmpi slt, %9, %60 : tensor<32x1xi32>
  %62 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %63 = arith.cmpi slt, %21, %62 : tensor<1x32xi32>
  %64 = tt.broadcast %61 : tensor<32x1xi1> -> tensor<32x32xi1>
  %65 = tt.broadcast %63 : tensor<1x32xi1> -> tensor<32x32xi1>
  %66 = arith.andi %64, %65 : tensor<32x32xi1>
  tt.store %59, %53, %66 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.constant'(0x555d5be94bf0) {
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.get_program_id'(0x555d5be78240) {
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.get_program_id'(0x555d5be81530) {
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.muli'(0x555d5be951e0) {
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.make_range'(0x555d5be96070) {
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.make_range -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::triton::MakeRangeOp>"
ImplicitTypeIDRegistry::lookupOrInsert(mlir::triton::detail::MakeRangeOpGenericAdaptorBase::Properties)
    ** Insert  : 'tt.make_range'(0x555d5bed2870)
    ** Replace : 'tt.make_range'(0x555d5be96070)
"{anonymous}::GenericOpPattern<mlir::triton::MakeRangeOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.make_range'(0x555d5bed2870) {
      %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %5 = tt.splat %2 : i32 -> tensor<32xi32>
  %6 = arith.addi %5, %4 : tensor<32xi32>
  %7 = arith.muli %1, %c32_i32 : i32
  %8 = tt.splat %7 : i32 -> tensor<32xi32>
  %9 = arith.addi %8, %4 : tensor<32xi32>
  %10 = tt.expand_dims %6 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %11 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %12 = arith.muli %10, %11 : tensor<32x1xi32>
  %13 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %14 = tt.broadcast %12 : tensor<32x1xi32> -> tensor<32x32xi32>
  %15 = tt.broadcast %13 : tensor<1x32xi32> -> tensor<32x32xi32>
  %16 = arith.addi %14, %15 : tensor<32x32xi32>
  %17 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %18 = tt.addptr %17, %16 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %19 = tt.expand_dims %4 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %20 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %21 = arith.muli %19, %20 : tensor<32x1xi32>
  %22 = tt.expand_dims %9 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %23 = tt.broadcast %21 : tensor<32x1xi32> -> tensor<32x32xi32>
  %24 = tt.broadcast %22 : tensor<1x32xi32> -> tensor<32x32xi32>
  %25 = arith.addi %23, %24 : tensor<32x32xi32>
  %26 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %27 = tt.addptr %26, %25 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %28 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %29 = tt.addptr %28, %9 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %30 = arith.addi %arg8, %c31_i32 : i32
  %31 = arith.divsi %30, %c32_i32 : i32
  %32 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %33 = arith.cmpi slt, %10, %32 : tensor<32x1xi32>
  %34 = tt.broadcast %33 : tensor<32x1xi1> -> tensor<32x32xi1>
  %35 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %36 = arith.cmpi slt, %22, %35 : tensor<1x32xi32>
  %37 = tt.broadcast %36 : tensor<1x32xi1> -> tensor<32x32xi1>
  %38 = arith.muli %arg10, %c32_i32 : i32
  %39 = tt.splat %38 : i32 -> tensor<32x32xi32>
  %40:3 = scf.for %arg12 = %c0_i32 to %31 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %18, %arg15 = %27) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %68 = arith.muli %arg12, %c32_i32 : i32
    %69 = arith.subi %arg8, %68 : i32
    %70 = tt.splat %69 : i32 -> tensor<1x32xi32>
    %71 = arith.cmpi slt, %13, %70 : tensor<1x32xi32>
    %72 = tt.broadcast %71 : tensor<1x32xi1> -> tensor<32x32xi1>
    %73 = arith.andi %34, %72 : tensor<32x32xi1>
    %74 = tt.load %arg14, %73, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %75 = tt.splat %69 : i32 -> tensor<32x1xi32>
    %76 = arith.cmpi slt, %19, %75 : tensor<32x1xi32>
    %77 = tt.broadcast %76 : tensor<32x1xi1> -> tensor<32x32xi1>
    %78 = arith.andi %77, %37 : tensor<32x32xi1>
    %79 = tt.load %arg15, %78, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %80 = tt.dot %74, %79, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %81 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %82 = tt.addptr %arg15, %39 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %80, %81, %82 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %41 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %42 = arith.cmpi slt, %9, %41 : tensor<32xi32>
  %43 = tt.load %29, %42, %cst_0 : tensor<32x!tt.ptr<f16>>
  %44 = arith.sitofp %arg4 : i32 to f32
  %45 = tt.splat %44 : f32 -> tensor<32x32xf32>
  %46 = arith.mulf %40#0, %45 : tensor<32x32xf32>
  %47 = arith.sitofp %arg5 : i32 to f16
  %48 = tt.splat %47 : f16 -> tensor<32xf16>
  %49 = arith.mulf %43, %48 : tensor<32xf16>
  %50 = tt.expand_dims %49 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %51 = arith.extf %50 : tensor<1x32xf16> to tensor<1x32xf32>
  %52 = tt.broadcast %51 : tensor<1x32xf32> -> tensor<32x32xf32>
  %53 = arith.addf %46, %52 : tensor<32x32xf32>
  %54 = arith.truncf %53 : tensor<32x32xf32> to tensor<32x32xf16>
  %55 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %56 = arith.muli %55, %10 : tensor<32x1xi32>
  %57 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %58 = tt.addptr %57, %56 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %59 = tt.broadcast %58 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %60 = tt.addptr %59, %24 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %61 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %62 = arith.cmpi slt, %10, %61 : tensor<32x1xi32>
  %63 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %64 = arith.cmpi slt, %22, %63 : tensor<1x32xi32>
  %65 = tt.broadcast %62 : tensor<32x1xi1> -> tensor<32x32xi1>
  %66 = tt.broadcast %64 : tensor<1x32xi1> -> tensor<32x32xi1>
  %67 = arith.andi %65, %66 : tensor<32x32xi1>
  tt.store %60, %54, %67 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.splat'(0x555d5be96a40) {
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.splat -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::triton::SplatOp>"
    ** Insert  : 'tt.splat'(0x555d5bebfac0)
    ** Replace : 'tt.splat'(0x555d5be96a40)
"{anonymous}::GenericOpPattern<mlir::triton::SplatOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.splat'(0x555d5bebfac0) {
      %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %5 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32>
  %7 = arith.addi %6, %4 : tensor<32xi32>
  %8 = arith.muli %1, %c32_i32 : i32
  %9 = tt.splat %8 : i32 -> tensor<32xi32>
  %10 = arith.addi %9, %4 : tensor<32xi32>
  %11 = tt.expand_dims %7 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %12 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %13 = arith.muli %11, %12 : tensor<32x1xi32>
  %14 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %15 = tt.broadcast %13 : tensor<32x1xi32> -> tensor<32x32xi32>
  %16 = tt.broadcast %14 : tensor<1x32xi32> -> tensor<32x32xi32>
  %17 = arith.addi %15, %16 : tensor<32x32xi32>
  %18 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %19 = tt.addptr %18, %17 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %20 = tt.expand_dims %4 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %21 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %22 = arith.muli %20, %21 : tensor<32x1xi32>
  %23 = tt.expand_dims %10 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %24 = tt.broadcast %22 : tensor<32x1xi32> -> tensor<32x32xi32>
  %25 = tt.broadcast %23 : tensor<1x32xi32> -> tensor<32x32xi32>
  %26 = arith.addi %24, %25 : tensor<32x32xi32>
  %27 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %28 = tt.addptr %27, %26 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %29 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %30 = tt.addptr %29, %10 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %31 = arith.addi %arg8, %c31_i32 : i32
  %32 = arith.divsi %31, %c32_i32 : i32
  %33 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %34 = arith.cmpi slt, %11, %33 : tensor<32x1xi32>
  %35 = tt.broadcast %34 : tensor<32x1xi1> -> tensor<32x32xi1>
  %36 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %37 = arith.cmpi slt, %23, %36 : tensor<1x32xi32>
  %38 = tt.broadcast %37 : tensor<1x32xi1> -> tensor<32x32xi1>
  %39 = arith.muli %arg10, %c32_i32 : i32
  %40 = tt.splat %39 : i32 -> tensor<32x32xi32>
  %41:3 = scf.for %arg12 = %c0_i32 to %32 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %19, %arg15 = %28) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %69 = arith.muli %arg12, %c32_i32 : i32
    %70 = arith.subi %arg8, %69 : i32
    %71 = tt.splat %70 : i32 -> tensor<1x32xi32>
    %72 = arith.cmpi slt, %14, %71 : tensor<1x32xi32>
    %73 = tt.broadcast %72 : tensor<1x32xi1> -> tensor<32x32xi1>
    %74 = arith.andi %35, %73 : tensor<32x32xi1>
    %75 = tt.load %arg14, %74, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %76 = tt.splat %70 : i32 -> tensor<32x1xi32>
    %77 = arith.cmpi slt, %20, %76 : tensor<32x1xi32>
    %78 = tt.broadcast %77 : tensor<32x1xi1> -> tensor<32x32xi1>
    %79 = arith.andi %78, %38 : tensor<32x32xi1>
    %80 = tt.load %arg15, %79, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %81 = tt.dot %75, %80, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %82 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %83 = tt.addptr %arg15, %40 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %81, %82, %83 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %42 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %43 = arith.cmpi slt, %10, %42 : tensor<32xi32>
  %44 = tt.load %30, %43, %cst_0 : tensor<32x!tt.ptr<f16>>
  %45 = arith.sitofp %arg4 : i32 to f32
  %46 = tt.splat %45 : f32 -> tensor<32x32xf32>
  %47 = arith.mulf %41#0, %46 : tensor<32x32xf32>
  %48 = arith.sitofp %arg5 : i32 to f16
  %49 = tt.splat %48 : f16 -> tensor<32xf16>
  %50 = arith.mulf %44, %49 : tensor<32xf16>
  %51 = tt.expand_dims %50 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %52 = arith.extf %51 : tensor<1x32xf16> to tensor<1x32xf32>
  %53 = tt.broadcast %52 : tensor<1x32xf32> -> tensor<32x32xf32>
  %54 = arith.addf %47, %53 : tensor<32x32xf32>
  %55 = arith.truncf %54 : tensor<32x32xf32> to tensor<32x32xf16>
  %56 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %57 = arith.muli %56, %11 : tensor<32x1xi32>
  %58 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %59 = tt.addptr %58, %57 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %60 = tt.broadcast %59 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %61 = tt.addptr %60, %25 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %62 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %63 = arith.cmpi slt, %11, %62 : tensor<32x1xi32>
  %64 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %65 = arith.cmpi slt, %23, %64 : tensor<1x32xi32>
  %66 = tt.broadcast %63 : tensor<32x1xi1> -> tensor<32x32xi1>
  %67 = tt.broadcast %65 : tensor<1x32xi1> -> tensor<32x32xi1>
  %68 = arith.andi %66, %67 : tensor<32x32xi1>
  tt.store %61, %55, %68 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.addi'(0x555d5be8f0e0) {
  %19 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'arith.addi -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::arith::AddIOp>"
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::detail::AddIOpGenericAdaptorBase::Properties)
    ** Insert  : 'arith.addi'(0x555d5be8dbd0)
    ** Replace : 'arith.addi'(0x555d5be8f0e0)
"{anonymous}::GenericOpPattern<mlir::arith::AddIOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'arith.addi'(0x555d5be8dbd0) {
      %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %5 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32>
  %7 = arith.addi %5, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %8 = arith.addi %6, %4 : tensor<32xi32>
  %9 = arith.muli %1, %c32_i32 : i32
  %10 = tt.splat %9 : i32 -> tensor<32xi32>
  %11 = arith.addi %10, %4 : tensor<32xi32>
  %12 = tt.expand_dims %8 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %13 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %14 = arith.muli %12, %13 : tensor<32x1xi32>
  %15 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %16 = tt.broadcast %14 : tensor<32x1xi32> -> tensor<32x32xi32>
  %17 = tt.broadcast %15 : tensor<1x32xi32> -> tensor<32x32xi32>
  %18 = arith.addi %16, %17 : tensor<32x32xi32>
  %19 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %20 = tt.addptr %19, %18 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %21 = tt.expand_dims %4 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %22 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %23 = arith.muli %21, %22 : tensor<32x1xi32>
  %24 = tt.expand_dims %11 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %25 = tt.broadcast %23 : tensor<32x1xi32> -> tensor<32x32xi32>
  %26 = tt.broadcast %24 : tensor<1x32xi32> -> tensor<32x32xi32>
  %27 = arith.addi %25, %26 : tensor<32x32xi32>
  %28 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %29 = tt.addptr %28, %27 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %30 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %31 = tt.addptr %30, %11 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %32 = arith.addi %arg8, %c31_i32 : i32
  %33 = arith.divsi %32, %c32_i32 : i32
  %34 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %35 = arith.cmpi slt, %12, %34 : tensor<32x1xi32>
  %36 = tt.broadcast %35 : tensor<32x1xi1> -> tensor<32x32xi1>
  %37 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %38 = arith.cmpi slt, %24, %37 : tensor<1x32xi32>
  %39 = tt.broadcast %38 : tensor<1x32xi1> -> tensor<32x32xi1>
  %40 = arith.muli %arg10, %c32_i32 : i32
  %41 = tt.splat %40 : i32 -> tensor<32x32xi32>
  %42:3 = scf.for %arg12 = %c0_i32 to %33 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %20, %arg15 = %29) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %70 = arith.muli %arg12, %c32_i32 : i32
    %71 = arith.subi %arg8, %70 : i32
    %72 = tt.splat %71 : i32 -> tensor<1x32xi32>
    %73 = arith.cmpi slt, %15, %72 : tensor<1x32xi32>
    %74 = tt.broadcast %73 : tensor<1x32xi1> -> tensor<32x32xi1>
    %75 = arith.andi %36, %74 : tensor<32x32xi1>
    %76 = tt.load %arg14, %75, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %77 = tt.splat %71 : i32 -> tensor<32x1xi32>
    %78 = arith.cmpi slt, %21, %77 : tensor<32x1xi32>
    %79 = tt.broadcast %78 : tensor<32x1xi1> -> tensor<32x32xi1>
    %80 = arith.andi %79, %39 : tensor<32x32xi1>
    %81 = tt.load %arg15, %80, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %82 = tt.dot %76, %81, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %83 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %84 = tt.addptr %arg15, %41 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %82, %83, %84 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %43 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %44 = arith.cmpi slt, %11, %43 : tensor<32xi32>
  %45 = tt.load %31, %44, %cst_0 : tensor<32x!tt.ptr<f16>>
  %46 = arith.sitofp %arg4 : i32 to f32
  %47 = tt.splat %46 : f32 -> tensor<32x32xf32>
  %48 = arith.mulf %42#0, %47 : tensor<32x32xf32>
  %49 = arith.sitofp %arg5 : i32 to f16
  %50 = tt.splat %49 : f16 -> tensor<32xf16>
  %51 = arith.mulf %45, %50 : tensor<32xf16>
  %52 = tt.expand_dims %51 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %53 = arith.extf %52 : tensor<1x32xf16> to tensor<1x32xf32>
  %54 = tt.broadcast %53 : tensor<1x32xf32> -> tensor<32x32xf32>
  %55 = arith.addf %48, %54 : tensor<32x32xf32>
  %56 = arith.truncf %55 : tensor<32x32xf32> to tensor<32x32xf16>
  %57 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %58 = arith.muli %57, %12 : tensor<32x1xi32>
  %59 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %60 = tt.addptr %59, %58 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %61 = tt.broadcast %60 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %62 = tt.addptr %61, %26 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %63 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %64 = arith.cmpi slt, %12, %63 : tensor<32x1xi32>
  %65 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %66 = arith.cmpi slt, %24, %65 : tensor<1x32xi32>
  %67 = tt.broadcast %64 : tensor<32x1xi1> -> tensor<32x32xi1>
  %68 = tt.broadcast %66 : tensor<1x32xi1> -> tensor<32x32xi1>
  %69 = arith.andi %67, %68 : tensor<32x32xi1>
  tt.store %62, %56, %69 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.muli'(0x555d5be8f260) {
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.splat'(0x555d5be8f370) {
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.splat -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::triton::SplatOp>"
    ** Insert  : 'tt.splat'(0x555d5becc130)
    ** Replace : 'tt.splat'(0x555d5be8f370)
"{anonymous}::GenericOpPattern<mlir::triton::SplatOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.splat'(0x555d5becc130) {
      %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %5 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32>
  %7 = arith.addi %5, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %8 = arith.addi %6, %4 : tensor<32xi32>
  %9 = arith.muli %1, %c32_i32 : i32
  %10 = tt.splat %9 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %11 = tt.splat %9 : i32 -> tensor<32xi32>
  %12 = arith.addi %11, %4 : tensor<32xi32>
  %13 = tt.expand_dims %8 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %14 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %15 = arith.muli %13, %14 : tensor<32x1xi32>
  %16 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %17 = tt.broadcast %15 : tensor<32x1xi32> -> tensor<32x32xi32>
  %18 = tt.broadcast %16 : tensor<1x32xi32> -> tensor<32x32xi32>
  %19 = arith.addi %17, %18 : tensor<32x32xi32>
  %20 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %21 = tt.addptr %20, %19 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %22 = tt.expand_dims %4 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %23 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %24 = arith.muli %22, %23 : tensor<32x1xi32>
  %25 = tt.expand_dims %12 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %26 = tt.broadcast %24 : tensor<32x1xi32> -> tensor<32x32xi32>
  %27 = tt.broadcast %25 : tensor<1x32xi32> -> tensor<32x32xi32>
  %28 = arith.addi %26, %27 : tensor<32x32xi32>
  %29 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %31 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %32 = tt.addptr %31, %12 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %33 = arith.addi %arg8, %c31_i32 : i32
  %34 = arith.divsi %33, %c32_i32 : i32
  %35 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %36 = arith.cmpi slt, %13, %35 : tensor<32x1xi32>
  %37 = tt.broadcast %36 : tensor<32x1xi1> -> tensor<32x32xi1>
  %38 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %39 = arith.cmpi slt, %25, %38 : tensor<1x32xi32>
  %40 = tt.broadcast %39 : tensor<1x32xi1> -> tensor<32x32xi1>
  %41 = arith.muli %arg10, %c32_i32 : i32
  %42 = tt.splat %41 : i32 -> tensor<32x32xi32>
  %43:3 = scf.for %arg12 = %c0_i32 to %34 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %21, %arg15 = %30) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %71 = arith.muli %arg12, %c32_i32 : i32
    %72 = arith.subi %arg8, %71 : i32
    %73 = tt.splat %72 : i32 -> tensor<1x32xi32>
    %74 = arith.cmpi slt, %16, %73 : tensor<1x32xi32>
    %75 = tt.broadcast %74 : tensor<1x32xi1> -> tensor<32x32xi1>
    %76 = arith.andi %37, %75 : tensor<32x32xi1>
    %77 = tt.load %arg14, %76, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %78 = tt.splat %72 : i32 -> tensor<32x1xi32>
    %79 = arith.cmpi slt, %22, %78 : tensor<32x1xi32>
    %80 = tt.broadcast %79 : tensor<32x1xi1> -> tensor<32x32xi1>
    %81 = arith.andi %80, %40 : tensor<32x32xi1>
    %82 = tt.load %arg15, %81, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %83 = tt.dot %77, %82, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %84 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %85 = tt.addptr %arg15, %42 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %83, %84, %85 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %44 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %45 = arith.cmpi slt, %12, %44 : tensor<32xi32>
  %46 = tt.load %32, %45, %cst_0 : tensor<32x!tt.ptr<f16>>
  %47 = arith.sitofp %arg4 : i32 to f32
  %48 = tt.splat %47 : f32 -> tensor<32x32xf32>
  %49 = arith.mulf %43#0, %48 : tensor<32x32xf32>
  %50 = arith.sitofp %arg5 : i32 to f16
  %51 = tt.splat %50 : f16 -> tensor<32xf16>
  %52 = arith.mulf %46, %51 : tensor<32xf16>
  %53 = tt.expand_dims %52 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %54 = arith.extf %53 : tensor<1x32xf16> to tensor<1x32xf32>
  %55 = tt.broadcast %54 : tensor<1x32xf32> -> tensor<32x32xf32>
  %56 = arith.addf %49, %55 : tensor<32x32xf32>
  %57 = arith.truncf %56 : tensor<32x32xf32> to tensor<32x32xf16>
  %58 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %59 = arith.muli %58, %13 : tensor<32x1xi32>
  %60 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %61 = tt.addptr %60, %59 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %62 = tt.broadcast %61 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %63 = tt.addptr %62, %27 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %64 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %65 = arith.cmpi slt, %13, %64 : tensor<32x1xi32>
  %66 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %67 = arith.cmpi slt, %25, %66 : tensor<1x32xi32>
  %68 = tt.broadcast %65 : tensor<32x1xi1> -> tensor<32x32xi1>
  %69 = tt.broadcast %67 : tensor<1x32xi1> -> tensor<32x32xi1>
  %70 = arith.andi %68, %69 : tensor<32x32xi1>
  tt.store %63, %57, %70 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.addi'(0x555d5be975c0) {
  %24 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'arith.addi -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::arith::AddIOp>"
    ** Insert  : 'arith.addi'(0x555d5be8dc80)
    ** Replace : 'arith.addi'(0x555d5be975c0)
"{anonymous}::GenericOpPattern<mlir::arith::AddIOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'arith.addi'(0x555d5be8dc80) {
      %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %5 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32>
  %7 = arith.addi %5, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %8 = arith.addi %6, %4 : tensor<32xi32>
  %9 = arith.muli %1, %c32_i32 : i32
  %10 = tt.splat %9 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %11 = tt.splat %9 : i32 -> tensor<32xi32>
  %12 = arith.addi %10, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %13 = arith.addi %11, %4 : tensor<32xi32>
  %14 = tt.expand_dims %8 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %15 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %16 = arith.muli %14, %15 : tensor<32x1xi32>
  %17 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %18 = tt.broadcast %16 : tensor<32x1xi32> -> tensor<32x32xi32>
  %19 = tt.broadcast %17 : tensor<1x32xi32> -> tensor<32x32xi32>
  %20 = arith.addi %18, %19 : tensor<32x32xi32>
  %21 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %22 = tt.addptr %21, %20 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %23 = tt.expand_dims %4 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %24 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %25 = arith.muli %23, %24 : tensor<32x1xi32>
  %26 = tt.expand_dims %13 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %27 = tt.broadcast %25 : tensor<32x1xi32> -> tensor<32x32xi32>
  %28 = tt.broadcast %26 : tensor<1x32xi32> -> tensor<32x32xi32>
  %29 = arith.addi %27, %28 : tensor<32x32xi32>
  %30 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %31 = tt.addptr %30, %29 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %32 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %33 = tt.addptr %32, %13 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %34 = arith.addi %arg8, %c31_i32 : i32
  %35 = arith.divsi %34, %c32_i32 : i32
  %36 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %37 = arith.cmpi slt, %14, %36 : tensor<32x1xi32>
  %38 = tt.broadcast %37 : tensor<32x1xi1> -> tensor<32x32xi1>
  %39 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %40 = arith.cmpi slt, %26, %39 : tensor<1x32xi32>
  %41 = tt.broadcast %40 : tensor<1x32xi1> -> tensor<32x32xi1>
  %42 = arith.muli %arg10, %c32_i32 : i32
  %43 = tt.splat %42 : i32 -> tensor<32x32xi32>
  %44:3 = scf.for %arg12 = %c0_i32 to %35 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %22, %arg15 = %31) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %72 = arith.muli %arg12, %c32_i32 : i32
    %73 = arith.subi %arg8, %72 : i32
    %74 = tt.splat %73 : i32 -> tensor<1x32xi32>
    %75 = arith.cmpi slt, %17, %74 : tensor<1x32xi32>
    %76 = tt.broadcast %75 : tensor<1x32xi1> -> tensor<32x32xi1>
    %77 = arith.andi %38, %76 : tensor<32x32xi1>
    %78 = tt.load %arg14, %77, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %79 = tt.splat %73 : i32 -> tensor<32x1xi32>
    %80 = arith.cmpi slt, %23, %79 : tensor<32x1xi32>
    %81 = tt.broadcast %80 : tensor<32x1xi1> -> tensor<32x32xi1>
    %82 = arith.andi %81, %41 : tensor<32x32xi1>
    %83 = tt.load %arg15, %82, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %84 = tt.dot %78, %83, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %85 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %86 = tt.addptr %arg15, %43 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %84, %85, %86 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %45 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %46 = arith.cmpi slt, %13, %45 : tensor<32xi32>
  %47 = tt.load %33, %46, %cst_0 : tensor<32x!tt.ptr<f16>>
  %48 = arith.sitofp %arg4 : i32 to f32
  %49 = tt.splat %48 : f32 -> tensor<32x32xf32>
  %50 = arith.mulf %44#0, %49 : tensor<32x32xf32>
  %51 = arith.sitofp %arg5 : i32 to f16
  %52 = tt.splat %51 : f16 -> tensor<32xf16>
  %53 = arith.mulf %47, %52 : tensor<32xf16>
  %54 = tt.expand_dims %53 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %55 = arith.extf %54 : tensor<1x32xf16> to tensor<1x32xf32>
  %56 = tt.broadcast %55 : tensor<1x32xf32> -> tensor<32x32xf32>
  %57 = arith.addf %50, %56 : tensor<32x32xf32>
  %58 = arith.truncf %57 : tensor<32x32xf32> to tensor<32x32xf16>
  %59 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %60 = arith.muli %59, %14 : tensor<32x1xi32>
  %61 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %62 = tt.addptr %61, %60 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %63 = tt.broadcast %62 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %64 = tt.addptr %63, %28 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %65 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %66 = arith.cmpi slt, %14, %65 : tensor<32x1xi32>
  %67 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %68 = arith.cmpi slt, %26, %67 : tensor<1x32xi32>
  %69 = tt.broadcast %66 : tensor<32x1xi1> -> tensor<32x32xi1>
  %70 = tt.broadcast %68 : tensor<1x32xi1> -> tensor<32x32xi1>
  %71 = arith.andi %69, %70 : tensor<32x32xi1>
  tt.store %64, %58, %71 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.expand_dims'(0x555d5be982e0) {
  %26 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.expand_dims -> ()' {
Trying to match "{anonymous}::TritonExpandDimsPattern"
    ** Insert  : 'triton_gpu.convert_layout'(0x555d5bed20e0)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::triton::detail::ExpandDimsOpGenericAdaptorBase::Properties)
    ** Insert  : 'tt.expand_dims'(0x555d5becc1f0)
    ** Replace : 'tt.expand_dims'(0x555d5be982e0)
"{anonymous}::TritonExpandDimsPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'triton_gpu.convert_layout'(0x555d5bed20e0) {
      %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'tt.expand_dims'(0x555d5becc1f0) {
      %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %5 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32>
  %7 = arith.addi %5, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %8 = arith.addi %6, %4 : tensor<32xi32>
  %9 = arith.muli %1, %c32_i32 : i32
  %10 = tt.splat %9 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %11 = tt.splat %9 : i32 -> tensor<32xi32>
  %12 = arith.addi %10, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %13 = arith.addi %11, %4 : tensor<32xi32>
  %14 = triton_gpu.convert_layout %7 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %15 = tt.expand_dims %14 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %16 = tt.expand_dims %8 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %17 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %18 = arith.muli %16, %17 : tensor<32x1xi32>
  %19 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %20 = tt.broadcast %18 : tensor<32x1xi32> -> tensor<32x32xi32>
  %21 = tt.broadcast %19 : tensor<1x32xi32> -> tensor<32x32xi32>
  %22 = arith.addi %20, %21 : tensor<32x32xi32>
  %23 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %24 = tt.addptr %23, %22 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %25 = tt.expand_dims %4 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %26 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %27 = arith.muli %25, %26 : tensor<32x1xi32>
  %28 = tt.expand_dims %13 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %29 = tt.broadcast %27 : tensor<32x1xi32> -> tensor<32x32xi32>
  %30 = tt.broadcast %28 : tensor<1x32xi32> -> tensor<32x32xi32>
  %31 = arith.addi %29, %30 : tensor<32x32xi32>
  %32 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %33 = tt.addptr %32, %31 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %34 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %35 = tt.addptr %34, %13 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %36 = arith.addi %arg8, %c31_i32 : i32
  %37 = arith.divsi %36, %c32_i32 : i32
  %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %39 = arith.cmpi slt, %16, %38 : tensor<32x1xi32>
  %40 = tt.broadcast %39 : tensor<32x1xi1> -> tensor<32x32xi1>
  %41 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %42 = arith.cmpi slt, %28, %41 : tensor<1x32xi32>
  %43 = tt.broadcast %42 : tensor<1x32xi1> -> tensor<32x32xi1>
  %44 = arith.muli %arg10, %c32_i32 : i32
  %45 = tt.splat %44 : i32 -> tensor<32x32xi32>
  %46:3 = scf.for %arg12 = %c0_i32 to %37 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %24, %arg15 = %33) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %74 = arith.muli %arg12, %c32_i32 : i32
    %75 = arith.subi %arg8, %74 : i32
    %76 = tt.splat %75 : i32 -> tensor<1x32xi32>
    %77 = arith.cmpi slt, %19, %76 : tensor<1x32xi32>
    %78 = tt.broadcast %77 : tensor<1x32xi1> -> tensor<32x32xi1>
    %79 = arith.andi %40, %78 : tensor<32x32xi1>
    %80 = tt.load %arg14, %79, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %81 = tt.splat %75 : i32 -> tensor<32x1xi32>
    %82 = arith.cmpi slt, %25, %81 : tensor<32x1xi32>
    %83 = tt.broadcast %82 : tensor<32x1xi1> -> tensor<32x32xi1>
    %84 = arith.andi %83, %43 : tensor<32x32xi1>
    %85 = tt.load %arg15, %84, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %86 = tt.dot %80, %85, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %87 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %88 = tt.addptr %arg15, %45 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %86, %87, %88 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %47 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %48 = arith.cmpi slt, %13, %47 : tensor<32xi32>
  %49 = tt.load %35, %48, %cst_0 : tensor<32x!tt.ptr<f16>>
  %50 = arith.sitofp %arg4 : i32 to f32
  %51 = tt.splat %50 : f32 -> tensor<32x32xf32>
  %52 = arith.mulf %46#0, %51 : tensor<32x32xf32>
  %53 = arith.sitofp %arg5 : i32 to f16
  %54 = tt.splat %53 : f16 -> tensor<32xf16>
  %55 = arith.mulf %49, %54 : tensor<32xf16>
  %56 = tt.expand_dims %55 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %57 = arith.extf %56 : tensor<1x32xf16> to tensor<1x32xf32>
  %58 = tt.broadcast %57 : tensor<1x32xf32> -> tensor<32x32xf32>
  %59 = arith.addf %52, %58 : tensor<32x32xf32>
  %60 = arith.truncf %59 : tensor<32x32xf32> to tensor<32x32xf16>
  %61 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %62 = arith.muli %61, %16 : tensor<32x1xi32>
  %63 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %64 = tt.addptr %63, %62 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %65 = tt.broadcast %64 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %66 = tt.addptr %65, %30 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %67 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %68 = arith.cmpi slt, %16, %67 : tensor<32x1xi32>
  %69 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %70 = arith.cmpi slt, %28, %69 : tensor<1x32xi32>
  %71 = tt.broadcast %68 : tensor<32x1xi1> -> tensor<32x32xi1>
  %72 = tt.broadcast %70 : tensor<1x32xi1> -> tensor<32x32xi1>
  %73 = arith.andi %71, %72 : tensor<32x32xi1>
  tt.store %66, %60, %73 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.splat'(0x555d5be983d0) {
  %29 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.splat -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::triton::SplatOp>"
    ** Insert  : 'tt.splat'(0x555d5bed2680)
    ** Replace : 'tt.splat'(0x555d5be983d0)
"{anonymous}::GenericOpPattern<mlir::triton::SplatOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.splat'(0x555d5bed2680) {
      %29 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %5 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32>
  %7 = arith.addi %5, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %8 = arith.addi %6, %4 : tensor<32xi32>
  %9 = arith.muli %1, %c32_i32 : i32
  %10 = tt.splat %9 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %11 = tt.splat %9 : i32 -> tensor<32xi32>
  %12 = arith.addi %10, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %13 = arith.addi %11, %4 : tensor<32xi32>
  %14 = triton_gpu.convert_layout %7 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %15 = tt.expand_dims %14 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %16 = tt.expand_dims %8 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %17 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %18 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %19 = arith.muli %16, %18 : tensor<32x1xi32>
  %20 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %21 = tt.broadcast %19 : tensor<32x1xi32> -> tensor<32x32xi32>
  %22 = tt.broadcast %20 : tensor<1x32xi32> -> tensor<32x32xi32>
  %23 = arith.addi %21, %22 : tensor<32x32xi32>
  %24 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %25 = tt.addptr %24, %23 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %26 = tt.expand_dims %4 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %27 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %28 = arith.muli %26, %27 : tensor<32x1xi32>
  %29 = tt.expand_dims %13 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %30 = tt.broadcast %28 : tensor<32x1xi32> -> tensor<32x32xi32>
  %31 = tt.broadcast %29 : tensor<1x32xi32> -> tensor<32x32xi32>
  %32 = arith.addi %30, %31 : tensor<32x32xi32>
  %33 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %34 = tt.addptr %33, %32 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %35 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %36 = tt.addptr %35, %13 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %37 = arith.addi %arg8, %c31_i32 : i32
  %38 = arith.divsi %37, %c32_i32 : i32
  %39 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %40 = arith.cmpi slt, %16, %39 : tensor<32x1xi32>
  %41 = tt.broadcast %40 : tensor<32x1xi1> -> tensor<32x32xi1>
  %42 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %43 = arith.cmpi slt, %29, %42 : tensor<1x32xi32>
  %44 = tt.broadcast %43 : tensor<1x32xi1> -> tensor<32x32xi1>
  %45 = arith.muli %arg10, %c32_i32 : i32
  %46 = tt.splat %45 : i32 -> tensor<32x32xi32>
  %47:3 = scf.for %arg12 = %c0_i32 to %38 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %25, %arg15 = %34) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %75 = arith.muli %arg12, %c32_i32 : i32
    %76 = arith.subi %arg8, %75 : i32
    %77 = tt.splat %76 : i32 -> tensor<1x32xi32>
    %78 = arith.cmpi slt, %20, %77 : tensor<1x32xi32>
    %79 = tt.broadcast %78 : tensor<1x32xi1> -> tensor<32x32xi1>
    %80 = arith.andi %41, %79 : tensor<32x32xi1>
    %81 = tt.load %arg14, %80, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %82 = tt.splat %76 : i32 -> tensor<32x1xi32>
    %83 = arith.cmpi slt, %26, %82 : tensor<32x1xi32>
    %84 = tt.broadcast %83 : tensor<32x1xi1> -> tensor<32x32xi1>
    %85 = arith.andi %84, %44 : tensor<32x32xi1>
    %86 = tt.load %arg15, %85, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %87 = tt.dot %81, %86, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %88 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %89 = tt.addptr %arg15, %46 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %87, %88, %89 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %48 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %49 = arith.cmpi slt, %13, %48 : tensor<32xi32>
  %50 = tt.load %36, %49, %cst_0 : tensor<32x!tt.ptr<f16>>
  %51 = arith.sitofp %arg4 : i32 to f32
  %52 = tt.splat %51 : f32 -> tensor<32x32xf32>
  %53 = arith.mulf %47#0, %52 : tensor<32x32xf32>
  %54 = arith.sitofp %arg5 : i32 to f16
  %55 = tt.splat %54 : f16 -> tensor<32xf16>
  %56 = arith.mulf %50, %55 : tensor<32xf16>
  %57 = tt.expand_dims %56 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %58 = arith.extf %57 : tensor<1x32xf16> to tensor<1x32xf32>
  %59 = tt.broadcast %58 : tensor<1x32xf32> -> tensor<32x32xf32>
  %60 = arith.addf %53, %59 : tensor<32x32xf32>
  %61 = arith.truncf %60 : tensor<32x32xf32> to tensor<32x32xf16>
  %62 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %63 = arith.muli %62, %16 : tensor<32x1xi32>
  %64 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %65 = tt.addptr %64, %63 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %66 = tt.broadcast %65 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %67 = tt.addptr %66, %31 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %68 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %69 = arith.cmpi slt, %16, %68 : tensor<32x1xi32>
  %70 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %71 = arith.cmpi slt, %29, %70 : tensor<1x32xi32>
  %72 = tt.broadcast %69 : tensor<32x1xi1> -> tensor<32x32xi1>
  %73 = tt.broadcast %71 : tensor<1x32xi1> -> tensor<32x32xi1>
  %74 = arith.andi %72, %73 : tensor<32x32xi1>
  tt.store %67, %61, %74 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.muli'(0x555d5be984c0) {
  %31 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'arith.muli -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::arith::MulIOp>"
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::detail::MulIOpGenericAdaptorBase::Properties)
    ** Insert  : 'arith.muli'(0x555d5bed6e40)
    ** Replace : 'arith.muli'(0x555d5be984c0)
"{anonymous}::GenericOpPattern<mlir::arith::MulIOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'arith.muli'(0x555d5bed6e40) {
      %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %5 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32>
  %7 = arith.addi %5, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %8 = arith.addi %6, %4 : tensor<32xi32>
  %9 = arith.muli %1, %c32_i32 : i32
  %10 = tt.splat %9 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %11 = tt.splat %9 : i32 -> tensor<32xi32>
  %12 = arith.addi %10, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %13 = arith.addi %11, %4 : tensor<32xi32>
  %14 = triton_gpu.convert_layout %7 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %15 = tt.expand_dims %14 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %16 = builtin.unrealized_conversion_cast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.expand_dims %8 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %18 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %20 = arith.muli %16, %18 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = arith.muli %17, %19 : tensor<32x1xi32>
  %22 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %23 = tt.broadcast %21 : tensor<32x1xi32> -> tensor<32x32xi32>
  %24 = tt.broadcast %22 : tensor<1x32xi32> -> tensor<32x32xi32>
  %25 = arith.addi %23, %24 : tensor<32x32xi32>
  %26 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %27 = tt.addptr %26, %25 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %28 = tt.expand_dims %4 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %29 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %30 = arith.muli %28, %29 : tensor<32x1xi32>
  %31 = tt.expand_dims %13 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %32 = tt.broadcast %30 : tensor<32x1xi32> -> tensor<32x32xi32>
  %33 = tt.broadcast %31 : tensor<1x32xi32> -> tensor<32x32xi32>
  %34 = arith.addi %32, %33 : tensor<32x32xi32>
  %35 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %36 = tt.addptr %35, %34 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %37 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %38 = tt.addptr %37, %13 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %39 = arith.addi %arg8, %c31_i32 : i32
  %40 = arith.divsi %39, %c32_i32 : i32
  %41 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %42 = arith.cmpi slt, %17, %41 : tensor<32x1xi32>
  %43 = tt.broadcast %42 : tensor<32x1xi1> -> tensor<32x32xi1>
  %44 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %45 = arith.cmpi slt, %31, %44 : tensor<1x32xi32>
  %46 = tt.broadcast %45 : tensor<1x32xi1> -> tensor<32x32xi1>
  %47 = arith.muli %arg10, %c32_i32 : i32
  %48 = tt.splat %47 : i32 -> tensor<32x32xi32>
  %49:3 = scf.for %arg12 = %c0_i32 to %40 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %27, %arg15 = %36) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %77 = arith.muli %arg12, %c32_i32 : i32
    %78 = arith.subi %arg8, %77 : i32
    %79 = tt.splat %78 : i32 -> tensor<1x32xi32>
    %80 = arith.cmpi slt, %22, %79 : tensor<1x32xi32>
    %81 = tt.broadcast %80 : tensor<1x32xi1> -> tensor<32x32xi1>
    %82 = arith.andi %43, %81 : tensor<32x32xi1>
    %83 = tt.load %arg14, %82, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %84 = tt.splat %78 : i32 -> tensor<32x1xi32>
    %85 = arith.cmpi slt, %28, %84 : tensor<32x1xi32>
    %86 = tt.broadcast %85 : tensor<32x1xi1> -> tensor<32x32xi1>
    %87 = arith.andi %86, %46 : tensor<32x32xi1>
    %88 = tt.load %arg15, %87, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %89 = tt.dot %83, %88, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %90 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %91 = tt.addptr %arg15, %48 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %89, %90, %91 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %50 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %51 = arith.cmpi slt, %13, %50 : tensor<32xi32>
  %52 = tt.load %38, %51, %cst_0 : tensor<32x!tt.ptr<f16>>
  %53 = arith.sitofp %arg4 : i32 to f32
  %54 = tt.splat %53 : f32 -> tensor<32x32xf32>
  %55 = arith.mulf %49#0, %54 : tensor<32x32xf32>
  %56 = arith.sitofp %arg5 : i32 to f16
  %57 = tt.splat %56 : f16 -> tensor<32xf16>
  %58 = arith.mulf %52, %57 : tensor<32xf16>
  %59 = tt.expand_dims %58 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %60 = arith.extf %59 : tensor<1x32xf16> to tensor<1x32xf32>
  %61 = tt.broadcast %60 : tensor<1x32xf32> -> tensor<32x32xf32>
  %62 = arith.addf %55, %61 : tensor<32x32xf32>
  %63 = arith.truncf %62 : tensor<32x32xf32> to tensor<32x32xf16>
  %64 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %65 = arith.muli %64, %17 : tensor<32x1xi32>
  %66 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %67 = tt.addptr %66, %65 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %68 = tt.broadcast %67 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %69 = tt.addptr %68, %33 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %70 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %71 = arith.cmpi slt, %17, %70 : tensor<32x1xi32>
  %72 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %73 = arith.cmpi slt, %31, %72 : tensor<1x32xi32>
  %74 = tt.broadcast %71 : tensor<32x1xi1> -> tensor<32x32xi1>
  %75 = tt.broadcast %73 : tensor<1x32xi1> -> tensor<32x32xi1>
  %76 = arith.andi %74, %75 : tensor<32x32xi1>
  tt.store %69, %63, %76 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.expand_dims'(0x555d5be98a50) {
  %34 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.expand_dims -> ()' {
Trying to match "{anonymous}::TritonExpandDimsPattern"
    ** Insert  : 'triton_gpu.convert_layout'(0x555d5bed6ff0)
    ** Insert  : 'tt.expand_dims'(0x555d5bed71d0)
    ** Replace : 'tt.expand_dims'(0x555d5be98a50)
"{anonymous}::TritonExpandDimsPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'triton_gpu.convert_layout'(0x555d5bed6ff0) {
      %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'tt.expand_dims'(0x555d5bed71d0) {
      %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %5 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32>
  %7 = arith.addi %5, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %8 = arith.addi %6, %4 : tensor<32xi32>
  %9 = arith.muli %1, %c32_i32 : i32
  %10 = tt.splat %9 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %11 = tt.splat %9 : i32 -> tensor<32xi32>
  %12 = arith.addi %10, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %13 = arith.addi %11, %4 : tensor<32xi32>
  %14 = triton_gpu.convert_layout %7 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %15 = tt.expand_dims %14 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %16 = builtin.unrealized_conversion_cast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.expand_dims %8 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %18 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %20 = arith.muli %16, %18 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = arith.muli %17, %19 : tensor<32x1xi32>
  %22 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %23 = tt.expand_dims %22 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %24 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %25 = tt.broadcast %21 : tensor<32x1xi32> -> tensor<32x32xi32>
  %26 = tt.broadcast %24 : tensor<1x32xi32> -> tensor<32x32xi32>
  %27 = arith.addi %25, %26 : tensor<32x32xi32>
  %28 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %29 = tt.addptr %28, %27 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %30 = tt.expand_dims %4 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %31 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %32 = arith.muli %30, %31 : tensor<32x1xi32>
  %33 = tt.expand_dims %13 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %34 = tt.broadcast %32 : tensor<32x1xi32> -> tensor<32x32xi32>
  %35 = tt.broadcast %33 : tensor<1x32xi32> -> tensor<32x32xi32>
  %36 = arith.addi %34, %35 : tensor<32x32xi32>
  %37 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %38 = tt.addptr %37, %36 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %39 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %40 = tt.addptr %39, %13 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %41 = arith.addi %arg8, %c31_i32 : i32
  %42 = arith.divsi %41, %c32_i32 : i32
  %43 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %44 = arith.cmpi slt, %17, %43 : tensor<32x1xi32>
  %45 = tt.broadcast %44 : tensor<32x1xi1> -> tensor<32x32xi1>
  %46 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %47 = arith.cmpi slt, %33, %46 : tensor<1x32xi32>
  %48 = tt.broadcast %47 : tensor<1x32xi1> -> tensor<32x32xi1>
  %49 = arith.muli %arg10, %c32_i32 : i32
  %50 = tt.splat %49 : i32 -> tensor<32x32xi32>
  %51:3 = scf.for %arg12 = %c0_i32 to %42 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %29, %arg15 = %38) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %79 = arith.muli %arg12, %c32_i32 : i32
    %80 = arith.subi %arg8, %79 : i32
    %81 = tt.splat %80 : i32 -> tensor<1x32xi32>
    %82 = arith.cmpi slt, %24, %81 : tensor<1x32xi32>
    %83 = tt.broadcast %82 : tensor<1x32xi1> -> tensor<32x32xi1>
    %84 = arith.andi %45, %83 : tensor<32x32xi1>
    %85 = tt.load %arg14, %84, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %86 = tt.splat %80 : i32 -> tensor<32x1xi32>
    %87 = arith.cmpi slt, %30, %86 : tensor<32x1xi32>
    %88 = tt.broadcast %87 : tensor<32x1xi1> -> tensor<32x32xi1>
    %89 = arith.andi %88, %48 : tensor<32x32xi1>
    %90 = tt.load %arg15, %89, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %91 = tt.dot %85, %90, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %92 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %93 = tt.addptr %arg15, %50 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %91, %92, %93 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %52 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %53 = arith.cmpi slt, %13, %52 : tensor<32xi32>
  %54 = tt.load %40, %53, %cst_0 : tensor<32x!tt.ptr<f16>>
  %55 = arith.sitofp %arg4 : i32 to f32
  %56 = tt.splat %55 : f32 -> tensor<32x32xf32>
  %57 = arith.mulf %51#0, %56 : tensor<32x32xf32>
  %58 = arith.sitofp %arg5 : i32 to f16
  %59 = tt.splat %58 : f16 -> tensor<32xf16>
  %60 = arith.mulf %54, %59 : tensor<32xf16>
  %61 = tt.expand_dims %60 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %62 = arith.extf %61 : tensor<1x32xf16> to tensor<1x32xf32>
  %63 = tt.broadcast %62 : tensor<1x32xf32> -> tensor<32x32xf32>
  %64 = arith.addf %57, %63 : tensor<32x32xf32>
  %65 = arith.truncf %64 : tensor<32x32xf32> to tensor<32x32xf16>
  %66 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %67 = arith.muli %66, %17 : tensor<32x1xi32>
  %68 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %69 = tt.addptr %68, %67 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %70 = tt.broadcast %69 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %71 = tt.addptr %70, %35 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %72 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %73 = arith.cmpi slt, %17, %72 : tensor<32x1xi32>
  %74 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %75 = arith.cmpi slt, %33, %74 : tensor<1x32xi32>
  %76 = tt.broadcast %73 : tensor<32x1xi1> -> tensor<32x32xi1>
  %77 = tt.broadcast %75 : tensor<1x32xi1> -> tensor<32x32xi1>
  %78 = arith.andi %76, %77 : tensor<32x32xi1>
  tt.store %71, %65, %78 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.broadcast'(0x555d5be98b40) {
  %37 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.broadcast -> ()' {
Trying to match "{anonymous}::TritonBroadcastPattern"
    ** Insert  : 'tt.broadcast'(0x555d5bed69f0)
    ** Replace : 'tt.broadcast'(0x555d5be98b40)
"{anonymous}::TritonBroadcastPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.broadcast'(0x555d5bed69f0) {
      %37 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %5 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32>
  %7 = arith.addi %5, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %8 = arith.addi %6, %4 : tensor<32xi32>
  %9 = arith.muli %1, %c32_i32 : i32
  %10 = tt.splat %9 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %11 = tt.splat %9 : i32 -> tensor<32xi32>
  %12 = arith.addi %10, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %13 = arith.addi %11, %4 : tensor<32xi32>
  %14 = triton_gpu.convert_layout %7 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %15 = tt.expand_dims %14 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %16 = builtin.unrealized_conversion_cast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.expand_dims %8 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %18 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %20 = arith.muli %16, %18 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = arith.muli %17, %19 : tensor<32x1xi32>
  %22 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %23 = tt.expand_dims %22 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %24 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %25 = tt.broadcast %20 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %26 = tt.broadcast %21 : tensor<32x1xi32> -> tensor<32x32xi32>
  %27 = tt.broadcast %24 : tensor<1x32xi32> -> tensor<32x32xi32>
  %28 = arith.addi %26, %27 : tensor<32x32xi32>
  %29 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %30 = tt.addptr %29, %28 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %31 = tt.expand_dims %4 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %32 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %33 = arith.muli %31, %32 : tensor<32x1xi32>
  %34 = tt.expand_dims %13 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %35 = tt.broadcast %33 : tensor<32x1xi32> -> tensor<32x32xi32>
  %36 = tt.broadcast %34 : tensor<1x32xi32> -> tensor<32x32xi32>
  %37 = arith.addi %35, %36 : tensor<32x32xi32>
  %38 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %39 = tt.addptr %38, %37 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %40 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %41 = tt.addptr %40, %13 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %42 = arith.addi %arg8, %c31_i32 : i32
  %43 = arith.divsi %42, %c32_i32 : i32
  %44 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %45 = arith.cmpi slt, %17, %44 : tensor<32x1xi32>
  %46 = tt.broadcast %45 : tensor<32x1xi1> -> tensor<32x32xi1>
  %47 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %48 = arith.cmpi slt, %34, %47 : tensor<1x32xi32>
  %49 = tt.broadcast %48 : tensor<1x32xi1> -> tensor<32x32xi1>
  %50 = arith.muli %arg10, %c32_i32 : i32
  %51 = tt.splat %50 : i32 -> tensor<32x32xi32>
  %52:3 = scf.for %arg12 = %c0_i32 to %43 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %30, %arg15 = %39) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %80 = arith.muli %arg12, %c32_i32 : i32
    %81 = arith.subi %arg8, %80 : i32
    %82 = tt.splat %81 : i32 -> tensor<1x32xi32>
    %83 = arith.cmpi slt, %24, %82 : tensor<1x32xi32>
    %84 = tt.broadcast %83 : tensor<1x32xi1> -> tensor<32x32xi1>
    %85 = arith.andi %46, %84 : tensor<32x32xi1>
    %86 = tt.load %arg14, %85, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %87 = tt.splat %81 : i32 -> tensor<32x1xi32>
    %88 = arith.cmpi slt, %31, %87 : tensor<32x1xi32>
    %89 = tt.broadcast %88 : tensor<32x1xi1> -> tensor<32x32xi1>
    %90 = arith.andi %89, %49 : tensor<32x32xi1>
    %91 = tt.load %arg15, %90, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %92 = tt.dot %86, %91, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %93 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %94 = tt.addptr %arg15, %51 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %92, %93, %94 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %53 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %54 = arith.cmpi slt, %13, %53 : tensor<32xi32>
  %55 = tt.load %41, %54, %cst_0 : tensor<32x!tt.ptr<f16>>
  %56 = arith.sitofp %arg4 : i32 to f32
  %57 = tt.splat %56 : f32 -> tensor<32x32xf32>
  %58 = arith.mulf %52#0, %57 : tensor<32x32xf32>
  %59 = arith.sitofp %arg5 : i32 to f16
  %60 = tt.splat %59 : f16 -> tensor<32xf16>
  %61 = arith.mulf %55, %60 : tensor<32xf16>
  %62 = tt.expand_dims %61 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %63 = arith.extf %62 : tensor<1x32xf16> to tensor<1x32xf32>
  %64 = tt.broadcast %63 : tensor<1x32xf32> -> tensor<32x32xf32>
  %65 = arith.addf %58, %64 : tensor<32x32xf32>
  %66 = arith.truncf %65 : tensor<32x32xf32> to tensor<32x32xf16>
  %67 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %68 = arith.muli %67, %17 : tensor<32x1xi32>
  %69 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %70 = tt.addptr %69, %68 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %71 = tt.broadcast %70 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %72 = tt.addptr %71, %36 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %73 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %74 = arith.cmpi slt, %17, %73 : tensor<32x1xi32>
  %75 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %76 = arith.cmpi slt, %34, %75 : tensor<1x32xi32>
  %77 = tt.broadcast %74 : tensor<32x1xi1> -> tensor<32x32xi1>
  %78 = tt.broadcast %76 : tensor<1x32xi1> -> tensor<32x32xi1>
  %79 = arith.andi %77, %78 : tensor<32x32xi1>
  tt.store %72, %66, %79 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.broadcast'(0x555d5be98c30) {
  %39 = "tt.broadcast"(%36) : (tensor<1x32xi32>) -> tensor<32x32xi32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.broadcast -> ()' {
Trying to match "{anonymous}::TritonBroadcastPattern"
    ** Insert  : 'tt.broadcast'(0x555d5bed7ee0)
    ** Replace : 'tt.broadcast'(0x555d5be98c30)
"{anonymous}::TritonBroadcastPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.broadcast'(0x555d5bed7ee0) {
      %40 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %5 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32>
  %7 = arith.addi %5, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %8 = arith.addi %6, %4 : tensor<32xi32>
  %9 = arith.muli %1, %c32_i32 : i32
  %10 = tt.splat %9 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %11 = tt.splat %9 : i32 -> tensor<32xi32>
  %12 = arith.addi %10, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %13 = arith.addi %11, %4 : tensor<32xi32>
  %14 = triton_gpu.convert_layout %7 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %15 = tt.expand_dims %14 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %16 = builtin.unrealized_conversion_cast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.expand_dims %8 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %18 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %20 = arith.muli %16, %18 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = arith.muli %17, %19 : tensor<32x1xi32>
  %22 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %23 = tt.expand_dims %22 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %24 = builtin.unrealized_conversion_cast %23 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %26 = tt.broadcast %20 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = tt.broadcast %21 : tensor<32x1xi32> -> tensor<32x32xi32>
  %28 = tt.broadcast %24 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = tt.broadcast %25 : tensor<1x32xi32> -> tensor<32x32xi32>
  %30 = arith.addi %27, %29 : tensor<32x32xi32>
  %31 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %32 = tt.addptr %31, %30 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %33 = tt.expand_dims %4 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %34 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %35 = arith.muli %33, %34 : tensor<32x1xi32>
  %36 = tt.expand_dims %13 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %37 = tt.broadcast %35 : tensor<32x1xi32> -> tensor<32x32xi32>
  %38 = tt.broadcast %36 : tensor<1x32xi32> -> tensor<32x32xi32>
  %39 = arith.addi %37, %38 : tensor<32x32xi32>
  %40 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %41 = tt.addptr %40, %39 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %42 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %43 = tt.addptr %42, %13 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %44 = arith.addi %arg8, %c31_i32 : i32
  %45 = arith.divsi %44, %c32_i32 : i32
  %46 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %47 = arith.cmpi slt, %17, %46 : tensor<32x1xi32>
  %48 = tt.broadcast %47 : tensor<32x1xi1> -> tensor<32x32xi1>
  %49 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %50 = arith.cmpi slt, %36, %49 : tensor<1x32xi32>
  %51 = tt.broadcast %50 : tensor<1x32xi1> -> tensor<32x32xi1>
  %52 = arith.muli %arg10, %c32_i32 : i32
  %53 = tt.splat %52 : i32 -> tensor<32x32xi32>
  %54:3 = scf.for %arg12 = %c0_i32 to %45 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %32, %arg15 = %41) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %82 = arith.muli %arg12, %c32_i32 : i32
    %83 = arith.subi %arg8, %82 : i32
    %84 = tt.splat %83 : i32 -> tensor<1x32xi32>
    %85 = arith.cmpi slt, %25, %84 : tensor<1x32xi32>
    %86 = tt.broadcast %85 : tensor<1x32xi1> -> tensor<32x32xi1>
    %87 = arith.andi %48, %86 : tensor<32x32xi1>
    %88 = tt.load %arg14, %87, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %89 = tt.splat %83 : i32 -> tensor<32x1xi32>
    %90 = arith.cmpi slt, %33, %89 : tensor<32x1xi32>
    %91 = tt.broadcast %90 : tensor<32x1xi1> -> tensor<32x32xi1>
    %92 = arith.andi %91, %51 : tensor<32x32xi1>
    %93 = tt.load %arg15, %92, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %94 = tt.dot %88, %93, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %95 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %96 = tt.addptr %arg15, %53 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %94, %95, %96 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %55 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %56 = arith.cmpi slt, %13, %55 : tensor<32xi32>
  %57 = tt.load %43, %56, %cst_0 : tensor<32x!tt.ptr<f16>>
  %58 = arith.sitofp %arg4 : i32 to f32
  %59 = tt.splat %58 : f32 -> tensor<32x32xf32>
  %60 = arith.mulf %54#0, %59 : tensor<32x32xf32>
  %61 = arith.sitofp %arg5 : i32 to f16
  %62 = tt.splat %61 : f16 -> tensor<32xf16>
  %63 = arith.mulf %57, %62 : tensor<32xf16>
  %64 = tt.expand_dims %63 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %65 = arith.extf %64 : tensor<1x32xf16> to tensor<1x32xf32>
  %66 = tt.broadcast %65 : tensor<1x32xf32> -> tensor<32x32xf32>
  %67 = arith.addf %60, %66 : tensor<32x32xf32>
  %68 = arith.truncf %67 : tensor<32x32xf32> to tensor<32x32xf16>
  %69 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %70 = arith.muli %69, %17 : tensor<32x1xi32>
  %71 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %72 = tt.addptr %71, %70 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %73 = tt.broadcast %72 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %74 = tt.addptr %73, %38 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %75 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %76 = arith.cmpi slt, %17, %75 : tensor<32x1xi32>
  %77 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %78 = arith.cmpi slt, %36, %77 : tensor<1x32xi32>
  %79 = tt.broadcast %76 : tensor<32x1xi1> -> tensor<32x32xi1>
  %80 = tt.broadcast %78 : tensor<1x32xi1> -> tensor<32x32xi1>
  %81 = arith.andi %79, %80 : tensor<32x32xi1>
  tt.store %74, %68, %81 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.addi'(0x555d5be98d20) {
  %42 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'arith.addi -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::arith::AddIOp>"
    ** Insert  : 'arith.addi'(0x555d5bed1950)
    ** Replace : 'arith.addi'(0x555d5be98d20)
"{anonymous}::GenericOpPattern<mlir::arith::AddIOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'arith.addi'(0x555d5bed1950) {
      %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %5 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32>
  %7 = arith.addi %5, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %8 = arith.addi %6, %4 : tensor<32xi32>
  %9 = arith.muli %1, %c32_i32 : i32
  %10 = tt.splat %9 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %11 = tt.splat %9 : i32 -> tensor<32xi32>
  %12 = arith.addi %10, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %13 = arith.addi %11, %4 : tensor<32xi32>
  %14 = triton_gpu.convert_layout %7 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %15 = tt.expand_dims %14 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %16 = builtin.unrealized_conversion_cast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.expand_dims %8 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %18 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %20 = arith.muli %16, %18 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = arith.muli %17, %19 : tensor<32x1xi32>
  %22 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %23 = tt.expand_dims %22 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %24 = builtin.unrealized_conversion_cast %23 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %26 = tt.broadcast %20 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = builtin.unrealized_conversion_cast %26 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = tt.broadcast %21 : tensor<32x1xi32> -> tensor<32x32xi32>
  %29 = tt.broadcast %24 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.broadcast %25 : tensor<1x32xi32> -> tensor<32x32xi32>
  %31 = arith.addi %27, %29 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %32 = arith.addi %28, %30 : tensor<32x32xi32>
  %33 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %34 = tt.addptr %33, %32 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %35 = tt.expand_dims %4 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %36 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %37 = arith.muli %35, %36 : tensor<32x1xi32>
  %38 = tt.expand_dims %13 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %39 = tt.broadcast %37 : tensor<32x1xi32> -> tensor<32x32xi32>
  %40 = tt.broadcast %38 : tensor<1x32xi32> -> tensor<32x32xi32>
  %41 = arith.addi %39, %40 : tensor<32x32xi32>
  %42 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %43 = tt.addptr %42, %41 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %44 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %45 = tt.addptr %44, %13 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %46 = arith.addi %arg8, %c31_i32 : i32
  %47 = arith.divsi %46, %c32_i32 : i32
  %48 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %49 = arith.cmpi slt, %17, %48 : tensor<32x1xi32>
  %50 = tt.broadcast %49 : tensor<32x1xi1> -> tensor<32x32xi1>
  %51 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %52 = arith.cmpi slt, %38, %51 : tensor<1x32xi32>
  %53 = tt.broadcast %52 : tensor<1x32xi1> -> tensor<32x32xi1>
  %54 = arith.muli %arg10, %c32_i32 : i32
  %55 = tt.splat %54 : i32 -> tensor<32x32xi32>
  %56:3 = scf.for %arg12 = %c0_i32 to %47 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %34, %arg15 = %43) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %84 = arith.muli %arg12, %c32_i32 : i32
    %85 = arith.subi %arg8, %84 : i32
    %86 = tt.splat %85 : i32 -> tensor<1x32xi32>
    %87 = arith.cmpi slt, %25, %86 : tensor<1x32xi32>
    %88 = tt.broadcast %87 : tensor<1x32xi1> -> tensor<32x32xi1>
    %89 = arith.andi %50, %88 : tensor<32x32xi1>
    %90 = tt.load %arg14, %89, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %91 = tt.splat %85 : i32 -> tensor<32x1xi32>
    %92 = arith.cmpi slt, %35, %91 : tensor<32x1xi32>
    %93 = tt.broadcast %92 : tensor<32x1xi1> -> tensor<32x32xi1>
    %94 = arith.andi %93, %53 : tensor<32x32xi1>
    %95 = tt.load %arg15, %94, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %96 = tt.dot %90, %95, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %97 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %98 = tt.addptr %arg15, %55 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %96, %97, %98 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %57 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %58 = arith.cmpi slt, %13, %57 : tensor<32xi32>
  %59 = tt.load %45, %58, %cst_0 : tensor<32x!tt.ptr<f16>>
  %60 = arith.sitofp %arg4 : i32 to f32
  %61 = tt.splat %60 : f32 -> tensor<32x32xf32>
  %62 = arith.mulf %56#0, %61 : tensor<32x32xf32>
  %63 = arith.sitofp %arg5 : i32 to f16
  %64 = tt.splat %63 : f16 -> tensor<32xf16>
  %65 = arith.mulf %59, %64 : tensor<32xf16>
  %66 = tt.expand_dims %65 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %67 = arith.extf %66 : tensor<1x32xf16> to tensor<1x32xf32>
  %68 = tt.broadcast %67 : tensor<1x32xf32> -> tensor<32x32xf32>
  %69 = arith.addf %62, %68 : tensor<32x32xf32>
  %70 = arith.truncf %69 : tensor<32x32xf32> to tensor<32x32xf16>
  %71 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %72 = arith.muli %71, %17 : tensor<32x1xi32>
  %73 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %74 = tt.addptr %73, %72 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %75 = tt.broadcast %74 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %76 = tt.addptr %75, %40 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %77 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %78 = arith.cmpi slt, %17, %77 : tensor<32x1xi32>
  %79 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %80 = arith.cmpi slt, %38, %79 : tensor<1x32xi32>
  %81 = tt.broadcast %78 : tensor<32x1xi1> -> tensor<32x32xi1>
  %82 = tt.broadcast %80 : tensor<1x32xi1> -> tensor<32x32xi1>
  %83 = arith.andi %81, %82 : tensor<32x32xi1>
  tt.store %76, %70, %83 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.splat'(0x555d5be992b0) {
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.splat -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::triton::SplatOp>"
    ** Insert  : 'tt.splat'(0x555d5bed7a70)
    ** Replace : 'tt.splat'(0x555d5be992b0)
"{anonymous}::GenericOpPattern<mlir::triton::SplatOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.splat'(0x555d5bed7a70) {
      %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %5 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32>
  %7 = arith.addi %5, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %8 = arith.addi %6, %4 : tensor<32xi32>
  %9 = arith.muli %1, %c32_i32 : i32
  %10 = tt.splat %9 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %11 = tt.splat %9 : i32 -> tensor<32xi32>
  %12 = arith.addi %10, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %13 = arith.addi %11, %4 : tensor<32xi32>
  %14 = triton_gpu.convert_layout %7 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %15 = tt.expand_dims %14 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %16 = builtin.unrealized_conversion_cast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.expand_dims %8 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %18 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %20 = arith.muli %16, %18 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = arith.muli %17, %19 : tensor<32x1xi32>
  %22 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %23 = tt.expand_dims %22 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %24 = builtin.unrealized_conversion_cast %23 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %26 = tt.broadcast %20 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = builtin.unrealized_conversion_cast %26 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = tt.broadcast %21 : tensor<32x1xi32> -> tensor<32x32xi32>
  %29 = tt.broadcast %24 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.broadcast %25 : tensor<1x32xi32> -> tensor<32x32xi32>
  %31 = arith.addi %27, %29 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %32 = arith.addi %28, %30 : tensor<32x32xi32>
  %33 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %34 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %35 = tt.addptr %34, %32 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %36 = tt.expand_dims %4 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %37 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %38 = arith.muli %36, %37 : tensor<32x1xi32>
  %39 = tt.expand_dims %13 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %40 = tt.broadcast %38 : tensor<32x1xi32> -> tensor<32x32xi32>
  %41 = tt.broadcast %39 : tensor<1x32xi32> -> tensor<32x32xi32>
  %42 = arith.addi %40, %41 : tensor<32x32xi32>
  %43 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %44 = tt.addptr %43, %42 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %45 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %46 = tt.addptr %45, %13 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %47 = arith.addi %arg8, %c31_i32 : i32
  %48 = arith.divsi %47, %c32_i32 : i32
  %49 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %50 = arith.cmpi slt, %17, %49 : tensor<32x1xi32>
  %51 = tt.broadcast %50 : tensor<32x1xi1> -> tensor<32x32xi1>
  %52 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %53 = arith.cmpi slt, %39, %52 : tensor<1x32xi32>
  %54 = tt.broadcast %53 : tensor<1x32xi1> -> tensor<32x32xi1>
  %55 = arith.muli %arg10, %c32_i32 : i32
  %56 = tt.splat %55 : i32 -> tensor<32x32xi32>
  %57:3 = scf.for %arg12 = %c0_i32 to %48 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %35, %arg15 = %44) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %85 = arith.muli %arg12, %c32_i32 : i32
    %86 = arith.subi %arg8, %85 : i32
    %87 = tt.splat %86 : i32 -> tensor<1x32xi32>
    %88 = arith.cmpi slt, %25, %87 : tensor<1x32xi32>
    %89 = tt.broadcast %88 : tensor<1x32xi1> -> tensor<32x32xi1>
    %90 = arith.andi %51, %89 : tensor<32x32xi1>
    %91 = tt.load %arg14, %90, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %92 = tt.splat %86 : i32 -> tensor<32x1xi32>
    %93 = arith.cmpi slt, %36, %92 : tensor<32x1xi32>
    %94 = tt.broadcast %93 : tensor<32x1xi1> -> tensor<32x32xi1>
    %95 = arith.andi %94, %54 : tensor<32x32xi1>
    %96 = tt.load %arg15, %95, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %97 = tt.dot %91, %96, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %98 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %99 = tt.addptr %arg15, %56 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %97, %98, %99 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %58 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %59 = arith.cmpi slt, %13, %58 : tensor<32xi32>
  %60 = tt.load %46, %59, %cst_0 : tensor<32x!tt.ptr<f16>>
  %61 = arith.sitofp %arg4 : i32 to f32
  %62 = tt.splat %61 : f32 -> tensor<32x32xf32>
  %63 = arith.mulf %57#0, %62 : tensor<32x32xf32>
  %64 = arith.sitofp %arg5 : i32 to f16
  %65 = tt.splat %64 : f16 -> tensor<32xf16>
  %66 = arith.mulf %60, %65 : tensor<32xf16>
  %67 = tt.expand_dims %66 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %68 = arith.extf %67 : tensor<1x32xf16> to tensor<1x32xf32>
  %69 = tt.broadcast %68 : tensor<1x32xf32> -> tensor<32x32xf32>
  %70 = arith.addf %63, %69 : tensor<32x32xf32>
  %71 = arith.truncf %70 : tensor<32x32xf32> to tensor<32x32xf16>
  %72 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %73 = arith.muli %72, %17 : tensor<32x1xi32>
  %74 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %75 = tt.addptr %74, %73 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %76 = tt.broadcast %75 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %77 = tt.addptr %76, %41 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %78 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %79 = arith.cmpi slt, %17, %78 : tensor<32x1xi32>
  %80 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %81 = arith.cmpi slt, %39, %80 : tensor<1x32xi32>
  %82 = tt.broadcast %79 : tensor<32x1xi1> -> tensor<32x32xi1>
  %83 = tt.broadcast %81 : tensor<1x32xi1> -> tensor<32x32xi1>
  %84 = arith.andi %82, %83 : tensor<32x32xi1>
  tt.store %77, %71, %84 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.addptr'(0x555d5be993a0) {
  %47 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.addptr -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::triton::AddPtrOp>"
    ** Insert  : 'tt.addptr'(0x555d5bed7c00)
    ** Replace : 'tt.addptr'(0x555d5be993a0)
"{anonymous}::GenericOpPattern<mlir::triton::AddPtrOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.addptr'(0x555d5bed7c00) {
      %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %5 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32>
  %7 = arith.addi %5, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %8 = arith.addi %6, %4 : tensor<32xi32>
  %9 = arith.muli %1, %c32_i32 : i32
  %10 = tt.splat %9 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %11 = tt.splat %9 : i32 -> tensor<32xi32>
  %12 = arith.addi %10, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %13 = arith.addi %11, %4 : tensor<32xi32>
  %14 = triton_gpu.convert_layout %7 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %15 = tt.expand_dims %14 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %16 = builtin.unrealized_conversion_cast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.expand_dims %8 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %18 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %20 = arith.muli %16, %18 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = arith.muli %17, %19 : tensor<32x1xi32>
  %22 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %23 = tt.expand_dims %22 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %24 = builtin.unrealized_conversion_cast %23 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %26 = tt.broadcast %20 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = builtin.unrealized_conversion_cast %26 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = tt.broadcast %21 : tensor<32x1xi32> -> tensor<32x32xi32>
  %29 = tt.broadcast %24 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.broadcast %25 : tensor<1x32xi32> -> tensor<32x32xi32>
  %31 = arith.addi %27, %29 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %32 = arith.addi %28, %30 : tensor<32x32xi32>
  %33 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %34 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %35 = tt.addptr %33, %31 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = tt.addptr %34, %32 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %37 = tt.expand_dims %4 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %38 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %39 = arith.muli %37, %38 : tensor<32x1xi32>
  %40 = tt.expand_dims %13 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %41 = tt.broadcast %39 : tensor<32x1xi32> -> tensor<32x32xi32>
  %42 = tt.broadcast %40 : tensor<1x32xi32> -> tensor<32x32xi32>
  %43 = arith.addi %41, %42 : tensor<32x32xi32>
  %44 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %45 = tt.addptr %44, %43 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %46 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %47 = tt.addptr %46, %13 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %48 = arith.addi %arg8, %c31_i32 : i32
  %49 = arith.divsi %48, %c32_i32 : i32
  %50 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %51 = arith.cmpi slt, %17, %50 : tensor<32x1xi32>
  %52 = tt.broadcast %51 : tensor<32x1xi1> -> tensor<32x32xi1>
  %53 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %54 = arith.cmpi slt, %40, %53 : tensor<1x32xi32>
  %55 = tt.broadcast %54 : tensor<1x32xi1> -> tensor<32x32xi1>
  %56 = arith.muli %arg10, %c32_i32 : i32
  %57 = tt.splat %56 : i32 -> tensor<32x32xi32>
  %58:3 = scf.for %arg12 = %c0_i32 to %49 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %36, %arg15 = %45) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %86 = arith.muli %arg12, %c32_i32 : i32
    %87 = arith.subi %arg8, %86 : i32
    %88 = tt.splat %87 : i32 -> tensor<1x32xi32>
    %89 = arith.cmpi slt, %25, %88 : tensor<1x32xi32>
    %90 = tt.broadcast %89 : tensor<1x32xi1> -> tensor<32x32xi1>
    %91 = arith.andi %52, %90 : tensor<32x32xi1>
    %92 = tt.load %arg14, %91, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %93 = tt.splat %87 : i32 -> tensor<32x1xi32>
    %94 = arith.cmpi slt, %37, %93 : tensor<32x1xi32>
    %95 = tt.broadcast %94 : tensor<32x1xi1> -> tensor<32x32xi1>
    %96 = arith.andi %95, %55 : tensor<32x32xi1>
    %97 = tt.load %arg15, %96, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %98 = tt.dot %92, %97, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %99 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %100 = tt.addptr %arg15, %57 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %98, %99, %100 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %59 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %60 = arith.cmpi slt, %13, %59 : tensor<32xi32>
  %61 = tt.load %47, %60, %cst_0 : tensor<32x!tt.ptr<f16>>
  %62 = arith.sitofp %arg4 : i32 to f32
  %63 = tt.splat %62 : f32 -> tensor<32x32xf32>
  %64 = arith.mulf %58#0, %63 : tensor<32x32xf32>
  %65 = arith.sitofp %arg5 : i32 to f16
  %66 = tt.splat %65 : f16 -> tensor<32xf16>
  %67 = arith.mulf %61, %66 : tensor<32xf16>
  %68 = tt.expand_dims %67 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %69 = arith.extf %68 : tensor<1x32xf16> to tensor<1x32xf32>
  %70 = tt.broadcast %69 : tensor<1x32xf32> -> tensor<32x32xf32>
  %71 = arith.addf %64, %70 : tensor<32x32xf32>
  %72 = arith.truncf %71 : tensor<32x32xf32> to tensor<32x32xf16>
  %73 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %74 = arith.muli %73, %17 : tensor<32x1xi32>
  %75 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %76 = tt.addptr %75, %74 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %77 = tt.broadcast %76 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %78 = tt.addptr %77, %42 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %79 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %80 = arith.cmpi slt, %17, %79 : tensor<32x1xi32>
  %81 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %82 = arith.cmpi slt, %40, %81 : tensor<1x32xi32>
  %83 = tt.broadcast %80 : tensor<32x1xi1> -> tensor<32x32xi1>
  %84 = tt.broadcast %82 : tensor<1x32xi1> -> tensor<32x32xi1>
  %85 = arith.andi %83, %84 : tensor<32x32xi1>
  tt.store %78, %72, %85 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.expand_dims'(0x555d5be994b0) {
  %49 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.expand_dims -> ()' {
Trying to match "{anonymous}::TritonExpandDimsPattern"
    ** Insert  : 'triton_gpu.convert_layout'(0x555d5bed8580)
    ** Insert  : 'tt.expand_dims'(0x555d5bed86a0)
    ** Replace : 'tt.expand_dims'(0x555d5be994b0)
"{anonymous}::TritonExpandDimsPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'triton_gpu.convert_layout'(0x555d5bed8580) {
      %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'tt.expand_dims'(0x555d5bed86a0) {
      %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %5 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32>
  %7 = arith.addi %5, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %8 = arith.addi %6, %4 : tensor<32xi32>
  %9 = arith.muli %1, %c32_i32 : i32
  %10 = tt.splat %9 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %11 = tt.splat %9 : i32 -> tensor<32xi32>
  %12 = arith.addi %10, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %13 = arith.addi %11, %4 : tensor<32xi32>
  %14 = triton_gpu.convert_layout %7 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %15 = tt.expand_dims %14 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %16 = builtin.unrealized_conversion_cast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.expand_dims %8 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %18 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %20 = arith.muli %16, %18 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = arith.muli %17, %19 : tensor<32x1xi32>
  %22 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %23 = tt.expand_dims %22 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %24 = builtin.unrealized_conversion_cast %23 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %26 = tt.broadcast %20 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = builtin.unrealized_conversion_cast %26 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = tt.broadcast %21 : tensor<32x1xi32> -> tensor<32x32xi32>
  %29 = tt.broadcast %24 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.broadcast %25 : tensor<1x32xi32> -> tensor<32x32xi32>
  %31 = arith.addi %27, %29 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %32 = arith.addi %28, %30 : tensor<32x32xi32>
  %33 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %34 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %35 = tt.addptr %33, %31 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = tt.addptr %34, %32 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %37 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %38 = tt.expand_dims %37 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %39 = tt.expand_dims %4 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %40 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %41 = arith.muli %39, %40 : tensor<32x1xi32>
  %42 = tt.expand_dims %13 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %43 = tt.broadcast %41 : tensor<32x1xi32> -> tensor<32x32xi32>
  %44 = tt.broadcast %42 : tensor<1x32xi32> -> tensor<32x32xi32>
  %45 = arith.addi %43, %44 : tensor<32x32xi32>
  %46 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %47 = tt.addptr %46, %45 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %48 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %49 = tt.addptr %48, %13 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %50 = arith.addi %arg8, %c31_i32 : i32
  %51 = arith.divsi %50, %c32_i32 : i32
  %52 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %53 = arith.cmpi slt, %17, %52 : tensor<32x1xi32>
  %54 = tt.broadcast %53 : tensor<32x1xi1> -> tensor<32x32xi1>
  %55 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %56 = arith.cmpi slt, %42, %55 : tensor<1x32xi32>
  %57 = tt.broadcast %56 : tensor<1x32xi1> -> tensor<32x32xi1>
  %58 = arith.muli %arg10, %c32_i32 : i32
  %59 = tt.splat %58 : i32 -> tensor<32x32xi32>
  %60:3 = scf.for %arg12 = %c0_i32 to %51 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %36, %arg15 = %47) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %88 = arith.muli %arg12, %c32_i32 : i32
    %89 = arith.subi %arg8, %88 : i32
    %90 = tt.splat %89 : i32 -> tensor<1x32xi32>
    %91 = arith.cmpi slt, %25, %90 : tensor<1x32xi32>
    %92 = tt.broadcast %91 : tensor<1x32xi1> -> tensor<32x32xi1>
    %93 = arith.andi %54, %92 : tensor<32x32xi1>
    %94 = tt.load %arg14, %93, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %95 = tt.splat %89 : i32 -> tensor<32x1xi32>
    %96 = arith.cmpi slt, %39, %95 : tensor<32x1xi32>
    %97 = tt.broadcast %96 : tensor<32x1xi1> -> tensor<32x32xi1>
    %98 = arith.andi %97, %57 : tensor<32x32xi1>
    %99 = tt.load %arg15, %98, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %100 = tt.dot %94, %99, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %101 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %102 = tt.addptr %arg15, %59 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %100, %101, %102 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %61 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %62 = arith.cmpi slt, %13, %61 : tensor<32xi32>
  %63 = tt.load %49, %62, %cst_0 : tensor<32x!tt.ptr<f16>>
  %64 = arith.sitofp %arg4 : i32 to f32
  %65 = tt.splat %64 : f32 -> tensor<32x32xf32>
  %66 = arith.mulf %60#0, %65 : tensor<32x32xf32>
  %67 = arith.sitofp %arg5 : i32 to f16
  %68 = tt.splat %67 : f16 -> tensor<32xf16>
  %69 = arith.mulf %63, %68 : tensor<32xf16>
  %70 = tt.expand_dims %69 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %71 = arith.extf %70 : tensor<1x32xf16> to tensor<1x32xf32>
  %72 = tt.broadcast %71 : tensor<1x32xf32> -> tensor<32x32xf32>
  %73 = arith.addf %66, %72 : tensor<32x32xf32>
  %74 = arith.truncf %73 : tensor<32x32xf32> to tensor<32x32xf16>
  %75 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %76 = arith.muli %75, %17 : tensor<32x1xi32>
  %77 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %78 = tt.addptr %77, %76 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %79 = tt.broadcast %78 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %80 = tt.addptr %79, %44 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %81 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %82 = arith.cmpi slt, %17, %81 : tensor<32x1xi32>
  %83 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %84 = arith.cmpi slt, %42, %83 : tensor<1x32xi32>
  %85 = tt.broadcast %82 : tensor<32x1xi1> -> tensor<32x32xi1>
  %86 = tt.broadcast %84 : tensor<1x32xi1> -> tensor<32x32xi1>
  %87 = arith.andi %85, %86 : tensor<32x32xi1>
  tt.store %80, %74, %87 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.splat'(0x555d5be995a0) {
  %52 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.splat -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::triton::SplatOp>"
    ** Insert  : 'tt.splat'(0x555d5bed7d70)
    ** Replace : 'tt.splat'(0x555d5be995a0)
"{anonymous}::GenericOpPattern<mlir::triton::SplatOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.splat'(0x555d5bed7d70) {
      %52 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %5 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32>
  %7 = arith.addi %5, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %8 = arith.addi %6, %4 : tensor<32xi32>
  %9 = arith.muli %1, %c32_i32 : i32
  %10 = tt.splat %9 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %11 = tt.splat %9 : i32 -> tensor<32xi32>
  %12 = arith.addi %10, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %13 = arith.addi %11, %4 : tensor<32xi32>
  %14 = triton_gpu.convert_layout %7 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %15 = tt.expand_dims %14 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %16 = builtin.unrealized_conversion_cast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.expand_dims %8 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %18 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %20 = arith.muli %16, %18 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = arith.muli %17, %19 : tensor<32x1xi32>
  %22 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %23 = tt.expand_dims %22 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %24 = builtin.unrealized_conversion_cast %23 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %26 = tt.broadcast %20 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = builtin.unrealized_conversion_cast %26 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = tt.broadcast %21 : tensor<32x1xi32> -> tensor<32x32xi32>
  %29 = tt.broadcast %24 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.broadcast %25 : tensor<1x32xi32> -> tensor<32x32xi32>
  %31 = arith.addi %27, %29 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %32 = arith.addi %28, %30 : tensor<32x32xi32>
  %33 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %34 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %35 = tt.addptr %33, %31 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = tt.addptr %34, %32 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %37 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %38 = tt.expand_dims %37 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %39 = tt.expand_dims %4 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %40 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %41 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %42 = arith.muli %39, %41 : tensor<32x1xi32>
  %43 = tt.expand_dims %13 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %44 = tt.broadcast %42 : tensor<32x1xi32> -> tensor<32x32xi32>
  %45 = tt.broadcast %43 : tensor<1x32xi32> -> tensor<32x32xi32>
  %46 = arith.addi %44, %45 : tensor<32x32xi32>
  %47 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %48 = tt.addptr %47, %46 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %49 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %50 = tt.addptr %49, %13 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %51 = arith.addi %arg8, %c31_i32 : i32
  %52 = arith.divsi %51, %c32_i32 : i32
  %53 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %54 = arith.cmpi slt, %17, %53 : tensor<32x1xi32>
  %55 = tt.broadcast %54 : tensor<32x1xi1> -> tensor<32x32xi1>
  %56 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %57 = arith.cmpi slt, %43, %56 : tensor<1x32xi32>
  %58 = tt.broadcast %57 : tensor<1x32xi1> -> tensor<32x32xi1>
  %59 = arith.muli %arg10, %c32_i32 : i32
  %60 = tt.splat %59 : i32 -> tensor<32x32xi32>
  %61:3 = scf.for %arg12 = %c0_i32 to %52 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %36, %arg15 = %48) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %89 = arith.muli %arg12, %c32_i32 : i32
    %90 = arith.subi %arg8, %89 : i32
    %91 = tt.splat %90 : i32 -> tensor<1x32xi32>
    %92 = arith.cmpi slt, %25, %91 : tensor<1x32xi32>
    %93 = tt.broadcast %92 : tensor<1x32xi1> -> tensor<32x32xi1>
    %94 = arith.andi %55, %93 : tensor<32x32xi1>
    %95 = tt.load %arg14, %94, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %96 = tt.splat %90 : i32 -> tensor<32x1xi32>
    %97 = arith.cmpi slt, %39, %96 : tensor<32x1xi32>
    %98 = tt.broadcast %97 : tensor<32x1xi1> -> tensor<32x32xi1>
    %99 = arith.andi %98, %58 : tensor<32x32xi1>
    %100 = tt.load %arg15, %99, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %101 = tt.dot %95, %100, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %102 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %103 = tt.addptr %arg15, %60 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %101, %102, %103 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %62 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %63 = arith.cmpi slt, %13, %62 : tensor<32xi32>
  %64 = tt.load %50, %63, %cst_0 : tensor<32x!tt.ptr<f16>>
  %65 = arith.sitofp %arg4 : i32 to f32
  %66 = tt.splat %65 : f32 -> tensor<32x32xf32>
  %67 = arith.mulf %61#0, %66 : tensor<32x32xf32>
  %68 = arith.sitofp %arg5 : i32 to f16
  %69 = tt.splat %68 : f16 -> tensor<32xf16>
  %70 = arith.mulf %64, %69 : tensor<32xf16>
  %71 = tt.expand_dims %70 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %72 = arith.extf %71 : tensor<1x32xf16> to tensor<1x32xf32>
  %73 = tt.broadcast %72 : tensor<1x32xf32> -> tensor<32x32xf32>
  %74 = arith.addf %67, %73 : tensor<32x32xf32>
  %75 = arith.truncf %74 : tensor<32x32xf32> to tensor<32x32xf16>
  %76 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %77 = arith.muli %76, %17 : tensor<32x1xi32>
  %78 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %79 = tt.addptr %78, %77 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %80 = tt.broadcast %79 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %81 = tt.addptr %80, %45 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %82 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %83 = arith.cmpi slt, %17, %82 : tensor<32x1xi32>
  %84 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %85 = arith.cmpi slt, %43, %84 : tensor<1x32xi32>
  %86 = tt.broadcast %83 : tensor<32x1xi1> -> tensor<32x32xi1>
  %87 = tt.broadcast %85 : tensor<1x32xi1> -> tensor<32x32xi1>
  %88 = arith.andi %86, %87 : tensor<32x32xi1>
  tt.store %81, %75, %88 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.muli'(0x555d5be99690) {
  %54 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'arith.muli -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::arith::MulIOp>"
    ** Insert  : 'arith.muli'(0x555d5bed6d50)
    ** Replace : 'arith.muli'(0x555d5be99690)
"{anonymous}::GenericOpPattern<mlir::arith::MulIOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'arith.muli'(0x555d5bed6d50) {
      %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %5 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32>
  %7 = arith.addi %5, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %8 = arith.addi %6, %4 : tensor<32xi32>
  %9 = arith.muli %1, %c32_i32 : i32
  %10 = tt.splat %9 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %11 = tt.splat %9 : i32 -> tensor<32xi32>
  %12 = arith.addi %10, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %13 = arith.addi %11, %4 : tensor<32xi32>
  %14 = triton_gpu.convert_layout %7 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %15 = tt.expand_dims %14 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %16 = builtin.unrealized_conversion_cast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.expand_dims %8 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %18 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %20 = arith.muli %16, %18 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = arith.muli %17, %19 : tensor<32x1xi32>
  %22 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %23 = tt.expand_dims %22 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %24 = builtin.unrealized_conversion_cast %23 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %26 = tt.broadcast %20 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = builtin.unrealized_conversion_cast %26 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = tt.broadcast %21 : tensor<32x1xi32> -> tensor<32x32xi32>
  %29 = tt.broadcast %24 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.broadcast %25 : tensor<1x32xi32> -> tensor<32x32xi32>
  %31 = arith.addi %27, %29 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %32 = arith.addi %28, %30 : tensor<32x32xi32>
  %33 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %34 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %35 = tt.addptr %33, %31 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = tt.addptr %34, %32 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %37 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %38 = tt.expand_dims %37 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %39 = builtin.unrealized_conversion_cast %38 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.expand_dims %4 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %41 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %43 = arith.muli %39, %41 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = arith.muli %40, %42 : tensor<32x1xi32>
  %45 = tt.expand_dims %13 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %46 = tt.broadcast %44 : tensor<32x1xi32> -> tensor<32x32xi32>
  %47 = tt.broadcast %45 : tensor<1x32xi32> -> tensor<32x32xi32>
  %48 = arith.addi %46, %47 : tensor<32x32xi32>
  %49 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %50 = tt.addptr %49, %48 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %51 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %52 = tt.addptr %51, %13 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %53 = arith.addi %arg8, %c31_i32 : i32
  %54 = arith.divsi %53, %c32_i32 : i32
  %55 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %56 = arith.cmpi slt, %17, %55 : tensor<32x1xi32>
  %57 = tt.broadcast %56 : tensor<32x1xi1> -> tensor<32x32xi1>
  %58 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %59 = arith.cmpi slt, %45, %58 : tensor<1x32xi32>
  %60 = tt.broadcast %59 : tensor<1x32xi1> -> tensor<32x32xi1>
  %61 = arith.muli %arg10, %c32_i32 : i32
  %62 = tt.splat %61 : i32 -> tensor<32x32xi32>
  %63:3 = scf.for %arg12 = %c0_i32 to %54 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %36, %arg15 = %50) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %91 = arith.muli %arg12, %c32_i32 : i32
    %92 = arith.subi %arg8, %91 : i32
    %93 = tt.splat %92 : i32 -> tensor<1x32xi32>
    %94 = arith.cmpi slt, %25, %93 : tensor<1x32xi32>
    %95 = tt.broadcast %94 : tensor<1x32xi1> -> tensor<32x32xi1>
    %96 = arith.andi %57, %95 : tensor<32x32xi1>
    %97 = tt.load %arg14, %96, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %98 = tt.splat %92 : i32 -> tensor<32x1xi32>
    %99 = arith.cmpi slt, %40, %98 : tensor<32x1xi32>
    %100 = tt.broadcast %99 : tensor<32x1xi1> -> tensor<32x32xi1>
    %101 = arith.andi %100, %60 : tensor<32x32xi1>
    %102 = tt.load %arg15, %101, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %103 = tt.dot %97, %102, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %104 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %105 = tt.addptr %arg15, %62 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %103, %104, %105 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %64 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %65 = arith.cmpi slt, %13, %64 : tensor<32xi32>
  %66 = tt.load %52, %65, %cst_0 : tensor<32x!tt.ptr<f16>>
  %67 = arith.sitofp %arg4 : i32 to f32
  %68 = tt.splat %67 : f32 -> tensor<32x32xf32>
  %69 = arith.mulf %63#0, %68 : tensor<32x32xf32>
  %70 = arith.sitofp %arg5 : i32 to f16
  %71 = tt.splat %70 : f16 -> tensor<32xf16>
  %72 = arith.mulf %66, %71 : tensor<32xf16>
  %73 = tt.expand_dims %72 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %74 = arith.extf %73 : tensor<1x32xf16> to tensor<1x32xf32>
  %75 = tt.broadcast %74 : tensor<1x32xf32> -> tensor<32x32xf32>
  %76 = arith.addf %69, %75 : tensor<32x32xf32>
  %77 = arith.truncf %76 : tensor<32x32xf32> to tensor<32x32xf16>
  %78 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %79 = arith.muli %78, %17 : tensor<32x1xi32>
  %80 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %81 = tt.addptr %80, %79 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %82 = tt.broadcast %81 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %83 = tt.addptr %82, %47 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %84 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %85 = arith.cmpi slt, %17, %84 : tensor<32x1xi32>
  %86 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %87 = arith.cmpi slt, %45, %86 : tensor<1x32xi32>
  %88 = tt.broadcast %85 : tensor<32x1xi1> -> tensor<32x32xi1>
  %89 = tt.broadcast %87 : tensor<1x32xi1> -> tensor<32x32xi1>
  %90 = arith.andi %88, %89 : tensor<32x32xi1>
  tt.store %83, %77, %90 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.expand_dims'(0x555d5be997a0) {
  %57 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.expand_dims -> ()' {
Trying to match "{anonymous}::TritonExpandDimsPattern"
    ** Insert  : 'triton_gpu.convert_layout'(0x555d5bed8e30)
    ** Insert  : 'tt.expand_dims'(0x555d5bed8880)
    ** Replace : 'tt.expand_dims'(0x555d5be997a0)
"{anonymous}::TritonExpandDimsPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'triton_gpu.convert_layout'(0x555d5bed8e30) {
      %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'tt.expand_dims'(0x555d5bed8880) {
      %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %5 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32>
  %7 = arith.addi %5, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %8 = arith.addi %6, %4 : tensor<32xi32>
  %9 = arith.muli %1, %c32_i32 : i32
  %10 = tt.splat %9 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %11 = tt.splat %9 : i32 -> tensor<32xi32>
  %12 = arith.addi %10, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %13 = arith.addi %11, %4 : tensor<32xi32>
  %14 = triton_gpu.convert_layout %7 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %15 = tt.expand_dims %14 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %16 = builtin.unrealized_conversion_cast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.expand_dims %8 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %18 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %20 = arith.muli %16, %18 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = arith.muli %17, %19 : tensor<32x1xi32>
  %22 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %23 = tt.expand_dims %22 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %24 = builtin.unrealized_conversion_cast %23 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %26 = tt.broadcast %20 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = builtin.unrealized_conversion_cast %26 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = tt.broadcast %21 : tensor<32x1xi32> -> tensor<32x32xi32>
  %29 = tt.broadcast %24 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.broadcast %25 : tensor<1x32xi32> -> tensor<32x32xi32>
  %31 = arith.addi %27, %29 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %32 = arith.addi %28, %30 : tensor<32x32xi32>
  %33 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %34 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %35 = tt.addptr %33, %31 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = tt.addptr %34, %32 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %37 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %38 = tt.expand_dims %37 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %39 = builtin.unrealized_conversion_cast %38 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.expand_dims %4 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %41 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %43 = arith.muli %39, %41 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = arith.muli %40, %42 : tensor<32x1xi32>
  %45 = triton_gpu.convert_layout %12 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %46 = tt.expand_dims %45 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %47 = tt.expand_dims %13 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %48 = tt.broadcast %44 : tensor<32x1xi32> -> tensor<32x32xi32>
  %49 = tt.broadcast %47 : tensor<1x32xi32> -> tensor<32x32xi32>
  %50 = arith.addi %48, %49 : tensor<32x32xi32>
  %51 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %52 = tt.addptr %51, %50 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %53 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %54 = tt.addptr %53, %13 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %55 = arith.addi %arg8, %c31_i32 : i32
  %56 = arith.divsi %55, %c32_i32 : i32
  %57 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %58 = arith.cmpi slt, %17, %57 : tensor<32x1xi32>
  %59 = tt.broadcast %58 : tensor<32x1xi1> -> tensor<32x32xi1>
  %60 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %61 = arith.cmpi slt, %47, %60 : tensor<1x32xi32>
  %62 = tt.broadcast %61 : tensor<1x32xi1> -> tensor<32x32xi1>
  %63 = arith.muli %arg10, %c32_i32 : i32
  %64 = tt.splat %63 : i32 -> tensor<32x32xi32>
  %65:3 = scf.for %arg12 = %c0_i32 to %56 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %36, %arg15 = %52) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %93 = arith.muli %arg12, %c32_i32 : i32
    %94 = arith.subi %arg8, %93 : i32
    %95 = tt.splat %94 : i32 -> tensor<1x32xi32>
    %96 = arith.cmpi slt, %25, %95 : tensor<1x32xi32>
    %97 = tt.broadcast %96 : tensor<1x32xi1> -> tensor<32x32xi1>
    %98 = arith.andi %59, %97 : tensor<32x32xi1>
    %99 = tt.load %arg14, %98, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %100 = tt.splat %94 : i32 -> tensor<32x1xi32>
    %101 = arith.cmpi slt, %40, %100 : tensor<32x1xi32>
    %102 = tt.broadcast %101 : tensor<32x1xi1> -> tensor<32x32xi1>
    %103 = arith.andi %102, %62 : tensor<32x32xi1>
    %104 = tt.load %arg15, %103, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %105 = tt.dot %99, %104, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %106 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %107 = tt.addptr %arg15, %64 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %105, %106, %107 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %66 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %67 = arith.cmpi slt, %13, %66 : tensor<32xi32>
  %68 = tt.load %54, %67, %cst_0 : tensor<32x!tt.ptr<f16>>
  %69 = arith.sitofp %arg4 : i32 to f32
  %70 = tt.splat %69 : f32 -> tensor<32x32xf32>
  %71 = arith.mulf %65#0, %70 : tensor<32x32xf32>
  %72 = arith.sitofp %arg5 : i32 to f16
  %73 = tt.splat %72 : f16 -> tensor<32xf16>
  %74 = arith.mulf %68, %73 : tensor<32xf16>
  %75 = tt.expand_dims %74 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %76 = arith.extf %75 : tensor<1x32xf16> to tensor<1x32xf32>
  %77 = tt.broadcast %76 : tensor<1x32xf32> -> tensor<32x32xf32>
  %78 = arith.addf %71, %77 : tensor<32x32xf32>
  %79 = arith.truncf %78 : tensor<32x32xf32> to tensor<32x32xf16>
  %80 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %81 = arith.muli %80, %17 : tensor<32x1xi32>
  %82 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %83 = tt.addptr %82, %81 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %84 = tt.broadcast %83 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %85 = tt.addptr %84, %49 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %86 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %87 = arith.cmpi slt, %17, %86 : tensor<32x1xi32>
  %88 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %89 = arith.cmpi slt, %47, %88 : tensor<1x32xi32>
  %90 = tt.broadcast %87 : tensor<32x1xi1> -> tensor<32x32xi1>
  %91 = tt.broadcast %89 : tensor<1x32xi1> -> tensor<32x32xi1>
  %92 = arith.andi %90, %91 : tensor<32x32xi1>
  tt.store %85, %79, %92 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.broadcast'(0x555d5be99890) {
  %60 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.broadcast -> ()' {
Trying to match "{anonymous}::TritonBroadcastPattern"
    ** Insert  : 'tt.broadcast'(0x555d5bed8000)
    ** Replace : 'tt.broadcast'(0x555d5be99890)
"{anonymous}::TritonBroadcastPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.broadcast'(0x555d5bed8000) {
      %60 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %5 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32>
  %7 = arith.addi %5, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %8 = arith.addi %6, %4 : tensor<32xi32>
  %9 = arith.muli %1, %c32_i32 : i32
  %10 = tt.splat %9 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %11 = tt.splat %9 : i32 -> tensor<32xi32>
  %12 = arith.addi %10, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %13 = arith.addi %11, %4 : tensor<32xi32>
  %14 = triton_gpu.convert_layout %7 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %15 = tt.expand_dims %14 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %16 = builtin.unrealized_conversion_cast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.expand_dims %8 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %18 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %20 = arith.muli %16, %18 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = arith.muli %17, %19 : tensor<32x1xi32>
  %22 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %23 = tt.expand_dims %22 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %24 = builtin.unrealized_conversion_cast %23 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %26 = tt.broadcast %20 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = builtin.unrealized_conversion_cast %26 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = tt.broadcast %21 : tensor<32x1xi32> -> tensor<32x32xi32>
  %29 = tt.broadcast %24 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.broadcast %25 : tensor<1x32xi32> -> tensor<32x32xi32>
  %31 = arith.addi %27, %29 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %32 = arith.addi %28, %30 : tensor<32x32xi32>
  %33 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %34 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %35 = tt.addptr %33, %31 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = tt.addptr %34, %32 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %37 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %38 = tt.expand_dims %37 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %39 = builtin.unrealized_conversion_cast %38 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.expand_dims %4 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %41 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %43 = arith.muli %39, %41 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = arith.muli %40, %42 : tensor<32x1xi32>
  %45 = triton_gpu.convert_layout %12 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %46 = tt.expand_dims %45 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %47 = tt.expand_dims %13 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %48 = tt.broadcast %43 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %49 = tt.broadcast %44 : tensor<32x1xi32> -> tensor<32x32xi32>
  %50 = tt.broadcast %47 : tensor<1x32xi32> -> tensor<32x32xi32>
  %51 = arith.addi %49, %50 : tensor<32x32xi32>
  %52 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %53 = tt.addptr %52, %51 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %54 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %55 = tt.addptr %54, %13 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %56 = arith.addi %arg8, %c31_i32 : i32
  %57 = arith.divsi %56, %c32_i32 : i32
  %58 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %59 = arith.cmpi slt, %17, %58 : tensor<32x1xi32>
  %60 = tt.broadcast %59 : tensor<32x1xi1> -> tensor<32x32xi1>
  %61 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %62 = arith.cmpi slt, %47, %61 : tensor<1x32xi32>
  %63 = tt.broadcast %62 : tensor<1x32xi1> -> tensor<32x32xi1>
  %64 = arith.muli %arg10, %c32_i32 : i32
  %65 = tt.splat %64 : i32 -> tensor<32x32xi32>
  %66:3 = scf.for %arg12 = %c0_i32 to %57 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %36, %arg15 = %53) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %94 = arith.muli %arg12, %c32_i32 : i32
    %95 = arith.subi %arg8, %94 : i32
    %96 = tt.splat %95 : i32 -> tensor<1x32xi32>
    %97 = arith.cmpi slt, %25, %96 : tensor<1x32xi32>
    %98 = tt.broadcast %97 : tensor<1x32xi1> -> tensor<32x32xi1>
    %99 = arith.andi %60, %98 : tensor<32x32xi1>
    %100 = tt.load %arg14, %99, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %101 = tt.splat %95 : i32 -> tensor<32x1xi32>
    %102 = arith.cmpi slt, %40, %101 : tensor<32x1xi32>
    %103 = tt.broadcast %102 : tensor<32x1xi1> -> tensor<32x32xi1>
    %104 = arith.andi %103, %63 : tensor<32x32xi1>
    %105 = tt.load %arg15, %104, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %106 = tt.dot %100, %105, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %107 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %108 = tt.addptr %arg15, %65 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %106, %107, %108 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %67 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %68 = arith.cmpi slt, %13, %67 : tensor<32xi32>
  %69 = tt.load %55, %68, %cst_0 : tensor<32x!tt.ptr<f16>>
  %70 = arith.sitofp %arg4 : i32 to f32
  %71 = tt.splat %70 : f32 -> tensor<32x32xf32>
  %72 = arith.mulf %66#0, %71 : tensor<32x32xf32>
  %73 = arith.sitofp %arg5 : i32 to f16
  %74 = tt.splat %73 : f16 -> tensor<32xf16>
  %75 = arith.mulf %69, %74 : tensor<32xf16>
  %76 = tt.expand_dims %75 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %77 = arith.extf %76 : tensor<1x32xf16> to tensor<1x32xf32>
  %78 = tt.broadcast %77 : tensor<1x32xf32> -> tensor<32x32xf32>
  %79 = arith.addf %72, %78 : tensor<32x32xf32>
  %80 = arith.truncf %79 : tensor<32x32xf32> to tensor<32x32xf16>
  %81 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %82 = arith.muli %81, %17 : tensor<32x1xi32>
  %83 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %84 = tt.addptr %83, %82 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %85 = tt.broadcast %84 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %86 = tt.addptr %85, %50 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %87 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %88 = arith.cmpi slt, %17, %87 : tensor<32x1xi32>
  %89 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %90 = arith.cmpi slt, %47, %89 : tensor<1x32xi32>
  %91 = tt.broadcast %88 : tensor<32x1xi1> -> tensor<32x32xi1>
  %92 = tt.broadcast %90 : tensor<1x32xi1> -> tensor<32x32xi1>
  %93 = arith.andi %91, %92 : tensor<32x32xi1>
  tt.store %86, %80, %93 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.broadcast'(0x555d5be99980) {
  %62 = "tt.broadcast"(%59) : (tensor<1x32xi32>) -> tensor<32x32xi32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.broadcast -> ()' {
Trying to match "{anonymous}::TritonBroadcastPattern"
    ** Insert  : 'tt.broadcast'(0x555d5bed9560)
    ** Replace : 'tt.broadcast'(0x555d5be99980)
"{anonymous}::TritonBroadcastPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.broadcast'(0x555d5bed9560) {
      %63 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %5 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32>
  %7 = arith.addi %5, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %8 = arith.addi %6, %4 : tensor<32xi32>
  %9 = arith.muli %1, %c32_i32 : i32
  %10 = tt.splat %9 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %11 = tt.splat %9 : i32 -> tensor<32xi32>
  %12 = arith.addi %10, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %13 = arith.addi %11, %4 : tensor<32xi32>
  %14 = triton_gpu.convert_layout %7 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %15 = tt.expand_dims %14 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %16 = builtin.unrealized_conversion_cast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.expand_dims %8 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %18 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %20 = arith.muli %16, %18 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = arith.muli %17, %19 : tensor<32x1xi32>
  %22 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %23 = tt.expand_dims %22 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %24 = builtin.unrealized_conversion_cast %23 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %26 = tt.broadcast %20 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = builtin.unrealized_conversion_cast %26 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = tt.broadcast %21 : tensor<32x1xi32> -> tensor<32x32xi32>
  %29 = tt.broadcast %24 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.broadcast %25 : tensor<1x32xi32> -> tensor<32x32xi32>
  %31 = arith.addi %27, %29 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %32 = arith.addi %28, %30 : tensor<32x32xi32>
  %33 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %34 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %35 = tt.addptr %33, %31 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = tt.addptr %34, %32 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %37 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %38 = tt.expand_dims %37 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %39 = builtin.unrealized_conversion_cast %38 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.expand_dims %4 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %41 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %43 = arith.muli %39, %41 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = arith.muli %40, %42 : tensor<32x1xi32>
  %45 = triton_gpu.convert_layout %12 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %46 = tt.expand_dims %45 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %47 = builtin.unrealized_conversion_cast %46 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = tt.expand_dims %13 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %49 = tt.broadcast %43 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %50 = tt.broadcast %44 : tensor<32x1xi32> -> tensor<32x32xi32>
  %51 = tt.broadcast %47 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = tt.broadcast %48 : tensor<1x32xi32> -> tensor<32x32xi32>
  %53 = arith.addi %50, %52 : tensor<32x32xi32>
  %54 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %55 = tt.addptr %54, %53 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %56 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %57 = tt.addptr %56, %13 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %58 = arith.addi %arg8, %c31_i32 : i32
  %59 = arith.divsi %58, %c32_i32 : i32
  %60 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %61 = arith.cmpi slt, %17, %60 : tensor<32x1xi32>
  %62 = tt.broadcast %61 : tensor<32x1xi1> -> tensor<32x32xi1>
  %63 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %64 = arith.cmpi slt, %48, %63 : tensor<1x32xi32>
  %65 = tt.broadcast %64 : tensor<1x32xi1> -> tensor<32x32xi1>
  %66 = arith.muli %arg10, %c32_i32 : i32
  %67 = tt.splat %66 : i32 -> tensor<32x32xi32>
  %68:3 = scf.for %arg12 = %c0_i32 to %59 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %36, %arg15 = %55) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %96 = arith.muli %arg12, %c32_i32 : i32
    %97 = arith.subi %arg8, %96 : i32
    %98 = tt.splat %97 : i32 -> tensor<1x32xi32>
    %99 = arith.cmpi slt, %25, %98 : tensor<1x32xi32>
    %100 = tt.broadcast %99 : tensor<1x32xi1> -> tensor<32x32xi1>
    %101 = arith.andi %62, %100 : tensor<32x32xi1>
    %102 = tt.load %arg14, %101, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %103 = tt.splat %97 : i32 -> tensor<32x1xi32>
    %104 = arith.cmpi slt, %40, %103 : tensor<32x1xi32>
    %105 = tt.broadcast %104 : tensor<32x1xi1> -> tensor<32x32xi1>
    %106 = arith.andi %105, %65 : tensor<32x32xi1>
    %107 = tt.load %arg15, %106, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %108 = tt.dot %102, %107, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %109 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %110 = tt.addptr %arg15, %67 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %108, %109, %110 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %69 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %70 = arith.cmpi slt, %13, %69 : tensor<32xi32>
  %71 = tt.load %57, %70, %cst_0 : tensor<32x!tt.ptr<f16>>
  %72 = arith.sitofp %arg4 : i32 to f32
  %73 = tt.splat %72 : f32 -> tensor<32x32xf32>
  %74 = arith.mulf %68#0, %73 : tensor<32x32xf32>
  %75 = arith.sitofp %arg5 : i32 to f16
  %76 = tt.splat %75 : f16 -> tensor<32xf16>
  %77 = arith.mulf %71, %76 : tensor<32xf16>
  %78 = tt.expand_dims %77 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %79 = arith.extf %78 : tensor<1x32xf16> to tensor<1x32xf32>
  %80 = tt.broadcast %79 : tensor<1x32xf32> -> tensor<32x32xf32>
  %81 = arith.addf %74, %80 : tensor<32x32xf32>
  %82 = arith.truncf %81 : tensor<32x32xf32> to tensor<32x32xf16>
  %83 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %84 = arith.muli %83, %17 : tensor<32x1xi32>
  %85 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %86 = tt.addptr %85, %84 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %87 = tt.broadcast %86 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %88 = tt.addptr %87, %52 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %89 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %90 = arith.cmpi slt, %17, %89 : tensor<32x1xi32>
  %91 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %92 = arith.cmpi slt, %48, %91 : tensor<1x32xi32>
  %93 = tt.broadcast %90 : tensor<32x1xi1> -> tensor<32x32xi1>
  %94 = tt.broadcast %92 : tensor<1x32xi1> -> tensor<32x32xi1>
  %95 = arith.andi %93, %94 : tensor<32x32xi1>
  tt.store %88, %82, %95 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.addi'(0x555d5be99a70) {
  %65 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'arith.addi -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::arith::AddIOp>"
    ** Insert  : 'arith.addi'(0x555d5bed8770)
    ** Replace : 'arith.addi'(0x555d5be99a70)
"{anonymous}::GenericOpPattern<mlir::arith::AddIOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'arith.addi'(0x555d5bed8770) {
      %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %5 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32>
  %7 = arith.addi %5, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %8 = arith.addi %6, %4 : tensor<32xi32>
  %9 = arith.muli %1, %c32_i32 : i32
  %10 = tt.splat %9 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %11 = tt.splat %9 : i32 -> tensor<32xi32>
  %12 = arith.addi %10, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %13 = arith.addi %11, %4 : tensor<32xi32>
  %14 = triton_gpu.convert_layout %7 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %15 = tt.expand_dims %14 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %16 = builtin.unrealized_conversion_cast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.expand_dims %8 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %18 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %20 = arith.muli %16, %18 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = arith.muli %17, %19 : tensor<32x1xi32>
  %22 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %23 = tt.expand_dims %22 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %24 = builtin.unrealized_conversion_cast %23 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %26 = tt.broadcast %20 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = builtin.unrealized_conversion_cast %26 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = tt.broadcast %21 : tensor<32x1xi32> -> tensor<32x32xi32>
  %29 = tt.broadcast %24 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.broadcast %25 : tensor<1x32xi32> -> tensor<32x32xi32>
  %31 = arith.addi %27, %29 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %32 = arith.addi %28, %30 : tensor<32x32xi32>
  %33 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %34 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %35 = tt.addptr %33, %31 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = tt.addptr %34, %32 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %37 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %38 = tt.expand_dims %37 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %39 = builtin.unrealized_conversion_cast %38 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.expand_dims %4 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %41 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %43 = arith.muli %39, %41 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = arith.muli %40, %42 : tensor<32x1xi32>
  %45 = triton_gpu.convert_layout %12 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %46 = tt.expand_dims %45 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %47 = builtin.unrealized_conversion_cast %46 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = tt.expand_dims %13 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %49 = tt.broadcast %43 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %50 = builtin.unrealized_conversion_cast %49 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %51 = tt.broadcast %44 : tensor<32x1xi32> -> tensor<32x32xi32>
  %52 = tt.broadcast %47 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %53 = tt.broadcast %48 : tensor<1x32xi32> -> tensor<32x32xi32>
  %54 = arith.addi %50, %52 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %55 = arith.addi %51, %53 : tensor<32x32xi32>
  %56 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %57 = tt.addptr %56, %55 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %58 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %59 = tt.addptr %58, %13 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %60 = arith.addi %arg8, %c31_i32 : i32
  %61 = arith.divsi %60, %c32_i32 : i32
  %62 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %63 = arith.cmpi slt, %17, %62 : tensor<32x1xi32>
  %64 = tt.broadcast %63 : tensor<32x1xi1> -> tensor<32x32xi1>
  %65 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %66 = arith.cmpi slt, %48, %65 : tensor<1x32xi32>
  %67 = tt.broadcast %66 : tensor<1x32xi1> -> tensor<32x32xi1>
  %68 = arith.muli %arg10, %c32_i32 : i32
  %69 = tt.splat %68 : i32 -> tensor<32x32xi32>
  %70:3 = scf.for %arg12 = %c0_i32 to %61 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %36, %arg15 = %57) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %98 = arith.muli %arg12, %c32_i32 : i32
    %99 = arith.subi %arg8, %98 : i32
    %100 = tt.splat %99 : i32 -> tensor<1x32xi32>
    %101 = arith.cmpi slt, %25, %100 : tensor<1x32xi32>
    %102 = tt.broadcast %101 : tensor<1x32xi1> -> tensor<32x32xi1>
    %103 = arith.andi %64, %102 : tensor<32x32xi1>
    %104 = tt.load %arg14, %103, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %105 = tt.splat %99 : i32 -> tensor<32x1xi32>
    %106 = arith.cmpi slt, %40, %105 : tensor<32x1xi32>
    %107 = tt.broadcast %106 : tensor<32x1xi1> -> tensor<32x32xi1>
    %108 = arith.andi %107, %67 : tensor<32x32xi1>
    %109 = tt.load %arg15, %108, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %110 = tt.dot %104, %109, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %111 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %112 = tt.addptr %arg15, %69 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %110, %111, %112 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %71 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %72 = arith.cmpi slt, %13, %71 : tensor<32xi32>
  %73 = tt.load %59, %72, %cst_0 : tensor<32x!tt.ptr<f16>>
  %74 = arith.sitofp %arg4 : i32 to f32
  %75 = tt.splat %74 : f32 -> tensor<32x32xf32>
  %76 = arith.mulf %70#0, %75 : tensor<32x32xf32>
  %77 = arith.sitofp %arg5 : i32 to f16
  %78 = tt.splat %77 : f16 -> tensor<32xf16>
  %79 = arith.mulf %73, %78 : tensor<32xf16>
  %80 = tt.expand_dims %79 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %81 = arith.extf %80 : tensor<1x32xf16> to tensor<1x32xf32>
  %82 = tt.broadcast %81 : tensor<1x32xf32> -> tensor<32x32xf32>
  %83 = arith.addf %76, %82 : tensor<32x32xf32>
  %84 = arith.truncf %83 : tensor<32x32xf32> to tensor<32x32xf16>
  %85 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %86 = arith.muli %85, %17 : tensor<32x1xi32>
  %87 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %88 = tt.addptr %87, %86 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %89 = tt.broadcast %88 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %90 = tt.addptr %89, %53 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %91 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %92 = arith.cmpi slt, %17, %91 : tensor<32x1xi32>
  %93 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %94 = arith.cmpi slt, %48, %93 : tensor<1x32xi32>
  %95 = tt.broadcast %92 : tensor<32x1xi1> -> tensor<32x32xi1>
  %96 = tt.broadcast %94 : tensor<1x32xi1> -> tensor<32x32xi1>
  %97 = arith.andi %95, %96 : tensor<32x32xi1>
  tt.store %90, %84, %97 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.splat'(0x555d5be9a190) {
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.splat -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::triton::SplatOp>"
    ** Insert  : 'tt.splat'(0x555d5bed9240)
    ** Replace : 'tt.splat'(0x555d5be9a190)
"{anonymous}::GenericOpPattern<mlir::triton::SplatOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.splat'(0x555d5bed9240) {
      %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %5 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32>
  %7 = arith.addi %5, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %8 = arith.addi %6, %4 : tensor<32xi32>
  %9 = arith.muli %1, %c32_i32 : i32
  %10 = tt.splat %9 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %11 = tt.splat %9 : i32 -> tensor<32xi32>
  %12 = arith.addi %10, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %13 = arith.addi %11, %4 : tensor<32xi32>
  %14 = triton_gpu.convert_layout %7 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %15 = tt.expand_dims %14 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %16 = builtin.unrealized_conversion_cast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.expand_dims %8 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %18 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %20 = arith.muli %16, %18 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = arith.muli %17, %19 : tensor<32x1xi32>
  %22 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %23 = tt.expand_dims %22 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %24 = builtin.unrealized_conversion_cast %23 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %26 = tt.broadcast %20 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = builtin.unrealized_conversion_cast %26 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = tt.broadcast %21 : tensor<32x1xi32> -> tensor<32x32xi32>
  %29 = tt.broadcast %24 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.broadcast %25 : tensor<1x32xi32> -> tensor<32x32xi32>
  %31 = arith.addi %27, %29 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %32 = arith.addi %28, %30 : tensor<32x32xi32>
  %33 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %34 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %35 = tt.addptr %33, %31 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = tt.addptr %34, %32 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %37 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %38 = tt.expand_dims %37 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %39 = builtin.unrealized_conversion_cast %38 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.expand_dims %4 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %41 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %43 = arith.muli %39, %41 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = arith.muli %40, %42 : tensor<32x1xi32>
  %45 = triton_gpu.convert_layout %12 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %46 = tt.expand_dims %45 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %47 = builtin.unrealized_conversion_cast %46 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = tt.expand_dims %13 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %49 = tt.broadcast %43 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %50 = builtin.unrealized_conversion_cast %49 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %51 = tt.broadcast %44 : tensor<32x1xi32> -> tensor<32x32xi32>
  %52 = tt.broadcast %47 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %53 = tt.broadcast %48 : tensor<1x32xi32> -> tensor<32x32xi32>
  %54 = arith.addi %50, %52 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %55 = arith.addi %51, %53 : tensor<32x32xi32>
  %56 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %58 = tt.addptr %57, %55 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %59 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %60 = tt.addptr %59, %13 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %61 = arith.addi %arg8, %c31_i32 : i32
  %62 = arith.divsi %61, %c32_i32 : i32
  %63 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %64 = arith.cmpi slt, %17, %63 : tensor<32x1xi32>
  %65 = tt.broadcast %64 : tensor<32x1xi1> -> tensor<32x32xi1>
  %66 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %67 = arith.cmpi slt, %48, %66 : tensor<1x32xi32>
  %68 = tt.broadcast %67 : tensor<1x32xi1> -> tensor<32x32xi1>
  %69 = arith.muli %arg10, %c32_i32 : i32
  %70 = tt.splat %69 : i32 -> tensor<32x32xi32>
  %71:3 = scf.for %arg12 = %c0_i32 to %62 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %36, %arg15 = %58) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %99 = arith.muli %arg12, %c32_i32 : i32
    %100 = arith.subi %arg8, %99 : i32
    %101 = tt.splat %100 : i32 -> tensor<1x32xi32>
    %102 = arith.cmpi slt, %25, %101 : tensor<1x32xi32>
    %103 = tt.broadcast %102 : tensor<1x32xi1> -> tensor<32x32xi1>
    %104 = arith.andi %65, %103 : tensor<32x32xi1>
    %105 = tt.load %arg14, %104, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %106 = tt.splat %100 : i32 -> tensor<32x1xi32>
    %107 = arith.cmpi slt, %40, %106 : tensor<32x1xi32>
    %108 = tt.broadcast %107 : tensor<32x1xi1> -> tensor<32x32xi1>
    %109 = arith.andi %108, %68 : tensor<32x32xi1>
    %110 = tt.load %arg15, %109, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %111 = tt.dot %105, %110, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %112 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %113 = tt.addptr %arg15, %70 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %111, %112, %113 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %72 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %73 = arith.cmpi slt, %13, %72 : tensor<32xi32>
  %74 = tt.load %60, %73, %cst_0 : tensor<32x!tt.ptr<f16>>
  %75 = arith.sitofp %arg4 : i32 to f32
  %76 = tt.splat %75 : f32 -> tensor<32x32xf32>
  %77 = arith.mulf %71#0, %76 : tensor<32x32xf32>
  %78 = arith.sitofp %arg5 : i32 to f16
  %79 = tt.splat %78 : f16 -> tensor<32xf16>
  %80 = arith.mulf %74, %79 : tensor<32xf16>
  %81 = tt.expand_dims %80 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %82 = arith.extf %81 : tensor<1x32xf16> to tensor<1x32xf32>
  %83 = tt.broadcast %82 : tensor<1x32xf32> -> tensor<32x32xf32>
  %84 = arith.addf %77, %83 : tensor<32x32xf32>
  %85 = arith.truncf %84 : tensor<32x32xf32> to tensor<32x32xf16>
  %86 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %87 = arith.muli %86, %17 : tensor<32x1xi32>
  %88 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %89 = tt.addptr %88, %87 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %90 = tt.broadcast %89 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %91 = tt.addptr %90, %53 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %92 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %93 = arith.cmpi slt, %17, %92 : tensor<32x1xi32>
  %94 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %95 = arith.cmpi slt, %48, %94 : tensor<1x32xi32>
  %96 = tt.broadcast %93 : tensor<32x1xi1> -> tensor<32x32xi1>
  %97 = tt.broadcast %95 : tensor<1x32xi1> -> tensor<32x32xi1>
  %98 = arith.andi %96, %97 : tensor<32x32xi1>
  tt.store %91, %85, %98 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.addptr'(0x555d5be9a280) {
  %70 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.addptr -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::triton::AddPtrOp>"
    ** Insert  : 'tt.addptr'(0x555d5bed7cb0)
    ** Replace : 'tt.addptr'(0x555d5be9a280)
"{anonymous}::GenericOpPattern<mlir::triton::AddPtrOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.addptr'(0x555d5bed7cb0) {
      %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %5 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32>
  %7 = arith.addi %5, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %8 = arith.addi %6, %4 : tensor<32xi32>
  %9 = arith.muli %1, %c32_i32 : i32
  %10 = tt.splat %9 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %11 = tt.splat %9 : i32 -> tensor<32xi32>
  %12 = arith.addi %10, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %13 = arith.addi %11, %4 : tensor<32xi32>
  %14 = triton_gpu.convert_layout %7 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %15 = tt.expand_dims %14 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %16 = builtin.unrealized_conversion_cast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.expand_dims %8 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %18 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %20 = arith.muli %16, %18 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = arith.muli %17, %19 : tensor<32x1xi32>
  %22 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %23 = tt.expand_dims %22 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %24 = builtin.unrealized_conversion_cast %23 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %26 = tt.broadcast %20 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = builtin.unrealized_conversion_cast %26 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = tt.broadcast %21 : tensor<32x1xi32> -> tensor<32x32xi32>
  %29 = tt.broadcast %24 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.broadcast %25 : tensor<1x32xi32> -> tensor<32x32xi32>
  %31 = arith.addi %27, %29 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %32 = arith.addi %28, %30 : tensor<32x32xi32>
  %33 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %34 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %35 = tt.addptr %33, %31 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = tt.addptr %34, %32 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %37 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %38 = tt.expand_dims %37 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %39 = builtin.unrealized_conversion_cast %38 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.expand_dims %4 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %41 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %43 = arith.muli %39, %41 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = arith.muli %40, %42 : tensor<32x1xi32>
  %45 = triton_gpu.convert_layout %12 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %46 = tt.expand_dims %45 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %47 = builtin.unrealized_conversion_cast %46 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = tt.expand_dims %13 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %49 = tt.broadcast %43 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %50 = builtin.unrealized_conversion_cast %49 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %51 = tt.broadcast %44 : tensor<32x1xi32> -> tensor<32x32xi32>
  %52 = tt.broadcast %47 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %53 = tt.broadcast %48 : tensor<1x32xi32> -> tensor<32x32xi32>
  %54 = arith.addi %50, %52 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %55 = arith.addi %51, %53 : tensor<32x32xi32>
  %56 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %58 = tt.addptr %56, %54 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = tt.addptr %57, %55 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %60 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %61 = tt.addptr %60, %13 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %62 = arith.addi %arg8, %c31_i32 : i32
  %63 = arith.divsi %62, %c32_i32 : i32
  %64 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %65 = arith.cmpi slt, %17, %64 : tensor<32x1xi32>
  %66 = tt.broadcast %65 : tensor<32x1xi1> -> tensor<32x32xi1>
  %67 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %68 = arith.cmpi slt, %48, %67 : tensor<1x32xi32>
  %69 = tt.broadcast %68 : tensor<1x32xi1> -> tensor<32x32xi1>
  %70 = arith.muli %arg10, %c32_i32 : i32
  %71 = tt.splat %70 : i32 -> tensor<32x32xi32>
  %72:3 = scf.for %arg12 = %c0_i32 to %63 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %36, %arg15 = %59) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %100 = arith.muli %arg12, %c32_i32 : i32
    %101 = arith.subi %arg8, %100 : i32
    %102 = tt.splat %101 : i32 -> tensor<1x32xi32>
    %103 = arith.cmpi slt, %25, %102 : tensor<1x32xi32>
    %104 = tt.broadcast %103 : tensor<1x32xi1> -> tensor<32x32xi1>
    %105 = arith.andi %66, %104 : tensor<32x32xi1>
    %106 = tt.load %arg14, %105, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %107 = tt.splat %101 : i32 -> tensor<32x1xi32>
    %108 = arith.cmpi slt, %40, %107 : tensor<32x1xi32>
    %109 = tt.broadcast %108 : tensor<32x1xi1> -> tensor<32x32xi1>
    %110 = arith.andi %109, %69 : tensor<32x32xi1>
    %111 = tt.load %arg15, %110, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %112 = tt.dot %106, %111, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %113 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %114 = tt.addptr %arg15, %71 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %112, %113, %114 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %73 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %74 = arith.cmpi slt, %13, %73 : tensor<32xi32>
  %75 = tt.load %61, %74, %cst_0 : tensor<32x!tt.ptr<f16>>
  %76 = arith.sitofp %arg4 : i32 to f32
  %77 = tt.splat %76 : f32 -> tensor<32x32xf32>
  %78 = arith.mulf %72#0, %77 : tensor<32x32xf32>
  %79 = arith.sitofp %arg5 : i32 to f16
  %80 = tt.splat %79 : f16 -> tensor<32xf16>
  %81 = arith.mulf %75, %80 : tensor<32xf16>
  %82 = tt.expand_dims %81 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %83 = arith.extf %82 : tensor<1x32xf16> to tensor<1x32xf32>
  %84 = tt.broadcast %83 : tensor<1x32xf32> -> tensor<32x32xf32>
  %85 = arith.addf %78, %84 : tensor<32x32xf32>
  %86 = arith.truncf %85 : tensor<32x32xf32> to tensor<32x32xf16>
  %87 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %88 = arith.muli %87, %17 : tensor<32x1xi32>
  %89 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %90 = tt.addptr %89, %88 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %91 = tt.broadcast %90 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %92 = tt.addptr %91, %53 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %93 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %94 = arith.cmpi slt, %17, %93 : tensor<32x1xi32>
  %95 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %96 = arith.cmpi slt, %48, %95 : tensor<1x32xi32>
  %97 = tt.broadcast %94 : tensor<32x1xi1> -> tensor<32x32xi1>
  %98 = tt.broadcast %96 : tensor<1x32xi1> -> tensor<32x32xi1>
  %99 = arith.andi %97, %98 : tensor<32x32xi1>
  tt.store %92, %86, %99 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.splat'(0x555d5be9a390) {
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.splat -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::triton::SplatOp>"
    ** Insert  : 'tt.splat'(0x555d5bed9330)
    ** Replace : 'tt.splat'(0x555d5be9a390)
"{anonymous}::GenericOpPattern<mlir::triton::SplatOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.splat'(0x555d5bed9330) {
      %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %5 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32>
  %7 = arith.addi %5, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %8 = arith.addi %6, %4 : tensor<32xi32>
  %9 = arith.muli %1, %c32_i32 : i32
  %10 = tt.splat %9 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %11 = tt.splat %9 : i32 -> tensor<32xi32>
  %12 = arith.addi %10, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %13 = arith.addi %11, %4 : tensor<32xi32>
  %14 = triton_gpu.convert_layout %7 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %15 = tt.expand_dims %14 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %16 = builtin.unrealized_conversion_cast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.expand_dims %8 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %18 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %20 = arith.muli %16, %18 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = arith.muli %17, %19 : tensor<32x1xi32>
  %22 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %23 = tt.expand_dims %22 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %24 = builtin.unrealized_conversion_cast %23 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %26 = tt.broadcast %20 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = builtin.unrealized_conversion_cast %26 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = tt.broadcast %21 : tensor<32x1xi32> -> tensor<32x32xi32>
  %29 = tt.broadcast %24 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.broadcast %25 : tensor<1x32xi32> -> tensor<32x32xi32>
  %31 = arith.addi %27, %29 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %32 = arith.addi %28, %30 : tensor<32x32xi32>
  %33 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %34 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %35 = tt.addptr %33, %31 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = tt.addptr %34, %32 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %37 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %38 = tt.expand_dims %37 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %39 = builtin.unrealized_conversion_cast %38 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.expand_dims %4 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %41 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %43 = arith.muli %39, %41 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = arith.muli %40, %42 : tensor<32x1xi32>
  %45 = triton_gpu.convert_layout %12 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %46 = tt.expand_dims %45 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %47 = builtin.unrealized_conversion_cast %46 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = tt.expand_dims %13 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %49 = tt.broadcast %43 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %50 = builtin.unrealized_conversion_cast %49 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %51 = tt.broadcast %44 : tensor<32x1xi32> -> tensor<32x32xi32>
  %52 = tt.broadcast %47 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %53 = tt.broadcast %48 : tensor<1x32xi32> -> tensor<32x32xi32>
  %54 = arith.addi %50, %52 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %55 = arith.addi %51, %53 : tensor<32x32xi32>
  %56 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %58 = tt.addptr %56, %54 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = tt.addptr %57, %55 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %60 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %61 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %62 = tt.addptr %61, %13 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %63 = arith.addi %arg8, %c31_i32 : i32
  %64 = arith.divsi %63, %c32_i32 : i32
  %65 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %66 = arith.cmpi slt, %17, %65 : tensor<32x1xi32>
  %67 = tt.broadcast %66 : tensor<32x1xi1> -> tensor<32x32xi1>
  %68 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %69 = arith.cmpi slt, %48, %68 : tensor<1x32xi32>
  %70 = tt.broadcast %69 : tensor<1x32xi1> -> tensor<32x32xi1>
  %71 = arith.muli %arg10, %c32_i32 : i32
  %72 = tt.splat %71 : i32 -> tensor<32x32xi32>
  %73:3 = scf.for %arg12 = %c0_i32 to %64 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %36, %arg15 = %59) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %101 = arith.muli %arg12, %c32_i32 : i32
    %102 = arith.subi %arg8, %101 : i32
    %103 = tt.splat %102 : i32 -> tensor<1x32xi32>
    %104 = arith.cmpi slt, %25, %103 : tensor<1x32xi32>
    %105 = tt.broadcast %104 : tensor<1x32xi1> -> tensor<32x32xi1>
    %106 = arith.andi %67, %105 : tensor<32x32xi1>
    %107 = tt.load %arg14, %106, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %108 = tt.splat %102 : i32 -> tensor<32x1xi32>
    %109 = arith.cmpi slt, %40, %108 : tensor<32x1xi32>
    %110 = tt.broadcast %109 : tensor<32x1xi1> -> tensor<32x32xi1>
    %111 = arith.andi %110, %70 : tensor<32x32xi1>
    %112 = tt.load %arg15, %111, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %113 = tt.dot %107, %112, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %114 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %115 = tt.addptr %arg15, %72 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %113, %114, %115 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %74 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %75 = arith.cmpi slt, %13, %74 : tensor<32xi32>
  %76 = tt.load %62, %75, %cst_0 : tensor<32x!tt.ptr<f16>>
  %77 = arith.sitofp %arg4 : i32 to f32
  %78 = tt.splat %77 : f32 -> tensor<32x32xf32>
  %79 = arith.mulf %73#0, %78 : tensor<32x32xf32>
  %80 = arith.sitofp %arg5 : i32 to f16
  %81 = tt.splat %80 : f16 -> tensor<32xf16>
  %82 = arith.mulf %76, %81 : tensor<32xf16>
  %83 = tt.expand_dims %82 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %84 = arith.extf %83 : tensor<1x32xf16> to tensor<1x32xf32>
  %85 = tt.broadcast %84 : tensor<1x32xf32> -> tensor<32x32xf32>
  %86 = arith.addf %79, %85 : tensor<32x32xf32>
  %87 = arith.truncf %86 : tensor<32x32xf32> to tensor<32x32xf16>
  %88 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %89 = arith.muli %88, %17 : tensor<32x1xi32>
  %90 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %91 = tt.addptr %90, %89 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %92 = tt.broadcast %91 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %93 = tt.addptr %92, %53 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %94 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %95 = arith.cmpi slt, %17, %94 : tensor<32x1xi32>
  %96 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %97 = arith.cmpi slt, %48, %96 : tensor<1x32xi32>
  %98 = tt.broadcast %95 : tensor<32x1xi1> -> tensor<32x32xi1>
  %99 = tt.broadcast %97 : tensor<1x32xi1> -> tensor<32x32xi1>
  %100 = arith.andi %98, %99 : tensor<32x32xi1>
  tt.store %93, %87, %100 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.addptr'(0x555d5be9a480) {
  %74 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.addptr -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::triton::AddPtrOp>"
    ** Insert  : 'tt.addptr'(0x555d5bed78a0)
    ** Replace : 'tt.addptr'(0x555d5be9a480)
"{anonymous}::GenericOpPattern<mlir::triton::AddPtrOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.addptr'(0x555d5bed78a0) {
      %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %5 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32>
  %7 = arith.addi %5, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %8 = arith.addi %6, %4 : tensor<32xi32>
  %9 = arith.muli %1, %c32_i32 : i32
  %10 = tt.splat %9 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %11 = tt.splat %9 : i32 -> tensor<32xi32>
  %12 = arith.addi %10, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %13 = arith.addi %11, %4 : tensor<32xi32>
  %14 = triton_gpu.convert_layout %7 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %15 = tt.expand_dims %14 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %16 = builtin.unrealized_conversion_cast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.expand_dims %8 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %18 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %20 = arith.muli %16, %18 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = arith.muli %17, %19 : tensor<32x1xi32>
  %22 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %23 = tt.expand_dims %22 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %24 = builtin.unrealized_conversion_cast %23 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %26 = tt.broadcast %20 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = builtin.unrealized_conversion_cast %26 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = tt.broadcast %21 : tensor<32x1xi32> -> tensor<32x32xi32>
  %29 = tt.broadcast %24 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.broadcast %25 : tensor<1x32xi32> -> tensor<32x32xi32>
  %31 = arith.addi %27, %29 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %32 = arith.addi %28, %30 : tensor<32x32xi32>
  %33 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %34 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %35 = tt.addptr %33, %31 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = tt.addptr %34, %32 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %37 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %38 = tt.expand_dims %37 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %39 = builtin.unrealized_conversion_cast %38 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.expand_dims %4 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %41 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %43 = arith.muli %39, %41 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = arith.muli %40, %42 : tensor<32x1xi32>
  %45 = triton_gpu.convert_layout %12 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %46 = tt.expand_dims %45 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %47 = builtin.unrealized_conversion_cast %46 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = tt.expand_dims %13 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %49 = tt.broadcast %43 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %50 = builtin.unrealized_conversion_cast %49 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %51 = tt.broadcast %44 : tensor<32x1xi32> -> tensor<32x32xi32>
  %52 = tt.broadcast %47 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %53 = tt.broadcast %48 : tensor<1x32xi32> -> tensor<32x32xi32>
  %54 = arith.addi %50, %52 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %55 = arith.addi %51, %53 : tensor<32x32xi32>
  %56 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %58 = tt.addptr %56, %54 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = tt.addptr %57, %55 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %60 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %61 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %62 = tt.addptr %60, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %63 = tt.addptr %61, %13 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %64 = arith.addi %arg8, %c31_i32 : i32
  %65 = arith.divsi %64, %c32_i32 : i32
  %66 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %67 = arith.cmpi slt, %17, %66 : tensor<32x1xi32>
  %68 = tt.broadcast %67 : tensor<32x1xi1> -> tensor<32x32xi1>
  %69 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %70 = arith.cmpi slt, %48, %69 : tensor<1x32xi32>
  %71 = tt.broadcast %70 : tensor<1x32xi1> -> tensor<32x32xi1>
  %72 = arith.muli %arg10, %c32_i32 : i32
  %73 = tt.splat %72 : i32 -> tensor<32x32xi32>
  %74:3 = scf.for %arg12 = %c0_i32 to %65 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %36, %arg15 = %59) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %102 = arith.muli %arg12, %c32_i32 : i32
    %103 = arith.subi %arg8, %102 : i32
    %104 = tt.splat %103 : i32 -> tensor<1x32xi32>
    %105 = arith.cmpi slt, %25, %104 : tensor<1x32xi32>
    %106 = tt.broadcast %105 : tensor<1x32xi1> -> tensor<32x32xi1>
    %107 = arith.andi %68, %106 : tensor<32x32xi1>
    %108 = tt.load %arg14, %107, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %109 = tt.splat %103 : i32 -> tensor<32x1xi32>
    %110 = arith.cmpi slt, %40, %109 : tensor<32x1xi32>
    %111 = tt.broadcast %110 : tensor<32x1xi1> -> tensor<32x32xi1>
    %112 = arith.andi %111, %71 : tensor<32x32xi1>
    %113 = tt.load %arg15, %112, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %114 = tt.dot %108, %113, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %115 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %116 = tt.addptr %arg15, %73 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %114, %115, %116 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %75 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %76 = arith.cmpi slt, %13, %75 : tensor<32xi32>
  %77 = tt.load %63, %76, %cst_0 : tensor<32x!tt.ptr<f16>>
  %78 = arith.sitofp %arg4 : i32 to f32
  %79 = tt.splat %78 : f32 -> tensor<32x32xf32>
  %80 = arith.mulf %74#0, %79 : tensor<32x32xf32>
  %81 = arith.sitofp %arg5 : i32 to f16
  %82 = tt.splat %81 : f16 -> tensor<32xf16>
  %83 = arith.mulf %77, %82 : tensor<32xf16>
  %84 = tt.expand_dims %83 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %85 = arith.extf %84 : tensor<1x32xf16> to tensor<1x32xf32>
  %86 = tt.broadcast %85 : tensor<1x32xf32> -> tensor<32x32xf32>
  %87 = arith.addf %80, %86 : tensor<32x32xf32>
  %88 = arith.truncf %87 : tensor<32x32xf32> to tensor<32x32xf16>
  %89 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %90 = arith.muli %89, %17 : tensor<32x1xi32>
  %91 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %92 = tt.addptr %91, %90 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %93 = tt.broadcast %92 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %94 = tt.addptr %93, %53 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %95 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %96 = arith.cmpi slt, %17, %95 : tensor<32x1xi32>
  %97 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %98 = arith.cmpi slt, %48, %97 : tensor<1x32xi32>
  %99 = tt.broadcast %96 : tensor<32x1xi1> -> tensor<32x32xi1>
  %100 = tt.broadcast %98 : tensor<1x32xi1> -> tensor<32x32xi1>
  %101 = arith.andi %99, %100 : tensor<32x32xi1>
  tt.store %94, %88, %101 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.addi'(0x555d5be9b1d0) {
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.divsi'(0x555d5be9b2e0) {
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.splat'(0x555d5be9b3f0) {
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.splat -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::triton::SplatOp>"
    ** Insert  : 'tt.splat'(0x555d5bed9480)
    ** Replace : 'tt.splat'(0x555d5be9b3f0)
"{anonymous}::GenericOpPattern<mlir::triton::SplatOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.splat'(0x555d5bed9480) {
      %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %5 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32>
  %7 = arith.addi %5, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %8 = arith.addi %6, %4 : tensor<32xi32>
  %9 = arith.muli %1, %c32_i32 : i32
  %10 = tt.splat %9 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %11 = tt.splat %9 : i32 -> tensor<32xi32>
  %12 = arith.addi %10, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %13 = arith.addi %11, %4 : tensor<32xi32>
  %14 = triton_gpu.convert_layout %7 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %15 = tt.expand_dims %14 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %16 = builtin.unrealized_conversion_cast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.expand_dims %8 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %18 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %20 = arith.muli %16, %18 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = arith.muli %17, %19 : tensor<32x1xi32>
  %22 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %23 = tt.expand_dims %22 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %24 = builtin.unrealized_conversion_cast %23 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %26 = tt.broadcast %20 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = builtin.unrealized_conversion_cast %26 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = tt.broadcast %21 : tensor<32x1xi32> -> tensor<32x32xi32>
  %29 = tt.broadcast %24 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.broadcast %25 : tensor<1x32xi32> -> tensor<32x32xi32>
  %31 = arith.addi %27, %29 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %32 = arith.addi %28, %30 : tensor<32x32xi32>
  %33 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %34 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %35 = tt.addptr %33, %31 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = tt.addptr %34, %32 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %37 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %38 = tt.expand_dims %37 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %39 = builtin.unrealized_conversion_cast %38 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.expand_dims %4 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %41 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %43 = arith.muli %39, %41 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = arith.muli %40, %42 : tensor<32x1xi32>
  %45 = triton_gpu.convert_layout %12 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %46 = tt.expand_dims %45 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %47 = builtin.unrealized_conversion_cast %46 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = tt.expand_dims %13 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %49 = tt.broadcast %43 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %50 = builtin.unrealized_conversion_cast %49 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %51 = tt.broadcast %44 : tensor<32x1xi32> -> tensor<32x32xi32>
  %52 = tt.broadcast %47 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %53 = tt.broadcast %48 : tensor<1x32xi32> -> tensor<32x32xi32>
  %54 = arith.addi %50, %52 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %55 = arith.addi %51, %53 : tensor<32x32xi32>
  %56 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %58 = tt.addptr %56, %54 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = tt.addptr %57, %55 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %60 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %61 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %62 = tt.addptr %60, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %63 = tt.addptr %61, %13 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %64 = arith.addi %arg8, %c31_i32 : i32
  %65 = arith.divsi %64, %c32_i32 : i32
  %66 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %68 = arith.cmpi slt, %17, %67 : tensor<32x1xi32>
  %69 = tt.broadcast %68 : tensor<32x1xi1> -> tensor<32x32xi1>
  %70 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %71 = arith.cmpi slt, %48, %70 : tensor<1x32xi32>
  %72 = tt.broadcast %71 : tensor<1x32xi1> -> tensor<32x32xi1>
  %73 = arith.muli %arg10, %c32_i32 : i32
  %74 = tt.splat %73 : i32 -> tensor<32x32xi32>
  %75:3 = scf.for %arg12 = %c0_i32 to %65 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %36, %arg15 = %59) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %103 = arith.muli %arg12, %c32_i32 : i32
    %104 = arith.subi %arg8, %103 : i32
    %105 = tt.splat %104 : i32 -> tensor<1x32xi32>
    %106 = arith.cmpi slt, %25, %105 : tensor<1x32xi32>
    %107 = tt.broadcast %106 : tensor<1x32xi1> -> tensor<32x32xi1>
    %108 = arith.andi %69, %107 : tensor<32x32xi1>
    %109 = tt.load %arg14, %108, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %110 = tt.splat %104 : i32 -> tensor<32x1xi32>
    %111 = arith.cmpi slt, %40, %110 : tensor<32x1xi32>
    %112 = tt.broadcast %111 : tensor<32x1xi1> -> tensor<32x32xi1>
    %113 = arith.andi %112, %72 : tensor<32x32xi1>
    %114 = tt.load %arg15, %113, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %115 = tt.dot %109, %114, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %116 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %117 = tt.addptr %arg15, %74 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %115, %116, %117 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %76 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %77 = arith.cmpi slt, %13, %76 : tensor<32xi32>
  %78 = tt.load %63, %77, %cst_0 : tensor<32x!tt.ptr<f16>>
  %79 = arith.sitofp %arg4 : i32 to f32
  %80 = tt.splat %79 : f32 -> tensor<32x32xf32>
  %81 = arith.mulf %75#0, %80 : tensor<32x32xf32>
  %82 = arith.sitofp %arg5 : i32 to f16
  %83 = tt.splat %82 : f16 -> tensor<32xf16>
  %84 = arith.mulf %78, %83 : tensor<32xf16>
  %85 = tt.expand_dims %84 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %86 = arith.extf %85 : tensor<1x32xf16> to tensor<1x32xf32>
  %87 = tt.broadcast %86 : tensor<1x32xf32> -> tensor<32x32xf32>
  %88 = arith.addf %81, %87 : tensor<32x32xf32>
  %89 = arith.truncf %88 : tensor<32x32xf32> to tensor<32x32xf16>
  %90 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %91 = arith.muli %90, %17 : tensor<32x1xi32>
  %92 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %93 = tt.addptr %92, %91 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %94 = tt.broadcast %93 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %95 = tt.addptr %94, %53 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %96 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %97 = arith.cmpi slt, %17, %96 : tensor<32x1xi32>
  %98 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %99 = arith.cmpi slt, %48, %98 : tensor<1x32xi32>
  %100 = tt.broadcast %97 : tensor<32x1xi1> -> tensor<32x32xi1>
  %101 = tt.broadcast %99 : tensor<1x32xi1> -> tensor<32x32xi1>
  %102 = arith.andi %100, %101 : tensor<32x32xi1>
  tt.store %95, %89, %102 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.cmpi'(0x555d5be9b500) {
  %80 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'arith.cmpi -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::arith::CmpIOp>"
    ** Insert  : 'arith.cmpi'(0x555d5bed73c0)
    ** Replace : 'arith.cmpi'(0x555d5be9b500)
"{anonymous}::GenericOpPattern<mlir::arith::CmpIOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'arith.cmpi'(0x555d5bed73c0) {
      %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %5 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32>
  %7 = arith.addi %5, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %8 = arith.addi %6, %4 : tensor<32xi32>
  %9 = arith.muli %1, %c32_i32 : i32
  %10 = tt.splat %9 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %11 = tt.splat %9 : i32 -> tensor<32xi32>
  %12 = arith.addi %10, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %13 = arith.addi %11, %4 : tensor<32xi32>
  %14 = triton_gpu.convert_layout %7 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %15 = tt.expand_dims %14 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %16 = builtin.unrealized_conversion_cast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.expand_dims %8 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %18 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %20 = arith.muli %16, %18 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = arith.muli %17, %19 : tensor<32x1xi32>
  %22 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %23 = tt.expand_dims %22 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %24 = builtin.unrealized_conversion_cast %23 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %26 = tt.broadcast %20 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = builtin.unrealized_conversion_cast %26 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = tt.broadcast %21 : tensor<32x1xi32> -> tensor<32x32xi32>
  %29 = tt.broadcast %24 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.broadcast %25 : tensor<1x32xi32> -> tensor<32x32xi32>
  %31 = arith.addi %27, %29 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %32 = arith.addi %28, %30 : tensor<32x32xi32>
  %33 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %34 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %35 = tt.addptr %33, %31 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = tt.addptr %34, %32 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %37 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %38 = tt.expand_dims %37 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %39 = builtin.unrealized_conversion_cast %38 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.expand_dims %4 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %41 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %43 = arith.muli %39, %41 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = arith.muli %40, %42 : tensor<32x1xi32>
  %45 = triton_gpu.convert_layout %12 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %46 = tt.expand_dims %45 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %47 = builtin.unrealized_conversion_cast %46 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = tt.expand_dims %13 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %49 = tt.broadcast %43 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %50 = builtin.unrealized_conversion_cast %49 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %51 = tt.broadcast %44 : tensor<32x1xi32> -> tensor<32x32xi32>
  %52 = tt.broadcast %47 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %53 = tt.broadcast %48 : tensor<1x32xi32> -> tensor<32x32xi32>
  %54 = arith.addi %50, %52 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %55 = arith.addi %51, %53 : tensor<32x32xi32>
  %56 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %58 = tt.addptr %56, %54 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = tt.addptr %57, %55 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %60 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %61 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %62 = tt.addptr %60, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %63 = tt.addptr %61, %13 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %64 = arith.addi %arg8, %c31_i32 : i32
  %65 = arith.divsi %64, %c32_i32 : i32
  %66 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %68 = arith.cmpi slt, %16, %66 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = arith.cmpi slt, %17, %67 : tensor<32x1xi32>
  %70 = tt.broadcast %69 : tensor<32x1xi1> -> tensor<32x32xi1>
  %71 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %72 = arith.cmpi slt, %48, %71 : tensor<1x32xi32>
  %73 = tt.broadcast %72 : tensor<1x32xi1> -> tensor<32x32xi1>
  %74 = arith.muli %arg10, %c32_i32 : i32
  %75 = tt.splat %74 : i32 -> tensor<32x32xi32>
  %76:3 = scf.for %arg12 = %c0_i32 to %65 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %36, %arg15 = %59) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %104 = arith.muli %arg12, %c32_i32 : i32
    %105 = arith.subi %arg8, %104 : i32
    %106 = tt.splat %105 : i32 -> tensor<1x32xi32>
    %107 = arith.cmpi slt, %25, %106 : tensor<1x32xi32>
    %108 = tt.broadcast %107 : tensor<1x32xi1> -> tensor<32x32xi1>
    %109 = arith.andi %70, %108 : tensor<32x32xi1>
    %110 = tt.load %arg14, %109, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %111 = tt.splat %105 : i32 -> tensor<32x1xi32>
    %112 = arith.cmpi slt, %40, %111 : tensor<32x1xi32>
    %113 = tt.broadcast %112 : tensor<32x1xi1> -> tensor<32x32xi1>
    %114 = arith.andi %113, %73 : tensor<32x32xi1>
    %115 = tt.load %arg15, %114, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %116 = tt.dot %110, %115, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %117 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %118 = tt.addptr %arg15, %75 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %116, %117, %118 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %77 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %78 = arith.cmpi slt, %13, %77 : tensor<32xi32>
  %79 = tt.load %63, %78, %cst_0 : tensor<32x!tt.ptr<f16>>
  %80 = arith.sitofp %arg4 : i32 to f32
  %81 = tt.splat %80 : f32 -> tensor<32x32xf32>
  %82 = arith.mulf %76#0, %81 : tensor<32x32xf32>
  %83 = arith.sitofp %arg5 : i32 to f16
  %84 = tt.splat %83 : f16 -> tensor<32xf16>
  %85 = arith.mulf %79, %84 : tensor<32xf16>
  %86 = tt.expand_dims %85 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %87 = arith.extf %86 : tensor<1x32xf16> to tensor<1x32xf32>
  %88 = tt.broadcast %87 : tensor<1x32xf32> -> tensor<32x32xf32>
  %89 = arith.addf %82, %88 : tensor<32x32xf32>
  %90 = arith.truncf %89 : tensor<32x32xf32> to tensor<32x32xf16>
  %91 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %92 = arith.muli %91, %17 : tensor<32x1xi32>
  %93 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %94 = tt.addptr %93, %92 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %95 = tt.broadcast %94 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %96 = tt.addptr %95, %53 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %97 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %98 = arith.cmpi slt, %17, %97 : tensor<32x1xi32>
  %99 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %100 = arith.cmpi slt, %48, %99 : tensor<1x32xi32>
  %101 = tt.broadcast %98 : tensor<32x1xi1> -> tensor<32x32xi1>
  %102 = tt.broadcast %100 : tensor<1x32xi1> -> tensor<32x32xi1>
  %103 = arith.andi %101, %102 : tensor<32x32xi1>
  tt.store %96, %90, %103 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.broadcast'(0x555d5be9b5f0) {
  %82 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.broadcast -> ()' {
Trying to match "{anonymous}::TritonBroadcastPattern"
    ** Insert  : 'tt.broadcast'(0x555d5bed72f0)
    ** Replace : 'tt.broadcast'(0x555d5be9b5f0)
"{anonymous}::TritonBroadcastPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.broadcast'(0x555d5bed72f0) {
      %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %5 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32>
  %7 = arith.addi %5, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %8 = arith.addi %6, %4 : tensor<32xi32>
  %9 = arith.muli %1, %c32_i32 : i32
  %10 = tt.splat %9 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %11 = tt.splat %9 : i32 -> tensor<32xi32>
  %12 = arith.addi %10, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %13 = arith.addi %11, %4 : tensor<32xi32>
  %14 = triton_gpu.convert_layout %7 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %15 = tt.expand_dims %14 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %16 = builtin.unrealized_conversion_cast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.expand_dims %8 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %18 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %20 = arith.muli %16, %18 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = arith.muli %17, %19 : tensor<32x1xi32>
  %22 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %23 = tt.expand_dims %22 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %24 = builtin.unrealized_conversion_cast %23 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %26 = tt.broadcast %20 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = builtin.unrealized_conversion_cast %26 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = tt.broadcast %21 : tensor<32x1xi32> -> tensor<32x32xi32>
  %29 = tt.broadcast %24 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.broadcast %25 : tensor<1x32xi32> -> tensor<32x32xi32>
  %31 = arith.addi %27, %29 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %32 = arith.addi %28, %30 : tensor<32x32xi32>
  %33 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %34 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %35 = tt.addptr %33, %31 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = tt.addptr %34, %32 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %37 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %38 = tt.expand_dims %37 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %39 = builtin.unrealized_conversion_cast %38 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.expand_dims %4 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %41 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %43 = arith.muli %39, %41 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = arith.muli %40, %42 : tensor<32x1xi32>
  %45 = triton_gpu.convert_layout %12 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %46 = tt.expand_dims %45 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %47 = builtin.unrealized_conversion_cast %46 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = tt.expand_dims %13 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %49 = tt.broadcast %43 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %50 = builtin.unrealized_conversion_cast %49 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %51 = tt.broadcast %44 : tensor<32x1xi32> -> tensor<32x32xi32>
  %52 = tt.broadcast %47 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %53 = tt.broadcast %48 : tensor<1x32xi32> -> tensor<32x32xi32>
  %54 = arith.addi %50, %52 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %55 = arith.addi %51, %53 : tensor<32x32xi32>
  %56 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %58 = tt.addptr %56, %54 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = tt.addptr %57, %55 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %60 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %61 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %62 = tt.addptr %60, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %63 = tt.addptr %61, %13 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %64 = arith.addi %arg8, %c31_i32 : i32
  %65 = arith.divsi %64, %c32_i32 : i32
  %66 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %68 = arith.cmpi slt, %16, %66 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = arith.cmpi slt, %17, %67 : tensor<32x1xi32>
  %70 = tt.broadcast %68 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = tt.broadcast %69 : tensor<32x1xi1> -> tensor<32x32xi1>
  %72 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %73 = arith.cmpi slt, %48, %72 : tensor<1x32xi32>
  %74 = tt.broadcast %73 : tensor<1x32xi1> -> tensor<32x32xi1>
  %75 = arith.muli %arg10, %c32_i32 : i32
  %76 = tt.splat %75 : i32 -> tensor<32x32xi32>
  %77:3 = scf.for %arg12 = %c0_i32 to %65 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %36, %arg15 = %59) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %105 = arith.muli %arg12, %c32_i32 : i32
    %106 = arith.subi %arg8, %105 : i32
    %107 = tt.splat %106 : i32 -> tensor<1x32xi32>
    %108 = arith.cmpi slt, %25, %107 : tensor<1x32xi32>
    %109 = tt.broadcast %108 : tensor<1x32xi1> -> tensor<32x32xi1>
    %110 = arith.andi %71, %109 : tensor<32x32xi1>
    %111 = tt.load %arg14, %110, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %112 = tt.splat %106 : i32 -> tensor<32x1xi32>
    %113 = arith.cmpi slt, %40, %112 : tensor<32x1xi32>
    %114 = tt.broadcast %113 : tensor<32x1xi1> -> tensor<32x32xi1>
    %115 = arith.andi %114, %74 : tensor<32x32xi1>
    %116 = tt.load %arg15, %115, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %117 = tt.dot %111, %116, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %118 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %119 = tt.addptr %arg15, %76 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %117, %118, %119 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %78 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %79 = arith.cmpi slt, %13, %78 : tensor<32xi32>
  %80 = tt.load %63, %79, %cst_0 : tensor<32x!tt.ptr<f16>>
  %81 = arith.sitofp %arg4 : i32 to f32
  %82 = tt.splat %81 : f32 -> tensor<32x32xf32>
  %83 = arith.mulf %77#0, %82 : tensor<32x32xf32>
  %84 = arith.sitofp %arg5 : i32 to f16
  %85 = tt.splat %84 : f16 -> tensor<32xf16>
  %86 = arith.mulf %80, %85 : tensor<32xf16>
  %87 = tt.expand_dims %86 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %88 = arith.extf %87 : tensor<1x32xf16> to tensor<1x32xf32>
  %89 = tt.broadcast %88 : tensor<1x32xf32> -> tensor<32x32xf32>
  %90 = arith.addf %83, %89 : tensor<32x32xf32>
  %91 = arith.truncf %90 : tensor<32x32xf32> to tensor<32x32xf16>
  %92 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %93 = arith.muli %92, %17 : tensor<32x1xi32>
  %94 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %95 = tt.addptr %94, %93 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %96 = tt.broadcast %95 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %97 = tt.addptr %96, %53 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %98 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %99 = arith.cmpi slt, %17, %98 : tensor<32x1xi32>
  %100 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %101 = arith.cmpi slt, %48, %100 : tensor<1x32xi32>
  %102 = tt.broadcast %99 : tensor<32x1xi1> -> tensor<32x32xi1>
  %103 = tt.broadcast %101 : tensor<1x32xi1> -> tensor<32x32xi1>
  %104 = arith.andi %102, %103 : tensor<32x32xi1>
  tt.store %97, %91, %104 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.splat'(0x555d5be9b6e0) {
  %84 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.splat -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::triton::SplatOp>"
    ** Insert  : 'tt.splat'(0x555d5beda690)
    ** Replace : 'tt.splat'(0x555d5be9b6e0)
"{anonymous}::GenericOpPattern<mlir::triton::SplatOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.splat'(0x555d5beda690) {
      %84 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %5 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32>
  %7 = arith.addi %5, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %8 = arith.addi %6, %4 : tensor<32xi32>
  %9 = arith.muli %1, %c32_i32 : i32
  %10 = tt.splat %9 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %11 = tt.splat %9 : i32 -> tensor<32xi32>
  %12 = arith.addi %10, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %13 = arith.addi %11, %4 : tensor<32xi32>
  %14 = triton_gpu.convert_layout %7 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %15 = tt.expand_dims %14 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %16 = builtin.unrealized_conversion_cast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.expand_dims %8 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %18 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %20 = arith.muli %16, %18 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = arith.muli %17, %19 : tensor<32x1xi32>
  %22 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %23 = tt.expand_dims %22 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %24 = builtin.unrealized_conversion_cast %23 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %26 = tt.broadcast %20 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = builtin.unrealized_conversion_cast %26 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = tt.broadcast %21 : tensor<32x1xi32> -> tensor<32x32xi32>
  %29 = tt.broadcast %24 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.broadcast %25 : tensor<1x32xi32> -> tensor<32x32xi32>
  %31 = arith.addi %27, %29 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %32 = arith.addi %28, %30 : tensor<32x32xi32>
  %33 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %34 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %35 = tt.addptr %33, %31 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = tt.addptr %34, %32 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %37 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %38 = tt.expand_dims %37 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %39 = builtin.unrealized_conversion_cast %38 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.expand_dims %4 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %41 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %43 = arith.muli %39, %41 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = arith.muli %40, %42 : tensor<32x1xi32>
  %45 = triton_gpu.convert_layout %12 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %46 = tt.expand_dims %45 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %47 = builtin.unrealized_conversion_cast %46 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = tt.expand_dims %13 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %49 = tt.broadcast %43 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %50 = builtin.unrealized_conversion_cast %49 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %51 = tt.broadcast %44 : tensor<32x1xi32> -> tensor<32x32xi32>
  %52 = tt.broadcast %47 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %53 = tt.broadcast %48 : tensor<1x32xi32> -> tensor<32x32xi32>
  %54 = arith.addi %50, %52 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %55 = arith.addi %51, %53 : tensor<32x32xi32>
  %56 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %58 = tt.addptr %56, %54 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = tt.addptr %57, %55 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %60 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %61 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %62 = tt.addptr %60, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %63 = tt.addptr %61, %13 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %64 = arith.addi %arg8, %c31_i32 : i32
  %65 = arith.divsi %64, %c32_i32 : i32
  %66 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %68 = arith.cmpi slt, %16, %66 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = arith.cmpi slt, %17, %67 : tensor<32x1xi32>
  %70 = tt.broadcast %68 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = tt.broadcast %69 : tensor<32x1xi1> -> tensor<32x32xi1>
  %72 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %73 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %74 = arith.cmpi slt, %48, %73 : tensor<1x32xi32>
  %75 = tt.broadcast %74 : tensor<1x32xi1> -> tensor<32x32xi1>
  %76 = arith.muli %arg10, %c32_i32 : i32
  %77 = tt.splat %76 : i32 -> tensor<32x32xi32>
  %78:3 = scf.for %arg12 = %c0_i32 to %65 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %36, %arg15 = %59) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %106 = arith.muli %arg12, %c32_i32 : i32
    %107 = arith.subi %arg8, %106 : i32
    %108 = tt.splat %107 : i32 -> tensor<1x32xi32>
    %109 = arith.cmpi slt, %25, %108 : tensor<1x32xi32>
    %110 = tt.broadcast %109 : tensor<1x32xi1> -> tensor<32x32xi1>
    %111 = arith.andi %71, %110 : tensor<32x32xi1>
    %112 = tt.load %arg14, %111, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %113 = tt.splat %107 : i32 -> tensor<32x1xi32>
    %114 = arith.cmpi slt, %40, %113 : tensor<32x1xi32>
    %115 = tt.broadcast %114 : tensor<32x1xi1> -> tensor<32x32xi1>
    %116 = arith.andi %115, %75 : tensor<32x32xi1>
    %117 = tt.load %arg15, %116, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %118 = tt.dot %112, %117, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %119 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %120 = tt.addptr %arg15, %77 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %118, %119, %120 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %79 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %80 = arith.cmpi slt, %13, %79 : tensor<32xi32>
  %81 = tt.load %63, %80, %cst_0 : tensor<32x!tt.ptr<f16>>
  %82 = arith.sitofp %arg4 : i32 to f32
  %83 = tt.splat %82 : f32 -> tensor<32x32xf32>
  %84 = arith.mulf %78#0, %83 : tensor<32x32xf32>
  %85 = arith.sitofp %arg5 : i32 to f16
  %86 = tt.splat %85 : f16 -> tensor<32xf16>
  %87 = arith.mulf %81, %86 : tensor<32xf16>
  %88 = tt.expand_dims %87 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %89 = arith.extf %88 : tensor<1x32xf16> to tensor<1x32xf32>
  %90 = tt.broadcast %89 : tensor<1x32xf32> -> tensor<32x32xf32>
  %91 = arith.addf %84, %90 : tensor<32x32xf32>
  %92 = arith.truncf %91 : tensor<32x32xf32> to tensor<32x32xf16>
  %93 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %94 = arith.muli %93, %17 : tensor<32x1xi32>
  %95 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %96 = tt.addptr %95, %94 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %97 = tt.broadcast %96 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %98 = tt.addptr %97, %53 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %99 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %100 = arith.cmpi slt, %17, %99 : tensor<32x1xi32>
  %101 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %102 = arith.cmpi slt, %48, %101 : tensor<1x32xi32>
  %103 = tt.broadcast %100 : tensor<32x1xi1> -> tensor<32x32xi1>
  %104 = tt.broadcast %102 : tensor<1x32xi1> -> tensor<32x32xi1>
  %105 = arith.andi %103, %104 : tensor<32x32xi1>
  tt.store %98, %92, %105 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.cmpi'(0x555d5be9bc70) {
  %86 = "arith.cmpi"(%60, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'arith.cmpi -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::arith::CmpIOp>"
    ** Insert  : 'arith.cmpi'(0x555d5bec9bd0)
    ** Replace : 'arith.cmpi'(0x555d5be9bc70)
"{anonymous}::GenericOpPattern<mlir::arith::CmpIOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'arith.cmpi'(0x555d5bec9bd0) {
      %86 = "arith.cmpi"(%59, %84) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %5 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32>
  %7 = arith.addi %5, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %8 = arith.addi %6, %4 : tensor<32xi32>
  %9 = arith.muli %1, %c32_i32 : i32
  %10 = tt.splat %9 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %11 = tt.splat %9 : i32 -> tensor<32xi32>
  %12 = arith.addi %10, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %13 = arith.addi %11, %4 : tensor<32xi32>
  %14 = triton_gpu.convert_layout %7 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %15 = tt.expand_dims %14 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %16 = builtin.unrealized_conversion_cast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.expand_dims %8 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %18 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %20 = arith.muli %16, %18 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = arith.muli %17, %19 : tensor<32x1xi32>
  %22 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %23 = tt.expand_dims %22 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %24 = builtin.unrealized_conversion_cast %23 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %26 = tt.broadcast %20 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = builtin.unrealized_conversion_cast %26 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = tt.broadcast %21 : tensor<32x1xi32> -> tensor<32x32xi32>
  %29 = tt.broadcast %24 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.broadcast %25 : tensor<1x32xi32> -> tensor<32x32xi32>
  %31 = arith.addi %27, %29 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %32 = arith.addi %28, %30 : tensor<32x32xi32>
  %33 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %34 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %35 = tt.addptr %33, %31 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = tt.addptr %34, %32 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %37 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %38 = tt.expand_dims %37 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %39 = builtin.unrealized_conversion_cast %38 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.expand_dims %4 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %41 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %43 = arith.muli %39, %41 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = arith.muli %40, %42 : tensor<32x1xi32>
  %45 = triton_gpu.convert_layout %12 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %46 = tt.expand_dims %45 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %47 = builtin.unrealized_conversion_cast %46 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = tt.expand_dims %13 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %49 = tt.broadcast %43 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %50 = builtin.unrealized_conversion_cast %49 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %51 = tt.broadcast %44 : tensor<32x1xi32> -> tensor<32x32xi32>
  %52 = tt.broadcast %47 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %53 = tt.broadcast %48 : tensor<1x32xi32> -> tensor<32x32xi32>
  %54 = arith.addi %50, %52 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %55 = arith.addi %51, %53 : tensor<32x32xi32>
  %56 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %58 = tt.addptr %56, %54 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = tt.addptr %57, %55 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %60 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %61 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %62 = tt.addptr %60, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %63 = tt.addptr %61, %13 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %64 = arith.addi %arg8, %c31_i32 : i32
  %65 = arith.divsi %64, %c32_i32 : i32
  %66 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %68 = arith.cmpi slt, %16, %66 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = arith.cmpi slt, %17, %67 : tensor<32x1xi32>
  %70 = tt.broadcast %68 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = tt.broadcast %69 : tensor<32x1xi1> -> tensor<32x32xi1>
  %72 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %73 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %74 = arith.cmpi slt, %47, %72 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = arith.cmpi slt, %48, %73 : tensor<1x32xi32>
  %76 = tt.broadcast %75 : tensor<1x32xi1> -> tensor<32x32xi1>
  %77 = arith.muli %arg10, %c32_i32 : i32
  %78 = tt.splat %77 : i32 -> tensor<32x32xi32>
  %79:3 = scf.for %arg12 = %c0_i32 to %65 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %36, %arg15 = %59) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %107 = arith.muli %arg12, %c32_i32 : i32
    %108 = arith.subi %arg8, %107 : i32
    %109 = tt.splat %108 : i32 -> tensor<1x32xi32>
    %110 = arith.cmpi slt, %25, %109 : tensor<1x32xi32>
    %111 = tt.broadcast %110 : tensor<1x32xi1> -> tensor<32x32xi1>
    %112 = arith.andi %71, %111 : tensor<32x32xi1>
    %113 = tt.load %arg14, %112, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %114 = tt.splat %108 : i32 -> tensor<32x1xi32>
    %115 = arith.cmpi slt, %40, %114 : tensor<32x1xi32>
    %116 = tt.broadcast %115 : tensor<32x1xi1> -> tensor<32x32xi1>
    %117 = arith.andi %116, %76 : tensor<32x32xi1>
    %118 = tt.load %arg15, %117, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %119 = tt.dot %113, %118, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %120 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %121 = tt.addptr %arg15, %78 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %119, %120, %121 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %80 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %81 = arith.cmpi slt, %13, %80 : tensor<32xi32>
  %82 = tt.load %63, %81, %cst_0 : tensor<32x!tt.ptr<f16>>
  %83 = arith.sitofp %arg4 : i32 to f32
  %84 = tt.splat %83 : f32 -> tensor<32x32xf32>
  %85 = arith.mulf %79#0, %84 : tensor<32x32xf32>
  %86 = arith.sitofp %arg5 : i32 to f16
  %87 = tt.splat %86 : f16 -> tensor<32xf16>
  %88 = arith.mulf %82, %87 : tensor<32xf16>
  %89 = tt.expand_dims %88 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %90 = arith.extf %89 : tensor<1x32xf16> to tensor<1x32xf32>
  %91 = tt.broadcast %90 : tensor<1x32xf32> -> tensor<32x32xf32>
  %92 = arith.addf %85, %91 : tensor<32x32xf32>
  %93 = arith.truncf %92 : tensor<32x32xf32> to tensor<32x32xf16>
  %94 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %95 = arith.muli %94, %17 : tensor<32x1xi32>
  %96 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %97 = tt.addptr %96, %95 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %98 = tt.broadcast %97 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %99 = tt.addptr %98, %53 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %100 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %101 = arith.cmpi slt, %17, %100 : tensor<32x1xi32>
  %102 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %103 = arith.cmpi slt, %48, %102 : tensor<1x32xi32>
  %104 = tt.broadcast %101 : tensor<32x1xi1> -> tensor<32x32xi1>
  %105 = tt.broadcast %103 : tensor<1x32xi1> -> tensor<32x32xi1>
  %106 = arith.andi %104, %105 : tensor<32x32xi1>
  tt.store %99, %93, %106 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.broadcast'(0x555d5be9bd60) {
  %88 = "tt.broadcast"(%87) : (tensor<1x32xi1>) -> tensor<32x32xi1>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.broadcast -> ()' {
Trying to match "{anonymous}::TritonBroadcastPattern"
    ** Insert  : 'tt.broadcast'(0x555d5bedadf0)
    ** Replace : 'tt.broadcast'(0x555d5be9bd60)
"{anonymous}::TritonBroadcastPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.broadcast'(0x555d5bedadf0) {
      %88 = "tt.broadcast"(%86) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %5 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32>
  %7 = arith.addi %5, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %8 = arith.addi %6, %4 : tensor<32xi32>
  %9 = arith.muli %1, %c32_i32 : i32
  %10 = tt.splat %9 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %11 = tt.splat %9 : i32 -> tensor<32xi32>
  %12 = arith.addi %10, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %13 = arith.addi %11, %4 : tensor<32xi32>
  %14 = triton_gpu.convert_layout %7 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %15 = tt.expand_dims %14 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %16 = builtin.unrealized_conversion_cast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.expand_dims %8 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %18 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %20 = arith.muli %16, %18 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = arith.muli %17, %19 : tensor<32x1xi32>
  %22 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %23 = tt.expand_dims %22 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %24 = builtin.unrealized_conversion_cast %23 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %26 = tt.broadcast %20 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = builtin.unrealized_conversion_cast %26 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = tt.broadcast %21 : tensor<32x1xi32> -> tensor<32x32xi32>
  %29 = tt.broadcast %24 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.broadcast %25 : tensor<1x32xi32> -> tensor<32x32xi32>
  %31 = arith.addi %27, %29 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %32 = arith.addi %28, %30 : tensor<32x32xi32>
  %33 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %34 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %35 = tt.addptr %33, %31 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = tt.addptr %34, %32 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %37 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %38 = tt.expand_dims %37 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %39 = builtin.unrealized_conversion_cast %38 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.expand_dims %4 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %41 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %43 = arith.muli %39, %41 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = arith.muli %40, %42 : tensor<32x1xi32>
  %45 = triton_gpu.convert_layout %12 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %46 = tt.expand_dims %45 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %47 = builtin.unrealized_conversion_cast %46 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = tt.expand_dims %13 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %49 = tt.broadcast %43 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %50 = builtin.unrealized_conversion_cast %49 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %51 = tt.broadcast %44 : tensor<32x1xi32> -> tensor<32x32xi32>
  %52 = tt.broadcast %47 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %53 = tt.broadcast %48 : tensor<1x32xi32> -> tensor<32x32xi32>
  %54 = arith.addi %50, %52 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %55 = arith.addi %51, %53 : tensor<32x32xi32>
  %56 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %58 = tt.addptr %56, %54 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = tt.addptr %57, %55 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %60 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %61 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %62 = tt.addptr %60, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %63 = tt.addptr %61, %13 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %64 = arith.addi %arg8, %c31_i32 : i32
  %65 = arith.divsi %64, %c32_i32 : i32
  %66 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %68 = arith.cmpi slt, %16, %66 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = arith.cmpi slt, %17, %67 : tensor<32x1xi32>
  %70 = tt.broadcast %68 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = tt.broadcast %69 : tensor<32x1xi1> -> tensor<32x32xi1>
  %72 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %73 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %74 = arith.cmpi slt, %47, %72 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = arith.cmpi slt, %48, %73 : tensor<1x32xi32>
  %76 = tt.broadcast %74 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %77 = tt.broadcast %75 : tensor<1x32xi1> -> tensor<32x32xi1>
  %78 = arith.muli %arg10, %c32_i32 : i32
  %79 = tt.splat %78 : i32 -> tensor<32x32xi32>
  %80:3 = scf.for %arg12 = %c0_i32 to %65 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %36, %arg15 = %59) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %108 = arith.muli %arg12, %c32_i32 : i32
    %109 = arith.subi %arg8, %108 : i32
    %110 = tt.splat %109 : i32 -> tensor<1x32xi32>
    %111 = arith.cmpi slt, %25, %110 : tensor<1x32xi32>
    %112 = tt.broadcast %111 : tensor<1x32xi1> -> tensor<32x32xi1>
    %113 = arith.andi %71, %112 : tensor<32x32xi1>
    %114 = tt.load %arg14, %113, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %115 = tt.splat %109 : i32 -> tensor<32x1xi32>
    %116 = arith.cmpi slt, %40, %115 : tensor<32x1xi32>
    %117 = tt.broadcast %116 : tensor<32x1xi1> -> tensor<32x32xi1>
    %118 = arith.andi %117, %77 : tensor<32x32xi1>
    %119 = tt.load %arg15, %118, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %120 = tt.dot %114, %119, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %121 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %122 = tt.addptr %arg15, %79 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %120, %121, %122 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %81 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %82 = arith.cmpi slt, %13, %81 : tensor<32xi32>
  %83 = tt.load %63, %82, %cst_0 : tensor<32x!tt.ptr<f16>>
  %84 = arith.sitofp %arg4 : i32 to f32
  %85 = tt.splat %84 : f32 -> tensor<32x32xf32>
  %86 = arith.mulf %80#0, %85 : tensor<32x32xf32>
  %87 = arith.sitofp %arg5 : i32 to f16
  %88 = tt.splat %87 : f16 -> tensor<32xf16>
  %89 = arith.mulf %83, %88 : tensor<32xf16>
  %90 = tt.expand_dims %89 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %91 = arith.extf %90 : tensor<1x32xf16> to tensor<1x32xf32>
  %92 = tt.broadcast %91 : tensor<1x32xf32> -> tensor<32x32xf32>
  %93 = arith.addf %86, %92 : tensor<32x32xf32>
  %94 = arith.truncf %93 : tensor<32x32xf32> to tensor<32x32xf16>
  %95 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %96 = arith.muli %95, %17 : tensor<32x1xi32>
  %97 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %98 = tt.addptr %97, %96 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %99 = tt.broadcast %98 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %100 = tt.addptr %99, %53 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %101 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %102 = arith.cmpi slt, %17, %101 : tensor<32x1xi32>
  %103 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %104 = arith.cmpi slt, %48, %103 : tensor<1x32xi32>
  %105 = tt.broadcast %102 : tensor<32x1xi1> -> tensor<32x32xi1>
  %106 = tt.broadcast %104 : tensor<1x32xi1> -> tensor<32x32xi1>
  %107 = arith.andi %105, %106 : tensor<32x32xi1>
  tt.store %100, %94, %107 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.muli'(0x555d5be9be50) {
  %90 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.splat'(0x555d5be9bf60) {
  %91 = "tt.splat"(%90) : (i32) -> tensor<32x32xi32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.splat -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::triton::SplatOp>"
    ** Insert  : 'tt.splat'(0x555d5bedaf10)
    ** Replace : 'tt.splat'(0x555d5be9bf60)
"{anonymous}::GenericOpPattern<mlir::triton::SplatOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.splat'(0x555d5bedaf10) {
      %91 = "tt.splat"(%90) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
  %c31_i32 = arith.constant 31 : i32
  %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %cst_0 = arith.constant dense<0.000000e+00> : tensor<32xf16>
  %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf16>
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %cst_3 = arith.constant dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_4 = arith.constant dense<32> : tensor<32x32xi32>
  %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %cst_6 = arith.constant dense<0.000000e+00> : tensor<32x32xf32>
  %c32_i32 = arith.constant 32 : i32
  %0 = tt.get_program_id x : i32
  %1 = tt.get_program_id y : i32
  %2 = arith.muli %0, %c32_i32 : i32
  %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>
  %5 = tt.splat %2 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %6 = tt.splat %2 : i32 -> tensor<32xi32>
  %7 = arith.addi %5, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %8 = arith.addi %6, %4 : tensor<32xi32>
  %9 = arith.muli %1, %c32_i32 : i32
  %10 = tt.splat %9 : i32 -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %11 = tt.splat %9 : i32 -> tensor<32xi32>
  %12 = arith.addi %10, %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %13 = arith.addi %11, %4 : tensor<32xi32>
  %14 = triton_gpu.convert_layout %7 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %15 = tt.expand_dims %14 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %16 = builtin.unrealized_conversion_cast %15 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %17 = tt.expand_dims %8 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %18 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %19 = tt.splat %arg9 : i32 -> tensor<32x1xi32>
  %20 = arith.muli %16, %18 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %21 = arith.muli %17, %19 : tensor<32x1xi32>
  %22 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %23 = tt.expand_dims %22 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %24 = builtin.unrealized_conversion_cast %23 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %25 = tt.expand_dims %4 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %26 = tt.broadcast %20 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %27 = builtin.unrealized_conversion_cast %26 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %28 = tt.broadcast %21 : tensor<32x1xi32> -> tensor<32x32xi32>
  %29 = tt.broadcast %24 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %30 = tt.broadcast %25 : tensor<1x32xi32> -> tensor<32x32xi32>
  %31 = arith.addi %27, %29 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %32 = arith.addi %28, %30 : tensor<32x32xi32>
  %33 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %34 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %35 = tt.addptr %33, %31 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %36 = tt.addptr %34, %32 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %37 = triton_gpu.convert_layout %3 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %38 = tt.expand_dims %37 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %39 = builtin.unrealized_conversion_cast %38 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = tt.expand_dims %4 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32>
  %41 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = tt.splat %arg10 : i32 -> tensor<32x1xi32>
  %43 = arith.muli %39, %41 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = arith.muli %40, %42 : tensor<32x1xi32>
  %45 = triton_gpu.convert_layout %12 : tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %46 = tt.expand_dims %45 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>> -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %47 = builtin.unrealized_conversion_cast %46 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>> to tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = tt.expand_dims %13 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32>
  %49 = tt.broadcast %43 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %50 = builtin.unrealized_conversion_cast %49 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> to tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %51 = tt.broadcast %44 : tensor<32x1xi32> -> tensor<32x32xi32>
  %52 = tt.broadcast %47 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %53 = tt.broadcast %48 : tensor<1x32xi32> -> tensor<32x32xi32>
  %54 = arith.addi %50, %52 : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %55 = arith.addi %51, %53 : tensor<32x32xi32>
  %56 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %57 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>>
  %58 = tt.addptr %56, %54 : tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %59 = tt.addptr %57, %55 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %60 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %61 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>>
  %62 = tt.addptr %60, %12 : tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %63 = tt.addptr %61, %13 : tensor<32x!tt.ptr<f16>>, tensor<32xi32>
  %64 = arith.addi %arg8, %c31_i32 : i32
  %65 = arith.divsi %64, %c32_i32 : i32
  %66 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %68 = arith.cmpi slt, %16, %66 : tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = arith.cmpi slt, %17, %67 : tensor<32x1xi32>
  %70 = tt.broadcast %68 : tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = tt.broadcast %69 : tensor<32x1xi1> -> tensor<32x32xi1>
  %72 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %73 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %74 = arith.cmpi slt, %47, %72 : tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %75 = arith.cmpi slt, %48, %73 : tensor<1x32xi32>
  %76 = tt.broadcast %74 : tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %77 = tt.broadcast %75 : tensor<1x32xi1> -> tensor<32x32xi1>
  %78 = arith.muli %arg10, %c32_i32 : i32
  %79 = tt.splat %78 : i32 -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %80 = tt.splat %78 : i32 -> tensor<32x32xi32>
  %81:3 = scf.for %arg12 = %c0_i32 to %65 step %c1_i32 iter_args(%arg13 = %cst_6, %arg14 = %36, %arg15 = %59) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)  : i32 {
    %109 = arith.muli %arg12, %c32_i32 : i32
    %110 = arith.subi %arg8, %109 : i32
    %111 = tt.splat %110 : i32 -> tensor<1x32xi32>
    %112 = arith.cmpi slt, %25, %111 : tensor<1x32xi32>
    %113 = tt.broadcast %112 : tensor<1x32xi1> -> tensor<32x32xi1>
    %114 = arith.andi %71, %113 : tensor<32x32xi1>
    %115 = tt.load %arg14, %114, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %116 = tt.splat %110 : i32 -> tensor<32x1xi32>
    %117 = arith.cmpi slt, %40, %116 : tensor<32x1xi32>
    %118 = tt.broadcast %117 : tensor<32x1xi1> -> tensor<32x32xi1>
    %119 = arith.andi %118, %77 : tensor<32x32xi1>
    %120 = tt.load %arg15, %119, %cst_2 : tensor<32x32x!tt.ptr<f16>>
    %121 = tt.dot %115, %120, %arg13 : tensor<32x32xf16> * tensor<32x32xf16> -> tensor<32x32xf32>
    %122 = tt.addptr %arg14, %cst_4 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    %123 = tt.addptr %arg15, %80 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
    scf.yield %121, %122, %123 : tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>
  }
  %82 = tt.splat %arg7 : i32 -> tensor<32xi32>
  %83 = arith.cmpi slt, %13, %82 : tensor<32xi32>
  %84 = tt.load %63, %83, %cst_0 : tensor<32x!tt.ptr<f16>>
  %85 = arith.sitofp %arg4 : i32 to f32
  %86 = tt.splat %85 : f32 -> tensor<32x32xf32>
  %87 = arith.mulf %81#0, %86 : tensor<32x32xf32>
  %88 = arith.sitofp %arg5 : i32 to f16
  %89 = tt.splat %88 : f16 -> tensor<32xf16>
  %90 = arith.mulf %84, %89 : tensor<32xf16>
  %91 = tt.expand_dims %90 {axis = 0 : i32} : tensor<32xf16> -> tensor<1x32xf16>
  %92 = arith.extf %91 : tensor<1x32xf16> to tensor<1x32xf32>
  %93 = tt.broadcast %92 : tensor<1x32xf32> -> tensor<32x32xf32>
  %94 = arith.addf %87, %93 : tensor<32x32xf32>
  %95 = arith.truncf %94 : tensor<32x32xf32> to tensor<32x32xf16>
  %96 = tt.splat %arg11 : i32 -> tensor<32x1xi32>
  %97 = arith.muli %96, %17 : tensor<32x1xi32>
  %98 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>>
  %99 = tt.addptr %98, %97 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>
  %100 = tt.broadcast %99 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>>
  %101 = tt.addptr %100, %53 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>
  %102 = tt.splat %arg6 : i32 -> tensor<32x1xi32>
  %103 = arith.cmpi slt, %17, %102 : tensor<32x1xi32>
  %104 = tt.splat %arg7 : i32 -> tensor<1x32xi32>
  %105 = arith.cmpi slt, %48, %104 : tensor<1x32xi32>
  %106 = tt.broadcast %103 : tensor<32x1xi1> -> tensor<32x32xi1>
  %107 = tt.broadcast %105 : tensor<1x32xi1> -> tensor<32x32xi1>
  %108 = arith.andi %106, %107 : tensor<32x32xi1>
  tt.store %101, %95, %108 : tensor<32x32x!tt.ptr<f16>>
  tt.return
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'scf.for'(0x555d5be9dda0) {
  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'scf.for -> ()' {
Trying to match "{anonymous}::SCFForPattern"
    ** Insert  : 'scf.for'(0x555d5bedafc0)
    ** Insert Block into : 'scf.for'(0x555d5bedafc0)
    ** Insert Block into : 'scf.for'(0x555d5bedafc0)
    ** Replace : 'scf.for'(0x555d5be9dda0)
"{anonymous}::SCFForPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'scf.for'(0x555d5bedafc0) {
    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.for' op 0-th region iter_arg and 0-th yielded value have different type: 'tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>' != 'tensor<32x32xf32>'
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %84 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %86 = "arith.cmpi"(%59, %84) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %87 = "arith.cmpi"(%60, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %88 = "tt.broadcast"(%86) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %90 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %91 = "tt.splat"(%90) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %92 = "tt.splat"(%90) : (i32) -> tensor<32x32xi32>
  %93:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %122 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %123 = "builtin.unrealized_conversion_cast"(%122) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %124 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %125 = "builtin.unrealized_conversion_cast"(%124) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %126 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %127 = "builtin.unrealized_conversion_cast"(%126) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %128 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %129 = "arith.subi"(%arg8, %128) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %130 = "tt.splat"(%129) : (i32) -> tensor<1x32xi32>
    %131 = "arith.cmpi"(%37, %130) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %132 = "tt.broadcast"(%131) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %133 = "arith.andi"(%83, %132) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %134 = "tt.load"(<<UNKNOWN SSA VALUE>>, %133, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %135 = "tt.splat"(%129) : (i32) -> tensor<32x1xi32>
    %136 = "arith.cmpi"(%52, %135) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %137 = "tt.broadcast"(%136) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %138 = "arith.andi"(%137, %89) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %139 = "tt.load"(<<UNKNOWN SSA VALUE>>, %138, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %140 = "tt.dot"(%134, %139, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %141 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %142 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %92) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%140, %141, %142) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %94:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %95 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %96 = "arith.cmpi"(%25, %95) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %97 = "tt.load"(%75, %96, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %98 = "arith.sitofp"(%arg4) : (i32) -> f32
  %99 = "tt.splat"(%98) : (f32) -> tensor<32x32xf32>
  %100 = "arith.mulf"(%94#0, %99) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %101 = "arith.sitofp"(%arg5) : (i32) -> f16
  %102 = "tt.splat"(%101) : (f16) -> tensor<32xf16>
  %103 = "arith.mulf"(%97, %102) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %104 = "tt.expand_dims"(%103) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %105 = "arith.extf"(%104) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %106 = "tt.broadcast"(%105) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %107 = "arith.addf"(%100, %106) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %108 = "arith.truncf"(%107) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %109 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %110 = "arith.muli"(%109, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %111 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %112 = "tt.addptr"(%111, %110) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %113 = "tt.broadcast"(%112) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %114 = "tt.addptr"(%113, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %115 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %116 = "arith.cmpi"(%29, %115) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %117 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %118 = "arith.cmpi"(%60, %117) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %119 = "tt.broadcast"(%116) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %120 = "tt.broadcast"(%118) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %121 = "arith.andi"(%119, %120) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%114, %108, %121) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.muli'(0x555d5be7a090) {
  %128 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.subi'(0x555d5be7a1a0) {
  %129 = "arith.subi"(%arg8, %128) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.splat'(0x555d5be7a2b0) {
  %130 = "tt.splat"(%129) : (i32) -> tensor<1x32xi32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.splat -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::triton::SplatOp>"
    ** Insert  : 'tt.splat'(0x555d5bed5e20)
    ** Replace : 'tt.splat'(0x555d5be7a2b0)
"{anonymous}::GenericOpPattern<mlir::triton::SplatOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.splat'(0x555d5bed5e20) {
      %130 = "tt.splat"(%129) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.for' op 0-th region iter_arg and 0-th yielded value have different type: 'tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>' != 'tensor<32x32xf32>'
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %84 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %86 = "arith.cmpi"(%59, %84) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %87 = "arith.cmpi"(%60, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %88 = "tt.broadcast"(%86) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %90 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %91 = "tt.splat"(%90) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %92 = "tt.splat"(%90) : (i32) -> tensor<32x32xi32>
  %93:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %122 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %123 = "builtin.unrealized_conversion_cast"(%122) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %124 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %125 = "builtin.unrealized_conversion_cast"(%124) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %126 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %127 = "builtin.unrealized_conversion_cast"(%126) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %128 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %129 = "arith.subi"(%arg8, %128) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %130 = "tt.splat"(%129) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %131 = "tt.splat"(%129) : (i32) -> tensor<1x32xi32>
    %132 = "arith.cmpi"(%37, %131) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %133 = "tt.broadcast"(%132) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %134 = "arith.andi"(%83, %133) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %135 = "tt.load"(<<UNKNOWN SSA VALUE>>, %134, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %136 = "tt.splat"(%129) : (i32) -> tensor<32x1xi32>
    %137 = "arith.cmpi"(%52, %136) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %138 = "tt.broadcast"(%137) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %139 = "arith.andi"(%138, %89) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %140 = "tt.load"(<<UNKNOWN SSA VALUE>>, %139, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %141 = "tt.dot"(%135, %140, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %142 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %143 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %92) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%141, %142, %143) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %94:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %95 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %96 = "arith.cmpi"(%25, %95) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %97 = "tt.load"(%75, %96, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %98 = "arith.sitofp"(%arg4) : (i32) -> f32
  %99 = "tt.splat"(%98) : (f32) -> tensor<32x32xf32>
  %100 = "arith.mulf"(%94#0, %99) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %101 = "arith.sitofp"(%arg5) : (i32) -> f16
  %102 = "tt.splat"(%101) : (f16) -> tensor<32xf16>
  %103 = "arith.mulf"(%97, %102) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %104 = "tt.expand_dims"(%103) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %105 = "arith.extf"(%104) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %106 = "tt.broadcast"(%105) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %107 = "arith.addf"(%100, %106) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %108 = "arith.truncf"(%107) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %109 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %110 = "arith.muli"(%109, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %111 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %112 = "tt.addptr"(%111, %110) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %113 = "tt.broadcast"(%112) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %114 = "tt.addptr"(%113, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %115 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %116 = "arith.cmpi"(%29, %115) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %117 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %118 = "arith.cmpi"(%60, %117) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %119 = "tt.broadcast"(%116) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %120 = "tt.broadcast"(%118) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %121 = "arith.andi"(%119, %120) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%114, %108, %121) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.cmpi'(0x555d5be7a3c0) {
  %132 = "arith.cmpi"(%37, %131) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'arith.cmpi -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::arith::CmpIOp>"
    ** Insert  : 'arith.cmpi'(0x555d5bed5460)
    ** Replace : 'arith.cmpi'(0x555d5be7a3c0)
"{anonymous}::GenericOpPattern<mlir::arith::CmpIOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'arith.cmpi'(0x555d5bed5460) {
      %132 = "arith.cmpi"(%36, %130) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.for' op 0-th region iter_arg and 0-th yielded value have different type: 'tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>' != 'tensor<32x32xf32>'
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %84 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %86 = "arith.cmpi"(%59, %84) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %87 = "arith.cmpi"(%60, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %88 = "tt.broadcast"(%86) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %90 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %91 = "tt.splat"(%90) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %92 = "tt.splat"(%90) : (i32) -> tensor<32x32xi32>
  %93:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %122 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %123 = "builtin.unrealized_conversion_cast"(%122) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %124 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %125 = "builtin.unrealized_conversion_cast"(%124) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %126 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %127 = "builtin.unrealized_conversion_cast"(%126) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %128 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %129 = "arith.subi"(%arg8, %128) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %130 = "tt.splat"(%129) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %131 = "tt.splat"(%129) : (i32) -> tensor<1x32xi32>
    %132 = "arith.cmpi"(%36, %130) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %133 = "arith.cmpi"(%37, %131) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %134 = "tt.broadcast"(%133) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %135 = "arith.andi"(%83, %134) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %136 = "tt.load"(<<UNKNOWN SSA VALUE>>, %135, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %137 = "tt.splat"(%129) : (i32) -> tensor<32x1xi32>
    %138 = "arith.cmpi"(%52, %137) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %139 = "tt.broadcast"(%138) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %140 = "arith.andi"(%139, %89) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %141 = "tt.load"(<<UNKNOWN SSA VALUE>>, %140, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %142 = "tt.dot"(%136, %141, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %143 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %144 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %92) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%142, %143, %144) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %94:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %95 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %96 = "arith.cmpi"(%25, %95) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %97 = "tt.load"(%75, %96, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %98 = "arith.sitofp"(%arg4) : (i32) -> f32
  %99 = "tt.splat"(%98) : (f32) -> tensor<32x32xf32>
  %100 = "arith.mulf"(%94#0, %99) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %101 = "arith.sitofp"(%arg5) : (i32) -> f16
  %102 = "tt.splat"(%101) : (f16) -> tensor<32xf16>
  %103 = "arith.mulf"(%97, %102) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %104 = "tt.expand_dims"(%103) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %105 = "arith.extf"(%104) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %106 = "tt.broadcast"(%105) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %107 = "arith.addf"(%100, %106) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %108 = "arith.truncf"(%107) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %109 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %110 = "arith.muli"(%109, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %111 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %112 = "tt.addptr"(%111, %110) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %113 = "tt.broadcast"(%112) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %114 = "tt.addptr"(%113, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %115 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %116 = "arith.cmpi"(%29, %115) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %117 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %118 = "arith.cmpi"(%60, %117) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %119 = "tt.broadcast"(%116) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %120 = "tt.broadcast"(%118) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %121 = "arith.andi"(%119, %120) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%114, %108, %121) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.broadcast'(0x555d5be7a4b0) {
  %134 = "tt.broadcast"(%133) : (tensor<1x32xi1>) -> tensor<32x32xi1>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.broadcast -> ()' {
Trying to match "{anonymous}::TritonBroadcastPattern"
    ** Insert  : 'tt.broadcast'(0x555d5bed5d90)
    ** Replace : 'tt.broadcast'(0x555d5be7a4b0)
"{anonymous}::TritonBroadcastPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.broadcast'(0x555d5bed5d90) {
      %134 = "tt.broadcast"(%132) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.for' op 0-th region iter_arg and 0-th yielded value have different type: 'tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>' != 'tensor<32x32xf32>'
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %84 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %86 = "arith.cmpi"(%59, %84) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %87 = "arith.cmpi"(%60, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %88 = "tt.broadcast"(%86) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %90 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %91 = "tt.splat"(%90) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %92 = "tt.splat"(%90) : (i32) -> tensor<32x32xi32>
  %93:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %122 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %123 = "builtin.unrealized_conversion_cast"(%122) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %124 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %125 = "builtin.unrealized_conversion_cast"(%124) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %126 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %127 = "builtin.unrealized_conversion_cast"(%126) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %128 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %129 = "arith.subi"(%arg8, %128) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %130 = "tt.splat"(%129) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %131 = "tt.splat"(%129) : (i32) -> tensor<1x32xi32>
    %132 = "arith.cmpi"(%36, %130) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %133 = "arith.cmpi"(%37, %131) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %134 = "tt.broadcast"(%132) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %135 = "tt.broadcast"(%133) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %136 = "arith.andi"(%83, %135) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %137 = "tt.load"(<<UNKNOWN SSA VALUE>>, %136, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %138 = "tt.splat"(%129) : (i32) -> tensor<32x1xi32>
    %139 = "arith.cmpi"(%52, %138) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %140 = "tt.broadcast"(%139) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %141 = "arith.andi"(%140, %89) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %142 = "tt.load"(<<UNKNOWN SSA VALUE>>, %141, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %143 = "tt.dot"(%137, %142, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %144 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %145 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %92) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%143, %144, %145) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %94:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %95 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %96 = "arith.cmpi"(%25, %95) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %97 = "tt.load"(%75, %96, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %98 = "arith.sitofp"(%arg4) : (i32) -> f32
  %99 = "tt.splat"(%98) : (f32) -> tensor<32x32xf32>
  %100 = "arith.mulf"(%94#0, %99) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %101 = "arith.sitofp"(%arg5) : (i32) -> f16
  %102 = "tt.splat"(%101) : (f16) -> tensor<32xf16>
  %103 = "arith.mulf"(%97, %102) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %104 = "tt.expand_dims"(%103) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %105 = "arith.extf"(%104) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %106 = "tt.broadcast"(%105) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %107 = "arith.addf"(%100, %106) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %108 = "arith.truncf"(%107) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %109 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %110 = "arith.muli"(%109, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %111 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %112 = "tt.addptr"(%111, %110) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %113 = "tt.broadcast"(%112) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %114 = "tt.addptr"(%113, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %115 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %116 = "arith.cmpi"(%29, %115) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %117 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %118 = "arith.cmpi"(%60, %117) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %119 = "tt.broadcast"(%116) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %120 = "tt.broadcast"(%118) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %121 = "arith.andi"(%119, %120) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%114, %108, %121) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.andi'(0x555d5be7a5a0) {
  %136 = "arith.andi"(%83, %135) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'arith.andi -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::arith::AndIOp>"
    ** Insert  : 'arith.andi'(0x555d5bedce20)
    ** Replace : 'arith.andi'(0x555d5be7a5a0)
"{anonymous}::GenericOpPattern<mlir::arith::AndIOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'arith.andi'(0x555d5bedce20) {
      %137 = "arith.andi"(%83, %135) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.for' op 0-th region iter_arg and 0-th yielded value have different type: 'tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>' != 'tensor<32x32xf32>'
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %123 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %124 = "builtin.unrealized_conversion_cast"(%123) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %125 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %126 = "builtin.unrealized_conversion_cast"(%125) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %127 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %128 = "builtin.unrealized_conversion_cast"(%127) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %129 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %130 = "arith.subi"(%arg8, %129) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %131 = "tt.splat"(%130) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %132 = "tt.splat"(%130) : (i32) -> tensor<1x32xi32>
    %133 = "arith.cmpi"(%36, %131) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %134 = "arith.cmpi"(%37, %132) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %135 = "tt.broadcast"(%133) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %136 = "tt.broadcast"(%134) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %137 = "arith.andi"(%83, %135) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %138 = "arith.andi"(%84, %136) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %139 = "tt.load"(<<UNKNOWN SSA VALUE>>, %138, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %140 = "tt.splat"(%130) : (i32) -> tensor<32x1xi32>
    %141 = "arith.cmpi"(%52, %140) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %142 = "tt.broadcast"(%141) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %143 = "arith.andi"(%142, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %144 = "tt.load"(<<UNKNOWN SSA VALUE>>, %143, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %145 = "tt.dot"(%139, %144, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %146 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %147 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%145, %146, %147) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %97 = "arith.cmpi"(%25, %96) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %98 = "tt.load"(%75, %97, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %99 = "arith.sitofp"(%arg4) : (i32) -> f32
  %100 = "tt.splat"(%99) : (f32) -> tensor<32x32xf32>
  %101 = "arith.mulf"(%95#0, %100) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %102 = "arith.sitofp"(%arg5) : (i32) -> f16
  %103 = "tt.splat"(%102) : (f16) -> tensor<32xf16>
  %104 = "arith.mulf"(%98, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %105 = "tt.expand_dims"(%104) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %106 = "arith.extf"(%105) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %107 = "tt.broadcast"(%106) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %108 = "arith.addf"(%101, %107) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %109 = "arith.truncf"(%108) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %110 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %111 = "arith.muli"(%110, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %112 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %113 = "tt.addptr"(%112, %111) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %114 = "tt.broadcast"(%113) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %115 = "tt.addptr"(%114, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %116 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %117 = "arith.cmpi"(%29, %116) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %118 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %119 = "arith.cmpi"(%60, %118) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %120 = "tt.broadcast"(%117) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %121 = "tt.broadcast"(%119) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %122 = "arith.andi"(%120, %121) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%115, %109, %122) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.load'(0x555d5be71f90) {
  %139 = "tt.load"(<<UNKNOWN SSA VALUE>>, %138, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.load -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::triton::LoadOp>"
    ** Insert  : 'tt.load'(0x555d5bed7b00)
    ** Replace : 'tt.load'(0x555d5be71f90)
"{anonymous}::GenericOpPattern<mlir::triton::LoadOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.load'(0x555d5bed7b00) {
      %139 = "tt.load"(%126, %137, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.for' op 0-th region iter_arg and 0-th yielded value have different type: 'tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>' != 'tensor<32x32xf32>'
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %123 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %124 = "builtin.unrealized_conversion_cast"(%123) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %125 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %126 = "builtin.unrealized_conversion_cast"(%125) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %127 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %128 = "builtin.unrealized_conversion_cast"(%127) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %129 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %130 = "arith.subi"(%arg8, %129) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %131 = "tt.splat"(%130) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %132 = "tt.splat"(%130) : (i32) -> tensor<1x32xi32>
    %133 = "arith.cmpi"(%36, %131) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %134 = "arith.cmpi"(%37, %132) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %135 = "tt.broadcast"(%133) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %136 = "tt.broadcast"(%134) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %137 = "arith.andi"(%83, %135) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %138 = "arith.andi"(%84, %136) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %139 = "tt.load"(%126, %137, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %140 = "tt.load"(<<UNKNOWN SSA VALUE>>, %138, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %141 = "tt.splat"(%130) : (i32) -> tensor<32x1xi32>
    %142 = "arith.cmpi"(%52, %141) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %143 = "tt.broadcast"(%142) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %144 = "arith.andi"(%143, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %145 = "tt.load"(<<UNKNOWN SSA VALUE>>, %144, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %146 = "tt.dot"(%140, %145, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %147 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %148 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%146, %147, %148) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %97 = "arith.cmpi"(%25, %96) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %98 = "tt.load"(%75, %97, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %99 = "arith.sitofp"(%arg4) : (i32) -> f32
  %100 = "tt.splat"(%99) : (f32) -> tensor<32x32xf32>
  %101 = "arith.mulf"(%95#0, %100) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %102 = "arith.sitofp"(%arg5) : (i32) -> f16
  %103 = "tt.splat"(%102) : (f16) -> tensor<32xf16>
  %104 = "arith.mulf"(%98, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %105 = "tt.expand_dims"(%104) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %106 = "arith.extf"(%105) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %107 = "tt.broadcast"(%106) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %108 = "arith.addf"(%101, %107) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %109 = "arith.truncf"(%108) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %110 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %111 = "arith.muli"(%110, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %112 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %113 = "tt.addptr"(%112, %111) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %114 = "tt.broadcast"(%113) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %115 = "tt.addptr"(%114, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %116 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %117 = "arith.cmpi"(%29, %116) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %118 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %119 = "arith.cmpi"(%60, %118) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %120 = "tt.broadcast"(%117) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %121 = "tt.broadcast"(%119) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %122 = "arith.andi"(%120, %121) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%115, %109, %122) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.splat'(0x555d5be7a780) {
  %141 = "tt.splat"(%130) : (i32) -> tensor<32x1xi32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.splat -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::triton::SplatOp>"
    ** Insert  : 'tt.splat'(0x555d5beda3f0)
    ** Replace : 'tt.splat'(0x555d5be7a780)
"{anonymous}::GenericOpPattern<mlir::triton::SplatOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.splat'(0x555d5beda3f0) {
      %141 = "tt.splat"(%130) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.for' op 0-th region iter_arg and 0-th yielded value have different type: 'tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>' != 'tensor<32x32xf32>'
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %123 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %124 = "builtin.unrealized_conversion_cast"(%123) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %125 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %126 = "builtin.unrealized_conversion_cast"(%125) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %127 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %128 = "builtin.unrealized_conversion_cast"(%127) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %129 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %130 = "arith.subi"(%arg8, %129) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %131 = "tt.splat"(%130) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %132 = "tt.splat"(%130) : (i32) -> tensor<1x32xi32>
    %133 = "arith.cmpi"(%36, %131) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %134 = "arith.cmpi"(%37, %132) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %135 = "tt.broadcast"(%133) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %136 = "tt.broadcast"(%134) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %137 = "arith.andi"(%83, %135) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %138 = "arith.andi"(%84, %136) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %139 = "tt.load"(%126, %137, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %140 = "tt.load"(<<UNKNOWN SSA VALUE>>, %138, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %141 = "tt.splat"(%130) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %142 = "tt.splat"(%130) : (i32) -> tensor<32x1xi32>
    %143 = "arith.cmpi"(%52, %142) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %144 = "tt.broadcast"(%143) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %145 = "arith.andi"(%144, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %146 = "tt.load"(<<UNKNOWN SSA VALUE>>, %145, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %147 = "tt.dot"(%140, %146, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %148 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %149 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%147, %148, %149) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %97 = "arith.cmpi"(%25, %96) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %98 = "tt.load"(%75, %97, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %99 = "arith.sitofp"(%arg4) : (i32) -> f32
  %100 = "tt.splat"(%99) : (f32) -> tensor<32x32xf32>
  %101 = "arith.mulf"(%95#0, %100) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %102 = "arith.sitofp"(%arg5) : (i32) -> f16
  %103 = "tt.splat"(%102) : (f16) -> tensor<32xf16>
  %104 = "arith.mulf"(%98, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %105 = "tt.expand_dims"(%104) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %106 = "arith.extf"(%105) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %107 = "tt.broadcast"(%106) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %108 = "arith.addf"(%101, %107) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %109 = "arith.truncf"(%108) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %110 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %111 = "arith.muli"(%110, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %112 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %113 = "tt.addptr"(%112, %111) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %114 = "tt.broadcast"(%113) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %115 = "tt.addptr"(%114, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %116 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %117 = "arith.cmpi"(%29, %116) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %118 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %119 = "arith.cmpi"(%60, %118) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %120 = "tt.broadcast"(%117) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %121 = "tt.broadcast"(%119) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %122 = "arith.andi"(%120, %121) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%115, %109, %122) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.cmpi'(0x555d5be9dc70) {
  %143 = "arith.cmpi"(%52, %142) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'arith.cmpi -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::arith::CmpIOp>"
    ** Insert  : 'arith.cmpi'(0x555d5bed0c70)
    ** Replace : 'arith.cmpi'(0x555d5be9dc70)
"{anonymous}::GenericOpPattern<mlir::arith::CmpIOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'arith.cmpi'(0x555d5bed0c70) {
      %143 = "arith.cmpi"(%51, %141) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.for' op 0-th region iter_arg and 0-th yielded value have different type: 'tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>' != 'tensor<32x32xf32>'
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %123 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %124 = "builtin.unrealized_conversion_cast"(%123) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %125 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %126 = "builtin.unrealized_conversion_cast"(%125) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %127 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %128 = "builtin.unrealized_conversion_cast"(%127) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %129 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %130 = "arith.subi"(%arg8, %129) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %131 = "tt.splat"(%130) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %132 = "tt.splat"(%130) : (i32) -> tensor<1x32xi32>
    %133 = "arith.cmpi"(%36, %131) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %134 = "arith.cmpi"(%37, %132) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %135 = "tt.broadcast"(%133) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %136 = "tt.broadcast"(%134) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %137 = "arith.andi"(%83, %135) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %138 = "arith.andi"(%84, %136) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %139 = "tt.load"(%126, %137, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %140 = "tt.load"(<<UNKNOWN SSA VALUE>>, %138, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %141 = "tt.splat"(%130) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %142 = "tt.splat"(%130) : (i32) -> tensor<32x1xi32>
    %143 = "arith.cmpi"(%51, %141) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %144 = "arith.cmpi"(%52, %142) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %145 = "tt.broadcast"(%144) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %146 = "arith.andi"(%145, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %147 = "tt.load"(<<UNKNOWN SSA VALUE>>, %146, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %148 = "tt.dot"(%140, %147, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %149 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %150 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%148, %149, %150) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %97 = "arith.cmpi"(%25, %96) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %98 = "tt.load"(%75, %97, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %99 = "arith.sitofp"(%arg4) : (i32) -> f32
  %100 = "tt.splat"(%99) : (f32) -> tensor<32x32xf32>
  %101 = "arith.mulf"(%95#0, %100) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %102 = "arith.sitofp"(%arg5) : (i32) -> f16
  %103 = "tt.splat"(%102) : (f16) -> tensor<32xf16>
  %104 = "arith.mulf"(%98, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %105 = "tt.expand_dims"(%104) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %106 = "arith.extf"(%105) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %107 = "tt.broadcast"(%106) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %108 = "arith.addf"(%101, %107) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %109 = "arith.truncf"(%108) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %110 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %111 = "arith.muli"(%110, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %112 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %113 = "tt.addptr"(%112, %111) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %114 = "tt.broadcast"(%113) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %115 = "tt.addptr"(%114, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %116 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %117 = "arith.cmpi"(%29, %116) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %118 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %119 = "arith.cmpi"(%60, %118) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %120 = "tt.broadcast"(%117) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %121 = "tt.broadcast"(%119) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %122 = "arith.andi"(%120, %121) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%115, %109, %122) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.broadcast'(0x555d5be79db0) {
  %145 = "tt.broadcast"(%144) : (tensor<32x1xi1>) -> tensor<32x32xi1>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.broadcast -> ()' {
Trying to match "{anonymous}::TritonBroadcastPattern"
    ** Insert  : 'tt.broadcast'(0x555d5bedcb00)
    ** Replace : 'tt.broadcast'(0x555d5be79db0)
"{anonymous}::TritonBroadcastPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.broadcast'(0x555d5bedcb00) {
      %145 = "tt.broadcast"(%143) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.for' op 0-th region iter_arg and 0-th yielded value have different type: 'tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>' != 'tensor<32x32xf32>'
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %123 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %124 = "builtin.unrealized_conversion_cast"(%123) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %125 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %126 = "builtin.unrealized_conversion_cast"(%125) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %127 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %128 = "builtin.unrealized_conversion_cast"(%127) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %129 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %130 = "arith.subi"(%arg8, %129) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %131 = "tt.splat"(%130) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %132 = "tt.splat"(%130) : (i32) -> tensor<1x32xi32>
    %133 = "arith.cmpi"(%36, %131) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %134 = "arith.cmpi"(%37, %132) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %135 = "tt.broadcast"(%133) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %136 = "tt.broadcast"(%134) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %137 = "arith.andi"(%83, %135) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %138 = "arith.andi"(%84, %136) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %139 = "tt.load"(%126, %137, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %140 = "tt.load"(<<UNKNOWN SSA VALUE>>, %138, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %141 = "tt.splat"(%130) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %142 = "tt.splat"(%130) : (i32) -> tensor<32x1xi32>
    %143 = "arith.cmpi"(%51, %141) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %144 = "arith.cmpi"(%52, %142) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %145 = "tt.broadcast"(%143) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %146 = "tt.broadcast"(%144) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %147 = "arith.andi"(%146, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %148 = "tt.load"(<<UNKNOWN SSA VALUE>>, %147, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %149 = "tt.dot"(%140, %148, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %150 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %151 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%149, %150, %151) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %97 = "arith.cmpi"(%25, %96) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %98 = "tt.load"(%75, %97, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %99 = "arith.sitofp"(%arg4) : (i32) -> f32
  %100 = "tt.splat"(%99) : (f32) -> tensor<32x32xf32>
  %101 = "arith.mulf"(%95#0, %100) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %102 = "arith.sitofp"(%arg5) : (i32) -> f16
  %103 = "tt.splat"(%102) : (f16) -> tensor<32xf16>
  %104 = "arith.mulf"(%98, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %105 = "tt.expand_dims"(%104) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %106 = "arith.extf"(%105) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %107 = "tt.broadcast"(%106) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %108 = "arith.addf"(%101, %107) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %109 = "arith.truncf"(%108) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %110 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %111 = "arith.muli"(%110, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %112 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %113 = "tt.addptr"(%112, %111) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %114 = "tt.broadcast"(%113) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %115 = "tt.addptr"(%114, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %116 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %117 = "arith.cmpi"(%29, %116) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %118 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %119 = "arith.cmpi"(%60, %118) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %120 = "tt.broadcast"(%117) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %121 = "tt.broadcast"(%119) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %122 = "arith.andi"(%120, %121) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%115, %109, %122) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.andi'(0x555d5be9df40) {
  %147 = "arith.andi"(%146, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'arith.andi -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::arith::AndIOp>"
    ** Insert  : 'arith.andi'(0x555d5bed0da0)
    ** Replace : 'arith.andi'(0x555d5be9df40)
"{anonymous}::GenericOpPattern<mlir::arith::AndIOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'arith.andi'(0x555d5bed0da0) {
      %148 = "arith.andi"(%146, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.for' op 0-th region iter_arg and 0-th yielded value have different type: 'tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>' != 'tensor<32x32xf32>'
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %123 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %124 = "builtin.unrealized_conversion_cast"(%123) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %125 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %126 = "builtin.unrealized_conversion_cast"(%125) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %127 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %128 = "builtin.unrealized_conversion_cast"(%127) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %129 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %130 = "arith.subi"(%arg8, %129) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %131 = "tt.splat"(%130) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %132 = "tt.splat"(%130) : (i32) -> tensor<1x32xi32>
    %133 = "arith.cmpi"(%36, %131) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %134 = "arith.cmpi"(%37, %132) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %135 = "tt.broadcast"(%133) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %136 = "tt.broadcast"(%134) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %137 = "arith.andi"(%83, %135) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %138 = "arith.andi"(%84, %136) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %139 = "tt.load"(%126, %137, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %140 = "tt.load"(<<UNKNOWN SSA VALUE>>, %138, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %141 = "tt.splat"(%130) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %142 = "tt.splat"(%130) : (i32) -> tensor<32x1xi32>
    %143 = "arith.cmpi"(%51, %141) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %144 = "arith.cmpi"(%52, %142) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %145 = "tt.broadcast"(%143) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %146 = "builtin.unrealized_conversion_cast"(%145) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %147 = "tt.broadcast"(%144) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %148 = "arith.andi"(%146, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = "arith.andi"(%147, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %150 = "tt.load"(<<UNKNOWN SSA VALUE>>, %149, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %151 = "tt.dot"(%140, %150, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %152 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %153 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%151, %152, %153) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %97 = "arith.cmpi"(%25, %96) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %98 = "tt.load"(%75, %97, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %99 = "arith.sitofp"(%arg4) : (i32) -> f32
  %100 = "tt.splat"(%99) : (f32) -> tensor<32x32xf32>
  %101 = "arith.mulf"(%95#0, %100) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %102 = "arith.sitofp"(%arg5) : (i32) -> f16
  %103 = "tt.splat"(%102) : (f16) -> tensor<32xf16>
  %104 = "arith.mulf"(%98, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %105 = "tt.expand_dims"(%104) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %106 = "arith.extf"(%105) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %107 = "tt.broadcast"(%106) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %108 = "arith.addf"(%101, %107) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %109 = "arith.truncf"(%108) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %110 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %111 = "arith.muli"(%110, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %112 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %113 = "tt.addptr"(%112, %111) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %114 = "tt.broadcast"(%113) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %115 = "tt.addptr"(%114, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %116 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %117 = "arith.cmpi"(%29, %116) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %118 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %119 = "arith.cmpi"(%60, %118) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %120 = "tt.broadcast"(%117) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %121 = "tt.broadcast"(%119) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %122 = "arith.andi"(%120, %121) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%115, %109, %122) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.load'(0x555d5be9e090) {
  %150 = "tt.load"(<<UNKNOWN SSA VALUE>>, %149, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.load -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::triton::LoadOp>"
    ** Insert  : 'tt.load'(0x555d5bedd0a0)
    ** Replace : 'tt.load'(0x555d5be9e090)
"{anonymous}::GenericOpPattern<mlir::triton::LoadOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.load'(0x555d5bedd0a0) {
      %150 = "tt.load"(%124, %148, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.for' op 0-th region iter_arg and 0-th yielded value have different type: 'tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>' != 'tensor<32x32xf32>'
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %123 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %124 = "builtin.unrealized_conversion_cast"(%123) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %125 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %126 = "builtin.unrealized_conversion_cast"(%125) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %127 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %128 = "builtin.unrealized_conversion_cast"(%127) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %129 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %130 = "arith.subi"(%arg8, %129) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %131 = "tt.splat"(%130) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %132 = "tt.splat"(%130) : (i32) -> tensor<1x32xi32>
    %133 = "arith.cmpi"(%36, %131) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %134 = "arith.cmpi"(%37, %132) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %135 = "tt.broadcast"(%133) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %136 = "tt.broadcast"(%134) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %137 = "arith.andi"(%83, %135) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %138 = "arith.andi"(%84, %136) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %139 = "tt.load"(%126, %137, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %140 = "tt.load"(<<UNKNOWN SSA VALUE>>, %138, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %141 = "tt.splat"(%130) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %142 = "tt.splat"(%130) : (i32) -> tensor<32x1xi32>
    %143 = "arith.cmpi"(%51, %141) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %144 = "arith.cmpi"(%52, %142) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %145 = "tt.broadcast"(%143) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %146 = "builtin.unrealized_conversion_cast"(%145) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %147 = "tt.broadcast"(%144) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %148 = "arith.andi"(%146, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = "arith.andi"(%147, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %150 = "tt.load"(%124, %148, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %151 = "tt.load"(<<UNKNOWN SSA VALUE>>, %149, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %152 = "tt.dot"(%140, %151, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %153 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %154 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%152, %153, %154) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %97 = "arith.cmpi"(%25, %96) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %98 = "tt.load"(%75, %97, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %99 = "arith.sitofp"(%arg4) : (i32) -> f32
  %100 = "tt.splat"(%99) : (f32) -> tensor<32x32xf32>
  %101 = "arith.mulf"(%95#0, %100) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %102 = "arith.sitofp"(%arg5) : (i32) -> f16
  %103 = "tt.splat"(%102) : (f16) -> tensor<32xf16>
  %104 = "arith.mulf"(%98, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %105 = "tt.expand_dims"(%104) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %106 = "arith.extf"(%105) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %107 = "tt.broadcast"(%106) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %108 = "arith.addf"(%101, %107) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %109 = "arith.truncf"(%108) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %110 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %111 = "arith.muli"(%110, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %112 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %113 = "tt.addptr"(%112, %111) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %114 = "tt.broadcast"(%113) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %115 = "tt.addptr"(%114, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %116 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %117 = "arith.cmpi"(%29, %116) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %118 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %119 = "arith.cmpi"(%60, %118) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %120 = "tt.broadcast"(%117) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %121 = "tt.broadcast"(%119) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %122 = "arith.andi"(%120, %121) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%115, %109, %122) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.dot'(0x555d5be71e50) {
  %152 = "tt.dot"(%140, %151, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.dot -> ()' {
Trying to match "{anonymous}::TritonDotPattern"
    ** Insert  : 'triton_gpu.convert_layout'(0x555d5bed5510)
    ** Insert  : 'triton_gpu.convert_layout'(0x555d5bed4d50)
    ** Insert  : 'triton_gpu.convert_layout'(0x555d5bed3df0)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::triton::detail::DotOpGenericAdaptorBase::Properties)
    ** Insert  : 'tt.dot'(0x555d5bed21a0)
    ** Replace : 'tt.dot'(0x555d5be71e50)
"{anonymous}::TritonDotPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'triton_gpu.convert_layout'(0x555d5bed5510) {
      %152 = "triton_gpu.convert_layout"(%139) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'triton_gpu.convert_layout'(0x555d5bed4d50) {
      %153 = "triton_gpu.convert_layout"(%150) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'triton_gpu.convert_layout'(0x555d5bed3df0) {
      %154 = "triton_gpu.convert_layout"(%128) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'tt.dot'(0x555d5bed21a0) {
      %155 = "tt.dot"(%152, %153, %154) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.for' op 0-th region iter_arg and 0-th yielded value have different type: 'tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>' != 'tensor<32x32xf32>'
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %123 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %124 = "builtin.unrealized_conversion_cast"(%123) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %125 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %126 = "builtin.unrealized_conversion_cast"(%125) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %127 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %128 = "builtin.unrealized_conversion_cast"(%127) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %129 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %130 = "arith.subi"(%arg8, %129) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %131 = "tt.splat"(%130) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %132 = "tt.splat"(%130) : (i32) -> tensor<1x32xi32>
    %133 = "arith.cmpi"(%36, %131) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %134 = "arith.cmpi"(%37, %132) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %135 = "tt.broadcast"(%133) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %136 = "tt.broadcast"(%134) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %137 = "arith.andi"(%83, %135) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %138 = "arith.andi"(%84, %136) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %139 = "tt.load"(%126, %137, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %140 = "tt.load"(<<UNKNOWN SSA VALUE>>, %138, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %141 = "tt.splat"(%130) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %142 = "tt.splat"(%130) : (i32) -> tensor<32x1xi32>
    %143 = "arith.cmpi"(%51, %141) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %144 = "arith.cmpi"(%52, %142) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %145 = "tt.broadcast"(%143) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %146 = "builtin.unrealized_conversion_cast"(%145) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %147 = "tt.broadcast"(%144) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %148 = "arith.andi"(%146, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = "arith.andi"(%147, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %150 = "tt.load"(%124, %148, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %151 = "tt.load"(<<UNKNOWN SSA VALUE>>, %149, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %152 = "triton_gpu.convert_layout"(%139) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %153 = "triton_gpu.convert_layout"(%150) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %154 = "triton_gpu.convert_layout"(%128) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %155 = "tt.dot"(%152, %153, %154) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %156 = "tt.dot"(%140, %151, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %157 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %158 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%156, %157, %158) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %97 = "arith.cmpi"(%25, %96) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %98 = "tt.load"(%75, %97, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %99 = "arith.sitofp"(%arg4) : (i32) -> f32
  %100 = "tt.splat"(%99) : (f32) -> tensor<32x32xf32>
  %101 = "arith.mulf"(%95#0, %100) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %102 = "arith.sitofp"(%arg5) : (i32) -> f16
  %103 = "tt.splat"(%102) : (f16) -> tensor<32xf16>
  %104 = "arith.mulf"(%98, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %105 = "tt.expand_dims"(%104) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %106 = "arith.extf"(%105) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %107 = "tt.broadcast"(%106) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %108 = "arith.addf"(%101, %107) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %109 = "arith.truncf"(%108) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %110 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %111 = "arith.muli"(%110, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %112 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %113 = "tt.addptr"(%112, %111) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %114 = "tt.broadcast"(%113) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %115 = "tt.addptr"(%114, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %116 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %117 = "arith.cmpi"(%29, %116) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %118 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %119 = "arith.cmpi"(%60, %118) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %120 = "tt.broadcast"(%117) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %121 = "tt.broadcast"(%119) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %122 = "arith.andi"(%120, %121) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%115, %109, %122) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.addptr'(0x555d5be9e690) {
  %157 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.addptr -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::triton::AddPtrOp>"
    ** Insert  : 'tt.addptr'(0x555d5bed3fc0)
    ** Replace : 'tt.addptr'(0x555d5be9e690)
"{anonymous}::GenericOpPattern<mlir::triton::AddPtrOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.addptr'(0x555d5bed3fc0) {
      %157 = "tt.addptr"(%126, %7) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.for' op 0-th region iter_arg and 0-th yielded value have different type: 'tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>' != 'tensor<32x32xf32>'
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %123 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %124 = "builtin.unrealized_conversion_cast"(%123) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %125 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %126 = "builtin.unrealized_conversion_cast"(%125) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %127 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %128 = "builtin.unrealized_conversion_cast"(%127) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %129 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %130 = "arith.subi"(%arg8, %129) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %131 = "tt.splat"(%130) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %132 = "tt.splat"(%130) : (i32) -> tensor<1x32xi32>
    %133 = "arith.cmpi"(%36, %131) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %134 = "arith.cmpi"(%37, %132) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %135 = "tt.broadcast"(%133) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %136 = "tt.broadcast"(%134) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %137 = "arith.andi"(%83, %135) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %138 = "arith.andi"(%84, %136) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %139 = "tt.load"(%126, %137, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %140 = "tt.load"(<<UNKNOWN SSA VALUE>>, %138, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %141 = "tt.splat"(%130) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %142 = "tt.splat"(%130) : (i32) -> tensor<32x1xi32>
    %143 = "arith.cmpi"(%51, %141) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %144 = "arith.cmpi"(%52, %142) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %145 = "tt.broadcast"(%143) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %146 = "builtin.unrealized_conversion_cast"(%145) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %147 = "tt.broadcast"(%144) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %148 = "arith.andi"(%146, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = "arith.andi"(%147, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %150 = "tt.load"(%124, %148, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %151 = "tt.load"(<<UNKNOWN SSA VALUE>>, %149, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %152 = "triton_gpu.convert_layout"(%139) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %153 = "triton_gpu.convert_layout"(%150) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %154 = "triton_gpu.convert_layout"(%128) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %155 = "tt.dot"(%152, %153, %154) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %156 = "tt.dot"(%140, %151, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %157 = "tt.addptr"(%126, %7) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %158 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %159 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%156, %158, %159) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %97 = "arith.cmpi"(%25, %96) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %98 = "tt.load"(%75, %97, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %99 = "arith.sitofp"(%arg4) : (i32) -> f32
  %100 = "tt.splat"(%99) : (f32) -> tensor<32x32xf32>
  %101 = "arith.mulf"(%95#0, %100) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %102 = "arith.sitofp"(%arg5) : (i32) -> f16
  %103 = "tt.splat"(%102) : (f16) -> tensor<32xf16>
  %104 = "arith.mulf"(%98, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %105 = "tt.expand_dims"(%104) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %106 = "arith.extf"(%105) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %107 = "tt.broadcast"(%106) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %108 = "arith.addf"(%101, %107) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %109 = "arith.truncf"(%108) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %110 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %111 = "arith.muli"(%110, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %112 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %113 = "tt.addptr"(%112, %111) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %114 = "tt.broadcast"(%113) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %115 = "tt.addptr"(%114, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %116 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %117 = "arith.cmpi"(%29, %116) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %118 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %119 = "arith.cmpi"(%60, %118) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %120 = "tt.broadcast"(%117) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %121 = "tt.broadcast"(%119) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %122 = "arith.andi"(%120, %121) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%115, %109, %122) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.addptr'(0x555d5be9e7a0) {
  %159 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.addptr -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::triton::AddPtrOp>"
    ** Insert  : 'tt.addptr'(0x555d5bee0190)
    ** Replace : 'tt.addptr'(0x555d5be9e7a0)
"{anonymous}::GenericOpPattern<mlir::triton::AddPtrOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.addptr'(0x555d5bee0190) {
      %159 = "tt.addptr"(%124, %92) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.for' op 0-th region iter_arg and 0-th yielded value have different type: 'tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>' != 'tensor<32x32xf32>'
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %123 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %124 = "builtin.unrealized_conversion_cast"(%123) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %125 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %126 = "builtin.unrealized_conversion_cast"(%125) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %127 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %128 = "builtin.unrealized_conversion_cast"(%127) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %129 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %130 = "arith.subi"(%arg8, %129) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %131 = "tt.splat"(%130) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %132 = "tt.splat"(%130) : (i32) -> tensor<1x32xi32>
    %133 = "arith.cmpi"(%36, %131) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %134 = "arith.cmpi"(%37, %132) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %135 = "tt.broadcast"(%133) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %136 = "tt.broadcast"(%134) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %137 = "arith.andi"(%83, %135) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %138 = "arith.andi"(%84, %136) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %139 = "tt.load"(%126, %137, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %140 = "tt.load"(<<UNKNOWN SSA VALUE>>, %138, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %141 = "tt.splat"(%130) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %142 = "tt.splat"(%130) : (i32) -> tensor<32x1xi32>
    %143 = "arith.cmpi"(%51, %141) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %144 = "arith.cmpi"(%52, %142) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %145 = "tt.broadcast"(%143) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %146 = "builtin.unrealized_conversion_cast"(%145) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %147 = "tt.broadcast"(%144) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %148 = "arith.andi"(%146, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = "arith.andi"(%147, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %150 = "tt.load"(%124, %148, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %151 = "tt.load"(<<UNKNOWN SSA VALUE>>, %149, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %152 = "triton_gpu.convert_layout"(%139) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %153 = "triton_gpu.convert_layout"(%150) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %154 = "triton_gpu.convert_layout"(%128) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %155 = "tt.dot"(%152, %153, %154) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %156 = "tt.dot"(%140, %151, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %157 = "tt.addptr"(%126, %7) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %158 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %159 = "tt.addptr"(%124, %92) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %160 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%156, %158, %160) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %97 = "arith.cmpi"(%25, %96) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %98 = "tt.load"(%75, %97, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %99 = "arith.sitofp"(%arg4) : (i32) -> f32
  %100 = "tt.splat"(%99) : (f32) -> tensor<32x32xf32>
  %101 = "arith.mulf"(%95#0, %100) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %102 = "arith.sitofp"(%arg5) : (i32) -> f16
  %103 = "tt.splat"(%102) : (f16) -> tensor<32xf16>
  %104 = "arith.mulf"(%98, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %105 = "tt.expand_dims"(%104) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %106 = "arith.extf"(%105) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %107 = "tt.broadcast"(%106) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %108 = "arith.addf"(%101, %107) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %109 = "arith.truncf"(%108) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %110 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %111 = "arith.muli"(%110, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %112 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %113 = "tt.addptr"(%112, %111) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %114 = "tt.broadcast"(%113) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %115 = "tt.addptr"(%114, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %116 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %117 = "arith.cmpi"(%29, %116) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %118 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %119 = "arith.cmpi"(%60, %118) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %120 = "tt.broadcast"(%117) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %121 = "tt.broadcast"(%119) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %122 = "arith.andi"(%120, %121) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%115, %109, %122) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'scf.yield'(0x555d5be9e8c0) {
  "scf.yield"(%156, %158, %160) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'scf.yield -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::scf::YieldOp>"
    ** Insert  : 'scf.yield'(0x555d5bed27a0)
    ** Replace : 'scf.yield'(0x555d5be9e8c0)
"{anonymous}::GenericOpPattern<mlir::scf::YieldOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'scf.yield'(0x555d5bed27a0) {
      "scf.yield"(%156, %158, %160) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> ()

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.yield' op must be the last operation in the parent block
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %123 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %124 = "builtin.unrealized_conversion_cast"(%123) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %125 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %126 = "builtin.unrealized_conversion_cast"(%125) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %127 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %128 = "builtin.unrealized_conversion_cast"(%127) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %129 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %130 = "arith.subi"(%arg8, %129) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %131 = "tt.splat"(%130) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %132 = "tt.splat"(%130) : (i32) -> tensor<1x32xi32>
    %133 = "arith.cmpi"(%36, %131) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %134 = "arith.cmpi"(%37, %132) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %135 = "tt.broadcast"(%133) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %136 = "tt.broadcast"(%134) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %137 = "arith.andi"(%83, %135) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %138 = "arith.andi"(%84, %136) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %139 = "tt.load"(%126, %137, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %140 = "tt.load"(<<UNKNOWN SSA VALUE>>, %138, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %141 = "tt.splat"(%130) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %142 = "tt.splat"(%130) : (i32) -> tensor<32x1xi32>
    %143 = "arith.cmpi"(%51, %141) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %144 = "arith.cmpi"(%52, %142) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %145 = "tt.broadcast"(%143) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %146 = "builtin.unrealized_conversion_cast"(%145) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %147 = "tt.broadcast"(%144) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %148 = "arith.andi"(%146, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = "arith.andi"(%147, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %150 = "tt.load"(%124, %148, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %151 = "tt.load"(<<UNKNOWN SSA VALUE>>, %149, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %152 = "triton_gpu.convert_layout"(%139) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %153 = "triton_gpu.convert_layout"(%150) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %154 = "triton_gpu.convert_layout"(%128) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %155 = "tt.dot"(%152, %153, %154) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %156 = "builtin.unrealized_conversion_cast"(%155) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %157 = "tt.dot"(%140, %151, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %158 = "tt.addptr"(%126, %7) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %159 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %160 = "tt.addptr"(%124, %92) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %161 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%156, %158, %160) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> ()
    "scf.yield"(%157, %159, %161) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %97 = "arith.cmpi"(%25, %96) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %98 = "tt.load"(%75, %97, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %99 = "arith.sitofp"(%arg4) : (i32) -> f32
  %100 = "tt.splat"(%99) : (f32) -> tensor<32x32xf32>
  %101 = "arith.mulf"(%95#0, %100) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %102 = "arith.sitofp"(%arg5) : (i32) -> f16
  %103 = "tt.splat"(%102) : (f16) -> tensor<32xf16>
  %104 = "arith.mulf"(%98, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %105 = "tt.expand_dims"(%104) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %106 = "arith.extf"(%105) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %107 = "tt.broadcast"(%106) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %108 = "arith.addf"(%101, %107) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %109 = "arith.truncf"(%108) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %110 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %111 = "arith.muli"(%110, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %112 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %113 = "tt.addptr"(%112, %111) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %114 = "tt.broadcast"(%113) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %115 = "tt.addptr"(%114, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %116 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %117 = "arith.cmpi"(%29, %116) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %118 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %119 = "arith.cmpi"(%60, %118) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %120 = "tt.broadcast"(%117) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %121 = "tt.broadcast"(%119) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %122 = "arith.andi"(%120, %121) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%115, %109, %122) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.splat'(0x555d5be9e990) {
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.splat -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::triton::SplatOp>"
    ** Insert  : 'tt.splat'(0x555d5bee0510)
    ** Replace : 'tt.splat'(0x555d5be9e990)
"{anonymous}::GenericOpPattern<mlir::triton::SplatOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.splat'(0x555d5bee0510) {
      %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.yield' op must be the last operation in the parent block
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %124 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %125 = "builtin.unrealized_conversion_cast"(%124) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %126 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %127 = "builtin.unrealized_conversion_cast"(%126) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %128 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %129 = "builtin.unrealized_conversion_cast"(%128) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %130 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %131 = "arith.subi"(%arg8, %130) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %132 = "tt.splat"(%131) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %133 = "tt.splat"(%131) : (i32) -> tensor<1x32xi32>
    %134 = "arith.cmpi"(%36, %132) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %135 = "arith.cmpi"(%37, %133) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %136 = "tt.broadcast"(%134) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %137 = "tt.broadcast"(%135) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %138 = "arith.andi"(%83, %136) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %139 = "arith.andi"(%84, %137) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %140 = "tt.load"(%127, %138, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %141 = "tt.load"(<<UNKNOWN SSA VALUE>>, %139, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %142 = "tt.splat"(%131) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %143 = "tt.splat"(%131) : (i32) -> tensor<32x1xi32>
    %144 = "arith.cmpi"(%51, %142) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %145 = "arith.cmpi"(%52, %143) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %146 = "tt.broadcast"(%144) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %147 = "builtin.unrealized_conversion_cast"(%146) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %148 = "tt.broadcast"(%145) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %149 = "arith.andi"(%147, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %150 = "arith.andi"(%148, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %151 = "tt.load"(%125, %149, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %152 = "tt.load"(<<UNKNOWN SSA VALUE>>, %150, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %153 = "triton_gpu.convert_layout"(%140) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %154 = "triton_gpu.convert_layout"(%151) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %155 = "triton_gpu.convert_layout"(%129) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %156 = "tt.dot"(%153, %154, %155) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %157 = "builtin.unrealized_conversion_cast"(%156) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %158 = "tt.dot"(%141, %152, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %159 = "tt.addptr"(%127, %7) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %160 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %161 = "tt.addptr"(%125, %92) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %162 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%157, %159, %161) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> ()
    "scf.yield"(%158, %160, %162) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %97 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %98 = "arith.cmpi"(%25, %97) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %99 = "tt.load"(%75, %98, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %100 = "arith.sitofp"(%arg4) : (i32) -> f32
  %101 = "tt.splat"(%100) : (f32) -> tensor<32x32xf32>
  %102 = "arith.mulf"(%95#0, %101) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %103 = "arith.sitofp"(%arg5) : (i32) -> f16
  %104 = "tt.splat"(%103) : (f16) -> tensor<32xf16>
  %105 = "arith.mulf"(%99, %104) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %106 = "tt.expand_dims"(%105) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %107 = "arith.extf"(%106) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %108 = "tt.broadcast"(%107) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %109 = "arith.addf"(%102, %108) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %110 = "arith.truncf"(%109) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %111 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %112 = "arith.muli"(%111, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %113 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %114 = "tt.addptr"(%113, %112) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %115 = "tt.broadcast"(%114) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %116 = "tt.addptr"(%115, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %117 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %118 = "arith.cmpi"(%29, %117) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %119 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %120 = "arith.cmpi"(%60, %119) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %121 = "tt.broadcast"(%118) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %122 = "tt.broadcast"(%120) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %123 = "arith.andi"(%121, %122) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%116, %110, %123) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.cmpi'(0x555d5be99b20) {
  %98 = "arith.cmpi"(%25, %97) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'arith.cmpi -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::arith::CmpIOp>"
    ** Insert  : 'arith.cmpi'(0x555d5bedf3c0)
    ** Replace : 'arith.cmpi'(0x555d5be99b20)
"{anonymous}::GenericOpPattern<mlir::arith::CmpIOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'arith.cmpi'(0x555d5bedf3c0) {
      %98 = "arith.cmpi"(%24, %96) <{predicate = 2 : i64}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.yield' op must be the last operation in the parent block
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %125 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %126 = "builtin.unrealized_conversion_cast"(%125) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %127 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %128 = "builtin.unrealized_conversion_cast"(%127) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %129 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %130 = "builtin.unrealized_conversion_cast"(%129) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %131 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %132 = "arith.subi"(%arg8, %131) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %133 = "tt.splat"(%132) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %134 = "tt.splat"(%132) : (i32) -> tensor<1x32xi32>
    %135 = "arith.cmpi"(%36, %133) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %136 = "arith.cmpi"(%37, %134) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %137 = "tt.broadcast"(%135) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %138 = "tt.broadcast"(%136) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %139 = "arith.andi"(%83, %137) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %140 = "arith.andi"(%84, %138) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %141 = "tt.load"(%128, %139, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %142 = "tt.load"(<<UNKNOWN SSA VALUE>>, %140, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %143 = "tt.splat"(%132) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %144 = "tt.splat"(%132) : (i32) -> tensor<32x1xi32>
    %145 = "arith.cmpi"(%51, %143) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %146 = "arith.cmpi"(%52, %144) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %147 = "tt.broadcast"(%145) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %148 = "builtin.unrealized_conversion_cast"(%147) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = "tt.broadcast"(%146) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %150 = "arith.andi"(%148, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %151 = "arith.andi"(%149, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %152 = "tt.load"(%126, %150, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %153 = "tt.load"(<<UNKNOWN SSA VALUE>>, %151, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %154 = "triton_gpu.convert_layout"(%141) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %155 = "triton_gpu.convert_layout"(%152) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %156 = "triton_gpu.convert_layout"(%130) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %157 = "tt.dot"(%154, %155, %156) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %158 = "builtin.unrealized_conversion_cast"(%157) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %159 = "tt.dot"(%142, %153, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %160 = "tt.addptr"(%128, %7) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %161 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %162 = "tt.addptr"(%126, %92) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %163 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%158, %160, %162) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> ()
    "scf.yield"(%159, %161, %163) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %97 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %98 = "arith.cmpi"(%24, %96) <{predicate = 2 : i64}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %99 = "arith.cmpi"(%25, %97) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %100 = "tt.load"(%75, %99, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %101 = "arith.sitofp"(%arg4) : (i32) -> f32
  %102 = "tt.splat"(%101) : (f32) -> tensor<32x32xf32>
  %103 = "arith.mulf"(%95#0, %102) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %104 = "arith.sitofp"(%arg5) : (i32) -> f16
  %105 = "tt.splat"(%104) : (f16) -> tensor<32xf16>
  %106 = "arith.mulf"(%100, %105) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %107 = "tt.expand_dims"(%106) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %108 = "arith.extf"(%107) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %109 = "tt.broadcast"(%108) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %110 = "arith.addf"(%103, %109) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %111 = "arith.truncf"(%110) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %112 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %113 = "arith.muli"(%112, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %114 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %115 = "tt.addptr"(%114, %113) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %116 = "tt.broadcast"(%115) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %117 = "tt.addptr"(%116, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %118 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %119 = "arith.cmpi"(%29, %118) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %120 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %121 = "arith.cmpi"(%60, %120) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %122 = "tt.broadcast"(%119) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %123 = "tt.broadcast"(%121) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %124 = "arith.andi"(%122, %123) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%117, %111, %124) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.load'(0x555d5be99bd0) {
  %100 = "tt.load"(%75, %99, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.load -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::triton::LoadOp>"
    ** Insert  : 'tt.load'(0x555d5bed4e10)
    ** Replace : 'tt.load'(0x555d5be99bd0)
"{anonymous}::GenericOpPattern<mlir::triton::LoadOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.load'(0x555d5bed4e10) {
      %100 = "tt.load"(%74, %98, %1) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.yield' op must be the last operation in the parent block
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %126 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %127 = "builtin.unrealized_conversion_cast"(%126) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %128 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %129 = "builtin.unrealized_conversion_cast"(%128) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %130 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %131 = "builtin.unrealized_conversion_cast"(%130) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %132 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %133 = "arith.subi"(%arg8, %132) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %134 = "tt.splat"(%133) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %135 = "tt.splat"(%133) : (i32) -> tensor<1x32xi32>
    %136 = "arith.cmpi"(%36, %134) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %137 = "arith.cmpi"(%37, %135) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %138 = "tt.broadcast"(%136) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %139 = "tt.broadcast"(%137) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %140 = "arith.andi"(%83, %138) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %141 = "arith.andi"(%84, %139) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %142 = "tt.load"(%129, %140, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %143 = "tt.load"(<<UNKNOWN SSA VALUE>>, %141, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %144 = "tt.splat"(%133) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %145 = "tt.splat"(%133) : (i32) -> tensor<32x1xi32>
    %146 = "arith.cmpi"(%51, %144) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %147 = "arith.cmpi"(%52, %145) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %148 = "tt.broadcast"(%146) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = "builtin.unrealized_conversion_cast"(%148) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %150 = "tt.broadcast"(%147) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %151 = "arith.andi"(%149, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %152 = "arith.andi"(%150, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %153 = "tt.load"(%127, %151, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %154 = "tt.load"(<<UNKNOWN SSA VALUE>>, %152, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %155 = "triton_gpu.convert_layout"(%142) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %156 = "triton_gpu.convert_layout"(%153) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %157 = "triton_gpu.convert_layout"(%131) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %158 = "tt.dot"(%155, %156, %157) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %159 = "builtin.unrealized_conversion_cast"(%158) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %160 = "tt.dot"(%143, %154, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %161 = "tt.addptr"(%129, %7) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %162 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %163 = "tt.addptr"(%127, %92) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %164 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%159, %161, %163) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> ()
    "scf.yield"(%160, %162, %164) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %97 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %98 = "arith.cmpi"(%24, %96) <{predicate = 2 : i64}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %99 = "arith.cmpi"(%25, %97) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %100 = "tt.load"(%74, %98, %1) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %101 = "tt.load"(%75, %99, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %102 = "arith.sitofp"(%arg4) : (i32) -> f32
  %103 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32>
  %104 = "arith.mulf"(%95#0, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %105 = "arith.sitofp"(%arg5) : (i32) -> f16
  %106 = "tt.splat"(%105) : (f16) -> tensor<32xf16>
  %107 = "arith.mulf"(%101, %106) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %108 = "tt.expand_dims"(%107) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %109 = "arith.extf"(%108) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %110 = "tt.broadcast"(%109) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %111 = "arith.addf"(%104, %110) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %112 = "arith.truncf"(%111) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %113 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %114 = "arith.muli"(%113, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %115 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %116 = "tt.addptr"(%115, %114) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %117 = "tt.broadcast"(%116) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %118 = "tt.addptr"(%117, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %119 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %120 = "arith.cmpi"(%29, %119) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %121 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %122 = "arith.cmpi"(%60, %121) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %123 = "tt.broadcast"(%120) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %124 = "tt.broadcast"(%122) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %125 = "arith.andi"(%123, %124) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%118, %112, %125) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.sitofp'(0x555d5be99cd0) {
  %102 = "arith.sitofp"(%arg4) : (i32) -> f32

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.splat'(0x555d5be99d60) {
  %103 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.splat -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::triton::SplatOp>"
    ** Insert  : 'tt.splat'(0x555d5bee0040)
    ** Replace : 'tt.splat'(0x555d5be99d60)
"{anonymous}::GenericOpPattern<mlir::triton::SplatOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.splat'(0x555d5bee0040) {
      %103 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.yield' op must be the last operation in the parent block
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %127 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %128 = "builtin.unrealized_conversion_cast"(%127) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %129 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %130 = "builtin.unrealized_conversion_cast"(%129) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %131 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %132 = "builtin.unrealized_conversion_cast"(%131) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %133 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %134 = "arith.subi"(%arg8, %133) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %135 = "tt.splat"(%134) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %136 = "tt.splat"(%134) : (i32) -> tensor<1x32xi32>
    %137 = "arith.cmpi"(%36, %135) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %138 = "arith.cmpi"(%37, %136) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %139 = "tt.broadcast"(%137) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %140 = "tt.broadcast"(%138) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %141 = "arith.andi"(%83, %139) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %142 = "arith.andi"(%84, %140) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %143 = "tt.load"(%130, %141, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %144 = "tt.load"(<<UNKNOWN SSA VALUE>>, %142, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %145 = "tt.splat"(%134) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %146 = "tt.splat"(%134) : (i32) -> tensor<32x1xi32>
    %147 = "arith.cmpi"(%51, %145) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %148 = "arith.cmpi"(%52, %146) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %149 = "tt.broadcast"(%147) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %150 = "builtin.unrealized_conversion_cast"(%149) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %151 = "tt.broadcast"(%148) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %152 = "arith.andi"(%150, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %153 = "arith.andi"(%151, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %154 = "tt.load"(%128, %152, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %155 = "tt.load"(<<UNKNOWN SSA VALUE>>, %153, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %156 = "triton_gpu.convert_layout"(%143) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %157 = "triton_gpu.convert_layout"(%154) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %158 = "triton_gpu.convert_layout"(%132) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %159 = "tt.dot"(%156, %157, %158) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %160 = "builtin.unrealized_conversion_cast"(%159) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %161 = "tt.dot"(%144, %155, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %162 = "tt.addptr"(%130, %7) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %163 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %164 = "tt.addptr"(%128, %92) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %165 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%160, %162, %164) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> ()
    "scf.yield"(%161, %163, %165) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %97 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %98 = "arith.cmpi"(%24, %96) <{predicate = 2 : i64}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %99 = "arith.cmpi"(%25, %97) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %100 = "tt.load"(%74, %98, %1) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %101 = "tt.load"(%75, %99, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %102 = "arith.sitofp"(%arg4) : (i32) -> f32
  %103 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %104 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32>
  %105 = "arith.mulf"(%95#0, %104) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %106 = "arith.sitofp"(%arg5) : (i32) -> f16
  %107 = "tt.splat"(%106) : (f16) -> tensor<32xf16>
  %108 = "arith.mulf"(%101, %107) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %109 = "tt.expand_dims"(%108) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %110 = "arith.extf"(%109) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %111 = "tt.broadcast"(%110) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %112 = "arith.addf"(%105, %111) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %113 = "arith.truncf"(%112) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %114 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %115 = "arith.muli"(%114, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %116 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %117 = "tt.addptr"(%116, %115) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %118 = "tt.broadcast"(%117) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %119 = "tt.addptr"(%118, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %120 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %121 = "arith.cmpi"(%29, %120) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %122 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %123 = "arith.cmpi"(%60, %122) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %124 = "tt.broadcast"(%121) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %125 = "tt.broadcast"(%123) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %126 = "arith.andi"(%124, %125) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%119, %113, %126) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.mulf'(0x555d5be99df0) {
  %105 = "arith.mulf"(%95#0, %104) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'arith.mulf -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::arith::MulFOp>"
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::detail::MulFOpGenericAdaptorBase::Properties)
    ** Insert  : 'arith.mulf'(0x555d5bedc460)
    ** Replace : 'arith.mulf'(0x555d5be99df0)
"{anonymous}::GenericOpPattern<mlir::arith::MulFOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'arith.mulf'(0x555d5bedc460) {
      %105 = "arith.mulf"(%94#0, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.yield' op must be the last operation in the parent block
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %128 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %129 = "builtin.unrealized_conversion_cast"(%128) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %130 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %131 = "builtin.unrealized_conversion_cast"(%130) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %132 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %133 = "builtin.unrealized_conversion_cast"(%132) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %134 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %135 = "arith.subi"(%arg8, %134) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %136 = "tt.splat"(%135) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %137 = "tt.splat"(%135) : (i32) -> tensor<1x32xi32>
    %138 = "arith.cmpi"(%36, %136) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %139 = "arith.cmpi"(%37, %137) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %140 = "tt.broadcast"(%138) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %141 = "tt.broadcast"(%139) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %142 = "arith.andi"(%83, %140) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %143 = "arith.andi"(%84, %141) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %144 = "tt.load"(%131, %142, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %145 = "tt.load"(<<UNKNOWN SSA VALUE>>, %143, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %146 = "tt.splat"(%135) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %147 = "tt.splat"(%135) : (i32) -> tensor<32x1xi32>
    %148 = "arith.cmpi"(%51, %146) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = "arith.cmpi"(%52, %147) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %150 = "tt.broadcast"(%148) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %151 = "builtin.unrealized_conversion_cast"(%150) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %152 = "tt.broadcast"(%149) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %153 = "arith.andi"(%151, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %154 = "arith.andi"(%152, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %155 = "tt.load"(%129, %153, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %156 = "tt.load"(<<UNKNOWN SSA VALUE>>, %154, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %157 = "triton_gpu.convert_layout"(%144) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %158 = "triton_gpu.convert_layout"(%155) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %159 = "triton_gpu.convert_layout"(%133) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %160 = "tt.dot"(%157, %158, %159) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %161 = "builtin.unrealized_conversion_cast"(%160) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %162 = "tt.dot"(%145, %156, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %163 = "tt.addptr"(%131, %7) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %164 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %165 = "tt.addptr"(%129, %92) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %166 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%161, %163, %165) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> ()
    "scf.yield"(%162, %164, %166) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %97 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %98 = "arith.cmpi"(%24, %96) <{predicate = 2 : i64}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %99 = "arith.cmpi"(%25, %97) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %100 = "tt.load"(%74, %98, %1) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %101 = "tt.load"(%75, %99, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %102 = "arith.sitofp"(%arg4) : (i32) -> f32
  %103 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %104 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32>
  %105 = "arith.mulf"(%94#0, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %106 = "arith.mulf"(%95#0, %104) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %107 = "arith.sitofp"(%arg5) : (i32) -> f16
  %108 = "tt.splat"(%107) : (f16) -> tensor<32xf16>
  %109 = "arith.mulf"(%101, %108) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %110 = "tt.expand_dims"(%109) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %111 = "arith.extf"(%110) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %112 = "tt.broadcast"(%111) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %113 = "arith.addf"(%106, %112) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %114 = "arith.truncf"(%113) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %115 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %116 = "arith.muli"(%115, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %117 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %118 = "tt.addptr"(%117, %116) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %119 = "tt.broadcast"(%118) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %120 = "tt.addptr"(%119, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %121 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %122 = "arith.cmpi"(%29, %121) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %123 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %124 = "arith.cmpi"(%60, %123) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %125 = "tt.broadcast"(%122) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %126 = "tt.broadcast"(%124) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %127 = "arith.andi"(%125, %126) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%120, %114, %127) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.sitofp'(0x555d5be9dff0) {
  %107 = "arith.sitofp"(%arg5) : (i32) -> f16

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.splat'(0x555d5be99f10) {
  %108 = "tt.splat"(%107) : (f16) -> tensor<32xf16>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.splat -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::triton::SplatOp>"
    ** Insert  : 'tt.splat'(0x555d5bedf2f0)
    ** Replace : 'tt.splat'(0x555d5be99f10)
"{anonymous}::GenericOpPattern<mlir::triton::SplatOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.splat'(0x555d5bedf2f0) {
      %108 = "tt.splat"(%107) : (f16) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.yield' op must be the last operation in the parent block
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %129 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %130 = "builtin.unrealized_conversion_cast"(%129) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %131 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %132 = "builtin.unrealized_conversion_cast"(%131) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %133 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %134 = "builtin.unrealized_conversion_cast"(%133) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %135 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %136 = "arith.subi"(%arg8, %135) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %137 = "tt.splat"(%136) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %138 = "tt.splat"(%136) : (i32) -> tensor<1x32xi32>
    %139 = "arith.cmpi"(%36, %137) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %140 = "arith.cmpi"(%37, %138) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %141 = "tt.broadcast"(%139) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %142 = "tt.broadcast"(%140) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %143 = "arith.andi"(%83, %141) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %144 = "arith.andi"(%84, %142) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %145 = "tt.load"(%132, %143, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %146 = "tt.load"(<<UNKNOWN SSA VALUE>>, %144, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %147 = "tt.splat"(%136) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %148 = "tt.splat"(%136) : (i32) -> tensor<32x1xi32>
    %149 = "arith.cmpi"(%51, %147) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %150 = "arith.cmpi"(%52, %148) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %151 = "tt.broadcast"(%149) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %152 = "builtin.unrealized_conversion_cast"(%151) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %153 = "tt.broadcast"(%150) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %154 = "arith.andi"(%152, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %155 = "arith.andi"(%153, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %156 = "tt.load"(%130, %154, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %157 = "tt.load"(<<UNKNOWN SSA VALUE>>, %155, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %158 = "triton_gpu.convert_layout"(%145) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %159 = "triton_gpu.convert_layout"(%156) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %160 = "triton_gpu.convert_layout"(%134) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %161 = "tt.dot"(%158, %159, %160) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %162 = "builtin.unrealized_conversion_cast"(%161) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %163 = "tt.dot"(%146, %157, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %164 = "tt.addptr"(%132, %7) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %165 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %166 = "tt.addptr"(%130, %92) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %167 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%162, %164, %166) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> ()
    "scf.yield"(%163, %165, %167) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %97 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %98 = "arith.cmpi"(%24, %96) <{predicate = 2 : i64}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %99 = "arith.cmpi"(%25, %97) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %100 = "tt.load"(%74, %98, %1) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %101 = "tt.load"(%75, %99, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %102 = "arith.sitofp"(%arg4) : (i32) -> f32
  %103 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %104 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32>
  %105 = "arith.mulf"(%94#0, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %106 = "arith.mulf"(%95#0, %104) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %107 = "arith.sitofp"(%arg5) : (i32) -> f16
  %108 = "tt.splat"(%107) : (f16) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %109 = "tt.splat"(%107) : (f16) -> tensor<32xf16>
  %110 = "arith.mulf"(%101, %109) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %111 = "tt.expand_dims"(%110) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %112 = "arith.extf"(%111) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %113 = "tt.broadcast"(%112) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %114 = "arith.addf"(%106, %113) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %115 = "arith.truncf"(%114) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %116 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %117 = "arith.muli"(%116, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %118 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %119 = "tt.addptr"(%118, %117) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %120 = "tt.broadcast"(%119) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %121 = "tt.addptr"(%120, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %122 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %123 = "arith.cmpi"(%29, %122) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %124 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %125 = "arith.cmpi"(%60, %124) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %126 = "tt.broadcast"(%123) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %127 = "tt.broadcast"(%125) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %128 = "arith.andi"(%126, %127) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%121, %115, %128) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.mulf'(0x555d5be99fa0) {
  %110 = "arith.mulf"(%101, %109) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'arith.mulf -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::arith::MulFOp>"
    ** Insert  : 'arith.mulf'(0x555d5bedf980)
    ** Replace : 'arith.mulf'(0x555d5be99fa0)
"{anonymous}::GenericOpPattern<mlir::arith::MulFOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'arith.mulf'(0x555d5bedf980) {
      %110 = "arith.mulf"(%100, %108) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.yield' op must be the last operation in the parent block
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %130 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %131 = "builtin.unrealized_conversion_cast"(%130) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %132 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %133 = "builtin.unrealized_conversion_cast"(%132) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %134 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %135 = "builtin.unrealized_conversion_cast"(%134) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %136 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %137 = "arith.subi"(%arg8, %136) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %138 = "tt.splat"(%137) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %139 = "tt.splat"(%137) : (i32) -> tensor<1x32xi32>
    %140 = "arith.cmpi"(%36, %138) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %141 = "arith.cmpi"(%37, %139) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %142 = "tt.broadcast"(%140) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %143 = "tt.broadcast"(%141) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %144 = "arith.andi"(%83, %142) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %145 = "arith.andi"(%84, %143) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %146 = "tt.load"(%133, %144, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %147 = "tt.load"(<<UNKNOWN SSA VALUE>>, %145, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %148 = "tt.splat"(%137) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = "tt.splat"(%137) : (i32) -> tensor<32x1xi32>
    %150 = "arith.cmpi"(%51, %148) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %151 = "arith.cmpi"(%52, %149) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %152 = "tt.broadcast"(%150) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %153 = "builtin.unrealized_conversion_cast"(%152) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %154 = "tt.broadcast"(%151) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %155 = "arith.andi"(%153, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %156 = "arith.andi"(%154, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %157 = "tt.load"(%131, %155, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %158 = "tt.load"(<<UNKNOWN SSA VALUE>>, %156, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %159 = "triton_gpu.convert_layout"(%146) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %160 = "triton_gpu.convert_layout"(%157) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %161 = "triton_gpu.convert_layout"(%135) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %162 = "tt.dot"(%159, %160, %161) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %163 = "builtin.unrealized_conversion_cast"(%162) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %164 = "tt.dot"(%147, %158, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %165 = "tt.addptr"(%133, %7) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %166 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %167 = "tt.addptr"(%131, %92) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %168 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%163, %165, %167) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> ()
    "scf.yield"(%164, %166, %168) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %97 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %98 = "arith.cmpi"(%24, %96) <{predicate = 2 : i64}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %99 = "arith.cmpi"(%25, %97) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %100 = "tt.load"(%74, %98, %1) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %101 = "tt.load"(%75, %99, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %102 = "arith.sitofp"(%arg4) : (i32) -> f32
  %103 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %104 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32>
  %105 = "arith.mulf"(%94#0, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %106 = "arith.mulf"(%95#0, %104) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %107 = "arith.sitofp"(%arg5) : (i32) -> f16
  %108 = "tt.splat"(%107) : (f16) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %109 = "tt.splat"(%107) : (f16) -> tensor<32xf16>
  %110 = "arith.mulf"(%100, %108) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %111 = "arith.mulf"(%101, %109) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %112 = "tt.expand_dims"(%111) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %113 = "arith.extf"(%112) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %114 = "tt.broadcast"(%113) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %115 = "arith.addf"(%106, %114) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %116 = "arith.truncf"(%115) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %117 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %118 = "arith.muli"(%117, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %119 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %120 = "tt.addptr"(%119, %118) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %121 = "tt.broadcast"(%120) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %122 = "tt.addptr"(%121, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %123 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %124 = "arith.cmpi"(%29, %123) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %125 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %126 = "arith.cmpi"(%60, %125) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %127 = "tt.broadcast"(%124) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %128 = "tt.broadcast"(%126) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %129 = "arith.andi"(%127, %128) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%122, %116, %129) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.expand_dims'(0x555d5be9a090) {
  %112 = "tt.expand_dims"(%111) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.expand_dims -> ()' {
Trying to match "{anonymous}::TritonExpandDimsPattern"
    ** Insert  : 'triton_gpu.convert_layout'(0x555d5bedc2d0)
    ** Insert  : 'tt.expand_dims'(0x555d5bedf8f0)
    ** Replace : 'tt.expand_dims'(0x555d5be9a090)
"{anonymous}::TritonExpandDimsPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'triton_gpu.convert_layout'(0x555d5bedc2d0) {
      %112 = "triton_gpu.convert_layout"(%110) : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'tt.expand_dims'(0x555d5bedf8f0) {
      %113 = "tt.expand_dims"(%112) <{axis = 0 : i32}> : (tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.yield' op must be the last operation in the parent block
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %132 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %133 = "builtin.unrealized_conversion_cast"(%132) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %134 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %135 = "builtin.unrealized_conversion_cast"(%134) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %136 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %137 = "builtin.unrealized_conversion_cast"(%136) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %138 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %139 = "arith.subi"(%arg8, %138) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %140 = "tt.splat"(%139) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %141 = "tt.splat"(%139) : (i32) -> tensor<1x32xi32>
    %142 = "arith.cmpi"(%36, %140) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %143 = "arith.cmpi"(%37, %141) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %144 = "tt.broadcast"(%142) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %145 = "tt.broadcast"(%143) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %146 = "arith.andi"(%83, %144) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %147 = "arith.andi"(%84, %145) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %148 = "tt.load"(%135, %146, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = "tt.load"(<<UNKNOWN SSA VALUE>>, %147, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %150 = "tt.splat"(%139) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %151 = "tt.splat"(%139) : (i32) -> tensor<32x1xi32>
    %152 = "arith.cmpi"(%51, %150) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %153 = "arith.cmpi"(%52, %151) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %154 = "tt.broadcast"(%152) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %155 = "builtin.unrealized_conversion_cast"(%154) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %156 = "tt.broadcast"(%153) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %157 = "arith.andi"(%155, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %158 = "arith.andi"(%156, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %159 = "tt.load"(%133, %157, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %160 = "tt.load"(<<UNKNOWN SSA VALUE>>, %158, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %161 = "triton_gpu.convert_layout"(%148) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %162 = "triton_gpu.convert_layout"(%159) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %163 = "triton_gpu.convert_layout"(%137) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %164 = "tt.dot"(%161, %162, %163) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %165 = "builtin.unrealized_conversion_cast"(%164) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %166 = "tt.dot"(%149, %160, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %167 = "tt.addptr"(%135, %7) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %168 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %169 = "tt.addptr"(%133, %92) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %170 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%165, %167, %169) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> ()
    "scf.yield"(%166, %168, %170) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %97 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %98 = "arith.cmpi"(%24, %96) <{predicate = 2 : i64}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %99 = "arith.cmpi"(%25, %97) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %100 = "tt.load"(%74, %98, %1) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %101 = "tt.load"(%75, %99, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %102 = "arith.sitofp"(%arg4) : (i32) -> f32
  %103 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %104 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32>
  %105 = "arith.mulf"(%94#0, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %106 = "arith.mulf"(%95#0, %104) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %107 = "arith.sitofp"(%arg5) : (i32) -> f16
  %108 = "tt.splat"(%107) : (f16) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %109 = "tt.splat"(%107) : (f16) -> tensor<32xf16>
  %110 = "arith.mulf"(%100, %108) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %111 = "arith.mulf"(%101, %109) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %112 = "triton_gpu.convert_layout"(%110) : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %113 = "tt.expand_dims"(%112) <{axis = 0 : i32}> : (tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %114 = "tt.expand_dims"(%111) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %115 = "arith.extf"(%114) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %116 = "tt.broadcast"(%115) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %117 = "arith.addf"(%106, %116) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %118 = "arith.truncf"(%117) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %119 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %120 = "arith.muli"(%119, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %121 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %122 = "tt.addptr"(%121, %120) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %123 = "tt.broadcast"(%122) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %124 = "tt.addptr"(%123, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %125 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %126 = "arith.cmpi"(%29, %125) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %127 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %128 = "arith.cmpi"(%60, %127) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %129 = "tt.broadcast"(%126) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %130 = "tt.broadcast"(%128) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %131 = "arith.andi"(%129, %130) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%124, %118, %131) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.extf'(0x555d5bea0a50) {
  %115 = "arith.extf"(%114) : (tensor<1x32xf16>) -> tensor<1x32xf32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'arith.extf -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::arith::ExtFOp>"
    ** Insert  : 'arith.extf'(0x555d5bedfb90)
    ** Replace : 'arith.extf'(0x555d5bea0a50)
"{anonymous}::GenericOpPattern<mlir::arith::ExtFOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'arith.extf'(0x555d5bedfb90) {
      %116 = "arith.extf"(%114) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.yield' op must be the last operation in the parent block
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %134 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %135 = "builtin.unrealized_conversion_cast"(%134) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %136 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %137 = "builtin.unrealized_conversion_cast"(%136) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %138 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %139 = "builtin.unrealized_conversion_cast"(%138) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %140 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %141 = "arith.subi"(%arg8, %140) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %142 = "tt.splat"(%141) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %143 = "tt.splat"(%141) : (i32) -> tensor<1x32xi32>
    %144 = "arith.cmpi"(%36, %142) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %145 = "arith.cmpi"(%37, %143) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %146 = "tt.broadcast"(%144) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %147 = "tt.broadcast"(%145) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %148 = "arith.andi"(%83, %146) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = "arith.andi"(%84, %147) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %150 = "tt.load"(%137, %148, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %151 = "tt.load"(<<UNKNOWN SSA VALUE>>, %149, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %152 = "tt.splat"(%141) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %153 = "tt.splat"(%141) : (i32) -> tensor<32x1xi32>
    %154 = "arith.cmpi"(%51, %152) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %155 = "arith.cmpi"(%52, %153) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %156 = "tt.broadcast"(%154) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %157 = "builtin.unrealized_conversion_cast"(%156) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %158 = "tt.broadcast"(%155) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %159 = "arith.andi"(%157, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %160 = "arith.andi"(%158, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %161 = "tt.load"(%135, %159, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %162 = "tt.load"(<<UNKNOWN SSA VALUE>>, %160, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %163 = "triton_gpu.convert_layout"(%150) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %164 = "triton_gpu.convert_layout"(%161) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %165 = "triton_gpu.convert_layout"(%139) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %166 = "tt.dot"(%163, %164, %165) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %167 = "builtin.unrealized_conversion_cast"(%166) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %168 = "tt.dot"(%151, %162, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %169 = "tt.addptr"(%137, %7) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %170 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %171 = "tt.addptr"(%135, %92) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %172 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%167, %169, %171) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> ()
    "scf.yield"(%168, %170, %172) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %97 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %98 = "arith.cmpi"(%24, %96) <{predicate = 2 : i64}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %99 = "arith.cmpi"(%25, %97) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %100 = "tt.load"(%74, %98, %1) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %101 = "tt.load"(%75, %99, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %102 = "arith.sitofp"(%arg4) : (i32) -> f32
  %103 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %104 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32>
  %105 = "arith.mulf"(%94#0, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %106 = "arith.mulf"(%95#0, %104) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %107 = "arith.sitofp"(%arg5) : (i32) -> f16
  %108 = "tt.splat"(%107) : (f16) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %109 = "tt.splat"(%107) : (f16) -> tensor<32xf16>
  %110 = "arith.mulf"(%100, %108) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %111 = "arith.mulf"(%101, %109) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %112 = "triton_gpu.convert_layout"(%110) : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %113 = "tt.expand_dims"(%112) <{axis = 0 : i32}> : (tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %114 = "builtin.unrealized_conversion_cast"(%113) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %115 = "tt.expand_dims"(%111) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %116 = "arith.extf"(%114) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %117 = "arith.extf"(%115) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %118 = "tt.broadcast"(%117) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %119 = "arith.addf"(%106, %118) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %120 = "arith.truncf"(%119) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %121 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %122 = "arith.muli"(%121, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %123 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %124 = "tt.addptr"(%123, %122) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %125 = "tt.broadcast"(%124) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %126 = "tt.addptr"(%125, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %127 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %128 = "arith.cmpi"(%29, %127) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %129 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %130 = "arith.cmpi"(%60, %129) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %131 = "tt.broadcast"(%128) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %132 = "tt.broadcast"(%130) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %133 = "arith.andi"(%131, %132) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%126, %120, %133) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.broadcast'(0x555d5bea0ae0) {
  %118 = "tt.broadcast"(%117) : (tensor<1x32xf32>) -> tensor<32x32xf32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.broadcast -> ()' {
Trying to match "{anonymous}::TritonBroadcastPattern"
    ** Insert  : 'tt.broadcast'(0x555d5beddb30)
    ** Replace : 'tt.broadcast'(0x555d5bea0ae0)
"{anonymous}::TritonBroadcastPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.broadcast'(0x555d5beddb30) {
      %118 = "tt.broadcast"(%116) : (tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.yield' op must be the last operation in the parent block
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %135 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %136 = "builtin.unrealized_conversion_cast"(%135) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %137 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %138 = "builtin.unrealized_conversion_cast"(%137) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %139 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %140 = "builtin.unrealized_conversion_cast"(%139) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %141 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %142 = "arith.subi"(%arg8, %141) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %143 = "tt.splat"(%142) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %144 = "tt.splat"(%142) : (i32) -> tensor<1x32xi32>
    %145 = "arith.cmpi"(%36, %143) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %146 = "arith.cmpi"(%37, %144) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %147 = "tt.broadcast"(%145) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %148 = "tt.broadcast"(%146) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %149 = "arith.andi"(%83, %147) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %150 = "arith.andi"(%84, %148) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %151 = "tt.load"(%138, %149, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %152 = "tt.load"(<<UNKNOWN SSA VALUE>>, %150, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %153 = "tt.splat"(%142) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %154 = "tt.splat"(%142) : (i32) -> tensor<32x1xi32>
    %155 = "arith.cmpi"(%51, %153) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %156 = "arith.cmpi"(%52, %154) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %157 = "tt.broadcast"(%155) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %158 = "builtin.unrealized_conversion_cast"(%157) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %159 = "tt.broadcast"(%156) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %160 = "arith.andi"(%158, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %161 = "arith.andi"(%159, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %162 = "tt.load"(%136, %160, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %163 = "tt.load"(<<UNKNOWN SSA VALUE>>, %161, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %164 = "triton_gpu.convert_layout"(%151) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %165 = "triton_gpu.convert_layout"(%162) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %166 = "triton_gpu.convert_layout"(%140) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %167 = "tt.dot"(%164, %165, %166) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %168 = "builtin.unrealized_conversion_cast"(%167) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %169 = "tt.dot"(%152, %163, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %170 = "tt.addptr"(%138, %7) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %171 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %172 = "tt.addptr"(%136, %92) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %173 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%168, %170, %172) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> ()
    "scf.yield"(%169, %171, %173) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %97 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %98 = "arith.cmpi"(%24, %96) <{predicate = 2 : i64}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %99 = "arith.cmpi"(%25, %97) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %100 = "tt.load"(%74, %98, %1) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %101 = "tt.load"(%75, %99, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %102 = "arith.sitofp"(%arg4) : (i32) -> f32
  %103 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %104 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32>
  %105 = "arith.mulf"(%94#0, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %106 = "arith.mulf"(%95#0, %104) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %107 = "arith.sitofp"(%arg5) : (i32) -> f16
  %108 = "tt.splat"(%107) : (f16) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %109 = "tt.splat"(%107) : (f16) -> tensor<32xf16>
  %110 = "arith.mulf"(%100, %108) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %111 = "arith.mulf"(%101, %109) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %112 = "triton_gpu.convert_layout"(%110) : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %113 = "tt.expand_dims"(%112) <{axis = 0 : i32}> : (tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %114 = "builtin.unrealized_conversion_cast"(%113) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %115 = "tt.expand_dims"(%111) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %116 = "arith.extf"(%114) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %117 = "arith.extf"(%115) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %118 = "tt.broadcast"(%116) : (tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %119 = "tt.broadcast"(%117) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %120 = "arith.addf"(%106, %119) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %121 = "arith.truncf"(%120) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %122 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %123 = "arith.muli"(%122, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %124 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %125 = "tt.addptr"(%124, %123) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %126 = "tt.broadcast"(%125) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %127 = "tt.addptr"(%126, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %128 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %129 = "arith.cmpi"(%29, %128) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %130 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %131 = "arith.cmpi"(%60, %130) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %132 = "tt.broadcast"(%129) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %133 = "tt.broadcast"(%131) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %134 = "arith.andi"(%132, %133) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%127, %121, %134) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.addf'(0x555d5bea0b70) {
  %120 = "arith.addf"(%106, %119) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'arith.addf -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::arith::AddFOp>"
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::detail::AddFOpGenericAdaptorBase::Properties)
    ** Insert  : 'arith.addf'(0x555d5bedd5d0)
    ** Replace : 'arith.addf'(0x555d5bea0b70)
"{anonymous}::GenericOpPattern<mlir::arith::AddFOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'arith.addf'(0x555d5bedd5d0) {
      %120 = "arith.addf"(%105, %118) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.yield' op must be the last operation in the parent block
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %136 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %137 = "builtin.unrealized_conversion_cast"(%136) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %138 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %139 = "builtin.unrealized_conversion_cast"(%138) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %140 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %141 = "builtin.unrealized_conversion_cast"(%140) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %142 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %143 = "arith.subi"(%arg8, %142) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %144 = "tt.splat"(%143) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %145 = "tt.splat"(%143) : (i32) -> tensor<1x32xi32>
    %146 = "arith.cmpi"(%36, %144) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %147 = "arith.cmpi"(%37, %145) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %148 = "tt.broadcast"(%146) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = "tt.broadcast"(%147) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %150 = "arith.andi"(%83, %148) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %151 = "arith.andi"(%84, %149) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %152 = "tt.load"(%139, %150, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %153 = "tt.load"(<<UNKNOWN SSA VALUE>>, %151, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %154 = "tt.splat"(%143) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %155 = "tt.splat"(%143) : (i32) -> tensor<32x1xi32>
    %156 = "arith.cmpi"(%51, %154) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %157 = "arith.cmpi"(%52, %155) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %158 = "tt.broadcast"(%156) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %159 = "builtin.unrealized_conversion_cast"(%158) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %160 = "tt.broadcast"(%157) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %161 = "arith.andi"(%159, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %162 = "arith.andi"(%160, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %163 = "tt.load"(%137, %161, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %164 = "tt.load"(<<UNKNOWN SSA VALUE>>, %162, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %165 = "triton_gpu.convert_layout"(%152) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %166 = "triton_gpu.convert_layout"(%163) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %167 = "triton_gpu.convert_layout"(%141) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %168 = "tt.dot"(%165, %166, %167) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %169 = "builtin.unrealized_conversion_cast"(%168) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %170 = "tt.dot"(%153, %164, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %171 = "tt.addptr"(%139, %7) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %172 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %173 = "tt.addptr"(%137, %92) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %174 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%169, %171, %173) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> ()
    "scf.yield"(%170, %172, %174) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %97 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %98 = "arith.cmpi"(%24, %96) <{predicate = 2 : i64}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %99 = "arith.cmpi"(%25, %97) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %100 = "tt.load"(%74, %98, %1) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %101 = "tt.load"(%75, %99, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %102 = "arith.sitofp"(%arg4) : (i32) -> f32
  %103 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %104 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32>
  %105 = "arith.mulf"(%94#0, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %106 = "arith.mulf"(%95#0, %104) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %107 = "arith.sitofp"(%arg5) : (i32) -> f16
  %108 = "tt.splat"(%107) : (f16) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %109 = "tt.splat"(%107) : (f16) -> tensor<32xf16>
  %110 = "arith.mulf"(%100, %108) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %111 = "arith.mulf"(%101, %109) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %112 = "triton_gpu.convert_layout"(%110) : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %113 = "tt.expand_dims"(%112) <{axis = 0 : i32}> : (tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %114 = "builtin.unrealized_conversion_cast"(%113) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %115 = "tt.expand_dims"(%111) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %116 = "arith.extf"(%114) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %117 = "arith.extf"(%115) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %118 = "tt.broadcast"(%116) : (tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %119 = "tt.broadcast"(%117) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %120 = "arith.addf"(%105, %118) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %121 = "arith.addf"(%106, %119) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %122 = "arith.truncf"(%121) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %123 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %124 = "arith.muli"(%123, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %125 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %126 = "tt.addptr"(%125, %124) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %127 = "tt.broadcast"(%126) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %128 = "tt.addptr"(%127, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %129 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %130 = "arith.cmpi"(%29, %129) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %131 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %132 = "arith.cmpi"(%60, %131) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %133 = "tt.broadcast"(%130) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %134 = "tt.broadcast"(%132) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %135 = "arith.andi"(%133, %134) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%128, %122, %135) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.truncf'(0x555d5bea0c20) {
  %122 = "arith.truncf"(%121) : (tensor<32x32xf32>) -> tensor<32x32xf16>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'arith.truncf -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::arith::TruncFOp>"
    ** Insert  : 'arith.truncf'(0x555d5bee0470)
    ** Replace : 'arith.truncf'(0x555d5bea0c20)
"{anonymous}::GenericOpPattern<mlir::arith::TruncFOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'arith.truncf'(0x555d5bee0470) {
      %122 = "arith.truncf"(%120) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.yield' op must be the last operation in the parent block
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %137 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %138 = "builtin.unrealized_conversion_cast"(%137) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %139 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %140 = "builtin.unrealized_conversion_cast"(%139) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %141 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %142 = "builtin.unrealized_conversion_cast"(%141) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %143 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %144 = "arith.subi"(%arg8, %143) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %145 = "tt.splat"(%144) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %146 = "tt.splat"(%144) : (i32) -> tensor<1x32xi32>
    %147 = "arith.cmpi"(%36, %145) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %148 = "arith.cmpi"(%37, %146) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %149 = "tt.broadcast"(%147) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %150 = "tt.broadcast"(%148) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %151 = "arith.andi"(%83, %149) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %152 = "arith.andi"(%84, %150) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %153 = "tt.load"(%140, %151, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %154 = "tt.load"(<<UNKNOWN SSA VALUE>>, %152, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %155 = "tt.splat"(%144) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %156 = "tt.splat"(%144) : (i32) -> tensor<32x1xi32>
    %157 = "arith.cmpi"(%51, %155) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %158 = "arith.cmpi"(%52, %156) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %159 = "tt.broadcast"(%157) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %160 = "builtin.unrealized_conversion_cast"(%159) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %161 = "tt.broadcast"(%158) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %162 = "arith.andi"(%160, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %163 = "arith.andi"(%161, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %164 = "tt.load"(%138, %162, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %165 = "tt.load"(<<UNKNOWN SSA VALUE>>, %163, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %166 = "triton_gpu.convert_layout"(%153) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %167 = "triton_gpu.convert_layout"(%164) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %168 = "triton_gpu.convert_layout"(%142) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %169 = "tt.dot"(%166, %167, %168) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %170 = "builtin.unrealized_conversion_cast"(%169) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %171 = "tt.dot"(%154, %165, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %172 = "tt.addptr"(%140, %7) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %173 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %174 = "tt.addptr"(%138, %92) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %175 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%170, %172, %174) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> ()
    "scf.yield"(%171, %173, %175) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %97 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %98 = "arith.cmpi"(%24, %96) <{predicate = 2 : i64}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %99 = "arith.cmpi"(%25, %97) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %100 = "tt.load"(%74, %98, %1) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %101 = "tt.load"(%75, %99, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %102 = "arith.sitofp"(%arg4) : (i32) -> f32
  %103 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %104 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32>
  %105 = "arith.mulf"(%94#0, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %106 = "arith.mulf"(%95#0, %104) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %107 = "arith.sitofp"(%arg5) : (i32) -> f16
  %108 = "tt.splat"(%107) : (f16) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %109 = "tt.splat"(%107) : (f16) -> tensor<32xf16>
  %110 = "arith.mulf"(%100, %108) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %111 = "arith.mulf"(%101, %109) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %112 = "triton_gpu.convert_layout"(%110) : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %113 = "tt.expand_dims"(%112) <{axis = 0 : i32}> : (tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %114 = "builtin.unrealized_conversion_cast"(%113) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %115 = "tt.expand_dims"(%111) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %116 = "arith.extf"(%114) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %117 = "arith.extf"(%115) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %118 = "tt.broadcast"(%116) : (tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %119 = "tt.broadcast"(%117) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %120 = "arith.addf"(%105, %118) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %121 = "arith.addf"(%106, %119) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %122 = "arith.truncf"(%120) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %123 = "arith.truncf"(%121) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %124 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %125 = "arith.muli"(%124, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %126 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %127 = "tt.addptr"(%126, %125) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %128 = "tt.broadcast"(%127) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %129 = "tt.addptr"(%128, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %130 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %131 = "arith.cmpi"(%29, %130) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %132 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %133 = "arith.cmpi"(%60, %132) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %134 = "tt.broadcast"(%131) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %135 = "tt.broadcast"(%133) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %136 = "arith.andi"(%134, %135) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%129, %123, %136) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.splat'(0x555d5bea0cc0) {
  %124 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.splat -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::triton::SplatOp>"
    ** Insert  : 'tt.splat'(0x555d5bedf120)
    ** Replace : 'tt.splat'(0x555d5bea0cc0)
"{anonymous}::GenericOpPattern<mlir::triton::SplatOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.splat'(0x555d5bedf120) {
      %124 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.yield' op must be the last operation in the parent block
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %138 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %139 = "builtin.unrealized_conversion_cast"(%138) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %140 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %141 = "builtin.unrealized_conversion_cast"(%140) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %142 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %143 = "builtin.unrealized_conversion_cast"(%142) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %144 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %145 = "arith.subi"(%arg8, %144) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %146 = "tt.splat"(%145) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %147 = "tt.splat"(%145) : (i32) -> tensor<1x32xi32>
    %148 = "arith.cmpi"(%36, %146) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = "arith.cmpi"(%37, %147) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %150 = "tt.broadcast"(%148) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %151 = "tt.broadcast"(%149) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %152 = "arith.andi"(%83, %150) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %153 = "arith.andi"(%84, %151) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %154 = "tt.load"(%141, %152, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %155 = "tt.load"(<<UNKNOWN SSA VALUE>>, %153, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %156 = "tt.splat"(%145) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %157 = "tt.splat"(%145) : (i32) -> tensor<32x1xi32>
    %158 = "arith.cmpi"(%51, %156) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %159 = "arith.cmpi"(%52, %157) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %160 = "tt.broadcast"(%158) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %161 = "builtin.unrealized_conversion_cast"(%160) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %162 = "tt.broadcast"(%159) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %163 = "arith.andi"(%161, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %164 = "arith.andi"(%162, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %165 = "tt.load"(%139, %163, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %166 = "tt.load"(<<UNKNOWN SSA VALUE>>, %164, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %167 = "triton_gpu.convert_layout"(%154) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %168 = "triton_gpu.convert_layout"(%165) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %169 = "triton_gpu.convert_layout"(%143) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %170 = "tt.dot"(%167, %168, %169) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %171 = "builtin.unrealized_conversion_cast"(%170) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %172 = "tt.dot"(%155, %166, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %173 = "tt.addptr"(%141, %7) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %174 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %175 = "tt.addptr"(%139, %92) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %176 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%171, %173, %175) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> ()
    "scf.yield"(%172, %174, %176) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %97 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %98 = "arith.cmpi"(%24, %96) <{predicate = 2 : i64}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %99 = "arith.cmpi"(%25, %97) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %100 = "tt.load"(%74, %98, %1) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %101 = "tt.load"(%75, %99, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %102 = "arith.sitofp"(%arg4) : (i32) -> f32
  %103 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %104 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32>
  %105 = "arith.mulf"(%94#0, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %106 = "arith.mulf"(%95#0, %104) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %107 = "arith.sitofp"(%arg5) : (i32) -> f16
  %108 = "tt.splat"(%107) : (f16) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %109 = "tt.splat"(%107) : (f16) -> tensor<32xf16>
  %110 = "arith.mulf"(%100, %108) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %111 = "arith.mulf"(%101, %109) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %112 = "triton_gpu.convert_layout"(%110) : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %113 = "tt.expand_dims"(%112) <{axis = 0 : i32}> : (tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %114 = "builtin.unrealized_conversion_cast"(%113) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %115 = "tt.expand_dims"(%111) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %116 = "arith.extf"(%114) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %117 = "arith.extf"(%115) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %118 = "tt.broadcast"(%116) : (tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %119 = "tt.broadcast"(%117) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %120 = "arith.addf"(%105, %118) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %121 = "arith.addf"(%106, %119) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %122 = "arith.truncf"(%120) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %123 = "arith.truncf"(%121) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %124 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %125 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %126 = "arith.muli"(%125, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %127 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %128 = "tt.addptr"(%127, %126) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %129 = "tt.broadcast"(%128) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %130 = "tt.addptr"(%129, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %131 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %132 = "arith.cmpi"(%29, %131) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %133 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %134 = "arith.cmpi"(%60, %133) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %135 = "tt.broadcast"(%132) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %136 = "tt.broadcast"(%134) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %137 = "arith.andi"(%135, %136) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%130, %123, %137) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.muli'(0x555d5bea0d50) {
  %126 = "arith.muli"(%125, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'arith.muli -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::arith::MulIOp>"
    ** Insert  : 'arith.muli'(0x555d5bedec50)
    ** Replace : 'arith.muli'(0x555d5bea0d50)
"{anonymous}::GenericOpPattern<mlir::arith::MulIOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'arith.muli'(0x555d5bedec50) {
      %126 = "arith.muli"(%124, %28) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.yield' op must be the last operation in the parent block
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %139 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %140 = "builtin.unrealized_conversion_cast"(%139) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %141 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %142 = "builtin.unrealized_conversion_cast"(%141) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %143 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %144 = "builtin.unrealized_conversion_cast"(%143) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %145 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %146 = "arith.subi"(%arg8, %145) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %147 = "tt.splat"(%146) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %148 = "tt.splat"(%146) : (i32) -> tensor<1x32xi32>
    %149 = "arith.cmpi"(%36, %147) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %150 = "arith.cmpi"(%37, %148) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %151 = "tt.broadcast"(%149) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %152 = "tt.broadcast"(%150) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %153 = "arith.andi"(%83, %151) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %154 = "arith.andi"(%84, %152) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %155 = "tt.load"(%142, %153, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %156 = "tt.load"(<<UNKNOWN SSA VALUE>>, %154, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %157 = "tt.splat"(%146) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %158 = "tt.splat"(%146) : (i32) -> tensor<32x1xi32>
    %159 = "arith.cmpi"(%51, %157) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %160 = "arith.cmpi"(%52, %158) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %161 = "tt.broadcast"(%159) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %162 = "builtin.unrealized_conversion_cast"(%161) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %163 = "tt.broadcast"(%160) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %164 = "arith.andi"(%162, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %165 = "arith.andi"(%163, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %166 = "tt.load"(%140, %164, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %167 = "tt.load"(<<UNKNOWN SSA VALUE>>, %165, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %168 = "triton_gpu.convert_layout"(%155) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %169 = "triton_gpu.convert_layout"(%166) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %170 = "triton_gpu.convert_layout"(%144) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %171 = "tt.dot"(%168, %169, %170) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %172 = "builtin.unrealized_conversion_cast"(%171) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %173 = "tt.dot"(%156, %167, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %174 = "tt.addptr"(%142, %7) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %175 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %176 = "tt.addptr"(%140, %92) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %177 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%172, %174, %176) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> ()
    "scf.yield"(%173, %175, %177) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %97 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %98 = "arith.cmpi"(%24, %96) <{predicate = 2 : i64}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %99 = "arith.cmpi"(%25, %97) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %100 = "tt.load"(%74, %98, %1) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %101 = "tt.load"(%75, %99, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %102 = "arith.sitofp"(%arg4) : (i32) -> f32
  %103 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %104 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32>
  %105 = "arith.mulf"(%94#0, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %106 = "arith.mulf"(%95#0, %104) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %107 = "arith.sitofp"(%arg5) : (i32) -> f16
  %108 = "tt.splat"(%107) : (f16) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %109 = "tt.splat"(%107) : (f16) -> tensor<32xf16>
  %110 = "arith.mulf"(%100, %108) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %111 = "arith.mulf"(%101, %109) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %112 = "triton_gpu.convert_layout"(%110) : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %113 = "tt.expand_dims"(%112) <{axis = 0 : i32}> : (tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %114 = "builtin.unrealized_conversion_cast"(%113) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %115 = "tt.expand_dims"(%111) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %116 = "arith.extf"(%114) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %117 = "arith.extf"(%115) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %118 = "tt.broadcast"(%116) : (tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %119 = "tt.broadcast"(%117) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %120 = "arith.addf"(%105, %118) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %121 = "arith.addf"(%106, %119) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %122 = "arith.truncf"(%120) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %123 = "arith.truncf"(%121) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %124 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %125 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %126 = "arith.muli"(%124, %28) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %127 = "arith.muli"(%125, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %128 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %129 = "tt.addptr"(%128, %127) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %130 = "tt.broadcast"(%129) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %131 = "tt.addptr"(%130, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %132 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %133 = "arith.cmpi"(%29, %132) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %134 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %135 = "arith.cmpi"(%60, %134) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %136 = "tt.broadcast"(%133) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %137 = "tt.broadcast"(%135) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %138 = "arith.andi"(%136, %137) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%131, %123, %138) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.splat'(0x555d5bea0e00) {
  %128 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.splat -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::triton::SplatOp>"
    ** Insert  : 'tt.splat'(0x555d5bedd500)
    ** Replace : 'tt.splat'(0x555d5bea0e00)
"{anonymous}::GenericOpPattern<mlir::triton::SplatOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.splat'(0x555d5bedd500) {
      %128 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.yield' op must be the last operation in the parent block
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %140 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %141 = "builtin.unrealized_conversion_cast"(%140) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %142 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %143 = "builtin.unrealized_conversion_cast"(%142) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %144 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %145 = "builtin.unrealized_conversion_cast"(%144) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %146 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %147 = "arith.subi"(%arg8, %146) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %148 = "tt.splat"(%147) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = "tt.splat"(%147) : (i32) -> tensor<1x32xi32>
    %150 = "arith.cmpi"(%36, %148) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %151 = "arith.cmpi"(%37, %149) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %152 = "tt.broadcast"(%150) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %153 = "tt.broadcast"(%151) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %154 = "arith.andi"(%83, %152) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %155 = "arith.andi"(%84, %153) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %156 = "tt.load"(%143, %154, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %157 = "tt.load"(<<UNKNOWN SSA VALUE>>, %155, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %158 = "tt.splat"(%147) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %159 = "tt.splat"(%147) : (i32) -> tensor<32x1xi32>
    %160 = "arith.cmpi"(%51, %158) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %161 = "arith.cmpi"(%52, %159) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %162 = "tt.broadcast"(%160) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %163 = "builtin.unrealized_conversion_cast"(%162) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %164 = "tt.broadcast"(%161) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %165 = "arith.andi"(%163, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %166 = "arith.andi"(%164, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %167 = "tt.load"(%141, %165, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %168 = "tt.load"(<<UNKNOWN SSA VALUE>>, %166, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %169 = "triton_gpu.convert_layout"(%156) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %170 = "triton_gpu.convert_layout"(%167) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %171 = "triton_gpu.convert_layout"(%145) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %172 = "tt.dot"(%169, %170, %171) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %173 = "builtin.unrealized_conversion_cast"(%172) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %174 = "tt.dot"(%157, %168, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %175 = "tt.addptr"(%143, %7) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %176 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %177 = "tt.addptr"(%141, %92) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %178 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%173, %175, %177) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> ()
    "scf.yield"(%174, %176, %178) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %97 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %98 = "arith.cmpi"(%24, %96) <{predicate = 2 : i64}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %99 = "arith.cmpi"(%25, %97) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %100 = "tt.load"(%74, %98, %1) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %101 = "tt.load"(%75, %99, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %102 = "arith.sitofp"(%arg4) : (i32) -> f32
  %103 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %104 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32>
  %105 = "arith.mulf"(%94#0, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %106 = "arith.mulf"(%95#0, %104) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %107 = "arith.sitofp"(%arg5) : (i32) -> f16
  %108 = "tt.splat"(%107) : (f16) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %109 = "tt.splat"(%107) : (f16) -> tensor<32xf16>
  %110 = "arith.mulf"(%100, %108) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %111 = "arith.mulf"(%101, %109) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %112 = "triton_gpu.convert_layout"(%110) : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %113 = "tt.expand_dims"(%112) <{axis = 0 : i32}> : (tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %114 = "builtin.unrealized_conversion_cast"(%113) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %115 = "tt.expand_dims"(%111) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %116 = "arith.extf"(%114) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %117 = "arith.extf"(%115) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %118 = "tt.broadcast"(%116) : (tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %119 = "tt.broadcast"(%117) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %120 = "arith.addf"(%105, %118) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %121 = "arith.addf"(%106, %119) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %122 = "arith.truncf"(%120) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %123 = "arith.truncf"(%121) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %124 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %125 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %126 = "arith.muli"(%124, %28) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %127 = "arith.muli"(%125, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %128 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %129 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %130 = "tt.addptr"(%129, %127) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %131 = "tt.broadcast"(%130) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %132 = "tt.addptr"(%131, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %133 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %134 = "arith.cmpi"(%29, %133) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %135 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %136 = "arith.cmpi"(%60, %135) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %137 = "tt.broadcast"(%134) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %138 = "tt.broadcast"(%136) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %139 = "arith.andi"(%137, %138) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%132, %123, %139) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.addptr'(0x555d5bea0ed0) {
  %130 = "tt.addptr"(%129, %127) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.addptr -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::triton::AddPtrOp>"
    ** Insert  : 'tt.addptr'(0x555d5bede000)
    ** Replace : 'tt.addptr'(0x555d5bea0ed0)
"{anonymous}::GenericOpPattern<mlir::triton::AddPtrOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.addptr'(0x555d5bede000) {
      %130 = "tt.addptr"(%128, %126) : (tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.yield' op must be the last operation in the parent block
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %141 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %142 = "builtin.unrealized_conversion_cast"(%141) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %143 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %144 = "builtin.unrealized_conversion_cast"(%143) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %145 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %146 = "builtin.unrealized_conversion_cast"(%145) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %147 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %148 = "arith.subi"(%arg8, %147) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %149 = "tt.splat"(%148) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %150 = "tt.splat"(%148) : (i32) -> tensor<1x32xi32>
    %151 = "arith.cmpi"(%36, %149) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %152 = "arith.cmpi"(%37, %150) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %153 = "tt.broadcast"(%151) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %154 = "tt.broadcast"(%152) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %155 = "arith.andi"(%83, %153) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %156 = "arith.andi"(%84, %154) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %157 = "tt.load"(%144, %155, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %158 = "tt.load"(<<UNKNOWN SSA VALUE>>, %156, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %159 = "tt.splat"(%148) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %160 = "tt.splat"(%148) : (i32) -> tensor<32x1xi32>
    %161 = "arith.cmpi"(%51, %159) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %162 = "arith.cmpi"(%52, %160) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %163 = "tt.broadcast"(%161) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %164 = "builtin.unrealized_conversion_cast"(%163) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %165 = "tt.broadcast"(%162) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %166 = "arith.andi"(%164, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %167 = "arith.andi"(%165, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %168 = "tt.load"(%142, %166, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %169 = "tt.load"(<<UNKNOWN SSA VALUE>>, %167, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %170 = "triton_gpu.convert_layout"(%157) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %171 = "triton_gpu.convert_layout"(%168) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %172 = "triton_gpu.convert_layout"(%146) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %173 = "tt.dot"(%170, %171, %172) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %174 = "builtin.unrealized_conversion_cast"(%173) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %175 = "tt.dot"(%158, %169, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %176 = "tt.addptr"(%144, %7) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %177 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %178 = "tt.addptr"(%142, %92) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %179 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%174, %176, %178) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> ()
    "scf.yield"(%175, %177, %179) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %97 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %98 = "arith.cmpi"(%24, %96) <{predicate = 2 : i64}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %99 = "arith.cmpi"(%25, %97) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %100 = "tt.load"(%74, %98, %1) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %101 = "tt.load"(%75, %99, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %102 = "arith.sitofp"(%arg4) : (i32) -> f32
  %103 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %104 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32>
  %105 = "arith.mulf"(%94#0, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %106 = "arith.mulf"(%95#0, %104) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %107 = "arith.sitofp"(%arg5) : (i32) -> f16
  %108 = "tt.splat"(%107) : (f16) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %109 = "tt.splat"(%107) : (f16) -> tensor<32xf16>
  %110 = "arith.mulf"(%100, %108) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %111 = "arith.mulf"(%101, %109) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %112 = "triton_gpu.convert_layout"(%110) : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %113 = "tt.expand_dims"(%112) <{axis = 0 : i32}> : (tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %114 = "builtin.unrealized_conversion_cast"(%113) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %115 = "tt.expand_dims"(%111) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %116 = "arith.extf"(%114) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %117 = "arith.extf"(%115) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %118 = "tt.broadcast"(%116) : (tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %119 = "tt.broadcast"(%117) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %120 = "arith.addf"(%105, %118) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %121 = "arith.addf"(%106, %119) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %122 = "arith.truncf"(%120) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %123 = "arith.truncf"(%121) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %124 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %125 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %126 = "arith.muli"(%124, %28) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %127 = "arith.muli"(%125, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %128 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %129 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %130 = "tt.addptr"(%128, %126) : (tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %131 = "tt.addptr"(%129, %127) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %132 = "tt.broadcast"(%131) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %133 = "tt.addptr"(%132, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %134 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %135 = "arith.cmpi"(%29, %134) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %136 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %137 = "arith.cmpi"(%60, %136) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %138 = "tt.broadcast"(%135) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %139 = "tt.broadcast"(%137) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %140 = "arith.andi"(%138, %139) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%133, %123, %140) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.broadcast'(0x555d5bea0fc0) {
  %132 = "tt.broadcast"(%131) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.broadcast -> ()' {
Trying to match "{anonymous}::TritonBroadcastPattern"
    ** Insert  : 'tt.broadcast'(0x555d5bedeb80)
    ** Replace : 'tt.broadcast'(0x555d5bea0fc0)
"{anonymous}::TritonBroadcastPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.broadcast'(0x555d5bedeb80) {
      %132 = "tt.broadcast"(%130) : (tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.yield' op must be the last operation in the parent block
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %142 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %143 = "builtin.unrealized_conversion_cast"(%142) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %144 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %145 = "builtin.unrealized_conversion_cast"(%144) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %146 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %147 = "builtin.unrealized_conversion_cast"(%146) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %148 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %149 = "arith.subi"(%arg8, %148) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %150 = "tt.splat"(%149) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %151 = "tt.splat"(%149) : (i32) -> tensor<1x32xi32>
    %152 = "arith.cmpi"(%36, %150) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %153 = "arith.cmpi"(%37, %151) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %154 = "tt.broadcast"(%152) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %155 = "tt.broadcast"(%153) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %156 = "arith.andi"(%83, %154) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %157 = "arith.andi"(%84, %155) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %158 = "tt.load"(%145, %156, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %159 = "tt.load"(<<UNKNOWN SSA VALUE>>, %157, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %160 = "tt.splat"(%149) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %161 = "tt.splat"(%149) : (i32) -> tensor<32x1xi32>
    %162 = "arith.cmpi"(%51, %160) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %163 = "arith.cmpi"(%52, %161) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %164 = "tt.broadcast"(%162) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %165 = "builtin.unrealized_conversion_cast"(%164) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %166 = "tt.broadcast"(%163) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %167 = "arith.andi"(%165, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %168 = "arith.andi"(%166, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %169 = "tt.load"(%143, %167, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %170 = "tt.load"(<<UNKNOWN SSA VALUE>>, %168, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %171 = "triton_gpu.convert_layout"(%158) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %172 = "triton_gpu.convert_layout"(%169) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %173 = "triton_gpu.convert_layout"(%147) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %174 = "tt.dot"(%171, %172, %173) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %175 = "builtin.unrealized_conversion_cast"(%174) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %176 = "tt.dot"(%159, %170, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %177 = "tt.addptr"(%145, %7) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %178 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %179 = "tt.addptr"(%143, %92) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %180 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%175, %177, %179) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> ()
    "scf.yield"(%176, %178, %180) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %97 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %98 = "arith.cmpi"(%24, %96) <{predicate = 2 : i64}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %99 = "arith.cmpi"(%25, %97) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %100 = "tt.load"(%74, %98, %1) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %101 = "tt.load"(%75, %99, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %102 = "arith.sitofp"(%arg4) : (i32) -> f32
  %103 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %104 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32>
  %105 = "arith.mulf"(%94#0, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %106 = "arith.mulf"(%95#0, %104) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %107 = "arith.sitofp"(%arg5) : (i32) -> f16
  %108 = "tt.splat"(%107) : (f16) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %109 = "tt.splat"(%107) : (f16) -> tensor<32xf16>
  %110 = "arith.mulf"(%100, %108) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %111 = "arith.mulf"(%101, %109) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %112 = "triton_gpu.convert_layout"(%110) : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %113 = "tt.expand_dims"(%112) <{axis = 0 : i32}> : (tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %114 = "builtin.unrealized_conversion_cast"(%113) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %115 = "tt.expand_dims"(%111) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %116 = "arith.extf"(%114) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %117 = "arith.extf"(%115) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %118 = "tt.broadcast"(%116) : (tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %119 = "tt.broadcast"(%117) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %120 = "arith.addf"(%105, %118) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %121 = "arith.addf"(%106, %119) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %122 = "arith.truncf"(%120) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %123 = "arith.truncf"(%121) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %124 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %125 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %126 = "arith.muli"(%124, %28) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %127 = "arith.muli"(%125, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %128 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %129 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %130 = "tt.addptr"(%128, %126) : (tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %131 = "tt.addptr"(%129, %127) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %132 = "tt.broadcast"(%130) : (tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %133 = "tt.broadcast"(%131) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %134 = "tt.addptr"(%133, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %135 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %136 = "arith.cmpi"(%29, %135) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %137 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %138 = "arith.cmpi"(%60, %137) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %139 = "tt.broadcast"(%136) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %140 = "tt.broadcast"(%138) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %141 = "arith.andi"(%139, %140) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%134, %123, %141) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.addptr'(0x555d5bea1090) {
  %134 = "tt.addptr"(%133, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.addptr -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::triton::AddPtrOp>"
    ** Insert  : 'tt.addptr'(0x555d5bee2a40)
    ** Replace : 'tt.addptr'(0x555d5bea1090)
"{anonymous}::GenericOpPattern<mlir::triton::AddPtrOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.addptr'(0x555d5bee2a40) {
      %135 = "tt.addptr"(%133, %64) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.yield' op must be the last operation in the parent block
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %144 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %145 = "builtin.unrealized_conversion_cast"(%144) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %146 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %147 = "builtin.unrealized_conversion_cast"(%146) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %148 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %149 = "builtin.unrealized_conversion_cast"(%148) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %150 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %151 = "arith.subi"(%arg8, %150) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %152 = "tt.splat"(%151) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %153 = "tt.splat"(%151) : (i32) -> tensor<1x32xi32>
    %154 = "arith.cmpi"(%36, %152) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %155 = "arith.cmpi"(%37, %153) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %156 = "tt.broadcast"(%154) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %157 = "tt.broadcast"(%155) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %158 = "arith.andi"(%83, %156) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %159 = "arith.andi"(%84, %157) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %160 = "tt.load"(%147, %158, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %161 = "tt.load"(<<UNKNOWN SSA VALUE>>, %159, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %162 = "tt.splat"(%151) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %163 = "tt.splat"(%151) : (i32) -> tensor<32x1xi32>
    %164 = "arith.cmpi"(%51, %162) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %165 = "arith.cmpi"(%52, %163) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %166 = "tt.broadcast"(%164) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %167 = "builtin.unrealized_conversion_cast"(%166) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %168 = "tt.broadcast"(%165) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %169 = "arith.andi"(%167, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %170 = "arith.andi"(%168, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %171 = "tt.load"(%145, %169, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %172 = "tt.load"(<<UNKNOWN SSA VALUE>>, %170, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %173 = "triton_gpu.convert_layout"(%160) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %174 = "triton_gpu.convert_layout"(%171) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %175 = "triton_gpu.convert_layout"(%149) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %176 = "tt.dot"(%173, %174, %175) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %177 = "builtin.unrealized_conversion_cast"(%176) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %178 = "tt.dot"(%161, %172, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %179 = "tt.addptr"(%147, %7) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %180 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %181 = "tt.addptr"(%145, %92) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %182 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%177, %179, %181) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> ()
    "scf.yield"(%178, %180, %182) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %97 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %98 = "arith.cmpi"(%24, %96) <{predicate = 2 : i64}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %99 = "arith.cmpi"(%25, %97) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %100 = "tt.load"(%74, %98, %1) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %101 = "tt.load"(%75, %99, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %102 = "arith.sitofp"(%arg4) : (i32) -> f32
  %103 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %104 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32>
  %105 = "arith.mulf"(%94#0, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %106 = "arith.mulf"(%95#0, %104) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %107 = "arith.sitofp"(%arg5) : (i32) -> f16
  %108 = "tt.splat"(%107) : (f16) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %109 = "tt.splat"(%107) : (f16) -> tensor<32xf16>
  %110 = "arith.mulf"(%100, %108) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %111 = "arith.mulf"(%101, %109) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %112 = "triton_gpu.convert_layout"(%110) : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %113 = "tt.expand_dims"(%112) <{axis = 0 : i32}> : (tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %114 = "builtin.unrealized_conversion_cast"(%113) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %115 = "tt.expand_dims"(%111) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %116 = "arith.extf"(%114) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %117 = "arith.extf"(%115) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %118 = "tt.broadcast"(%116) : (tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %119 = "tt.broadcast"(%117) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %120 = "arith.addf"(%105, %118) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %121 = "arith.addf"(%106, %119) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %122 = "arith.truncf"(%120) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %123 = "arith.truncf"(%121) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %124 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %125 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %126 = "arith.muli"(%124, %28) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %127 = "arith.muli"(%125, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %128 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %129 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %130 = "tt.addptr"(%128, %126) : (tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %131 = "tt.addptr"(%129, %127) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %132 = "tt.broadcast"(%130) : (tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %133 = "builtin.unrealized_conversion_cast"(%132) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %134 = "tt.broadcast"(%131) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %135 = "tt.addptr"(%133, %64) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %136 = "tt.addptr"(%134, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %137 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %138 = "arith.cmpi"(%29, %137) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %139 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %140 = "arith.cmpi"(%60, %139) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %141 = "tt.broadcast"(%138) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %142 = "tt.broadcast"(%140) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %143 = "arith.andi"(%141, %142) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%136, %123, %143) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.splat'(0x555d5bea11a0) {
  %137 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.splat -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::triton::SplatOp>"
    ** Insert  : 'tt.splat'(0x555d5bee2b00)
    ** Replace : 'tt.splat'(0x555d5bea11a0)
"{anonymous}::GenericOpPattern<mlir::triton::SplatOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.splat'(0x555d5bee2b00) {
      %137 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.yield' op must be the last operation in the parent block
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %145 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %146 = "builtin.unrealized_conversion_cast"(%145) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %147 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %148 = "builtin.unrealized_conversion_cast"(%147) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %150 = "builtin.unrealized_conversion_cast"(%149) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %151 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %152 = "arith.subi"(%arg8, %151) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %153 = "tt.splat"(%152) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %154 = "tt.splat"(%152) : (i32) -> tensor<1x32xi32>
    %155 = "arith.cmpi"(%36, %153) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %156 = "arith.cmpi"(%37, %154) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %157 = "tt.broadcast"(%155) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %158 = "tt.broadcast"(%156) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %159 = "arith.andi"(%83, %157) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %160 = "arith.andi"(%84, %158) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %161 = "tt.load"(%148, %159, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %162 = "tt.load"(<<UNKNOWN SSA VALUE>>, %160, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %163 = "tt.splat"(%152) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %164 = "tt.splat"(%152) : (i32) -> tensor<32x1xi32>
    %165 = "arith.cmpi"(%51, %163) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %166 = "arith.cmpi"(%52, %164) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %167 = "tt.broadcast"(%165) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %168 = "builtin.unrealized_conversion_cast"(%167) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %169 = "tt.broadcast"(%166) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %170 = "arith.andi"(%168, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %171 = "arith.andi"(%169, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %172 = "tt.load"(%146, %170, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %173 = "tt.load"(<<UNKNOWN SSA VALUE>>, %171, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %174 = "triton_gpu.convert_layout"(%161) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %175 = "triton_gpu.convert_layout"(%172) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %176 = "triton_gpu.convert_layout"(%150) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %177 = "tt.dot"(%174, %175, %176) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %178 = "builtin.unrealized_conversion_cast"(%177) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %179 = "tt.dot"(%162, %173, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %180 = "tt.addptr"(%148, %7) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %181 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %182 = "tt.addptr"(%146, %92) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %183 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%178, %180, %182) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> ()
    "scf.yield"(%179, %181, %183) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %97 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %98 = "arith.cmpi"(%24, %96) <{predicate = 2 : i64}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %99 = "arith.cmpi"(%25, %97) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %100 = "tt.load"(%74, %98, %1) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %101 = "tt.load"(%75, %99, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %102 = "arith.sitofp"(%arg4) : (i32) -> f32
  %103 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %104 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32>
  %105 = "arith.mulf"(%94#0, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %106 = "arith.mulf"(%95#0, %104) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %107 = "arith.sitofp"(%arg5) : (i32) -> f16
  %108 = "tt.splat"(%107) : (f16) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %109 = "tt.splat"(%107) : (f16) -> tensor<32xf16>
  %110 = "arith.mulf"(%100, %108) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %111 = "arith.mulf"(%101, %109) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %112 = "triton_gpu.convert_layout"(%110) : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %113 = "tt.expand_dims"(%112) <{axis = 0 : i32}> : (tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %114 = "builtin.unrealized_conversion_cast"(%113) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %115 = "tt.expand_dims"(%111) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %116 = "arith.extf"(%114) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %117 = "arith.extf"(%115) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %118 = "tt.broadcast"(%116) : (tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %119 = "tt.broadcast"(%117) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %120 = "arith.addf"(%105, %118) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %121 = "arith.addf"(%106, %119) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %122 = "arith.truncf"(%120) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %123 = "arith.truncf"(%121) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %124 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %125 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %126 = "arith.muli"(%124, %28) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %127 = "arith.muli"(%125, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %128 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %129 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %130 = "tt.addptr"(%128, %126) : (tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %131 = "tt.addptr"(%129, %127) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %132 = "tt.broadcast"(%130) : (tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %133 = "builtin.unrealized_conversion_cast"(%132) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %134 = "tt.broadcast"(%131) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %135 = "tt.addptr"(%133, %64) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %136 = "tt.addptr"(%134, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %137 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %138 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %139 = "arith.cmpi"(%29, %138) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %140 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %141 = "arith.cmpi"(%60, %140) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %142 = "tt.broadcast"(%139) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %143 = "tt.broadcast"(%141) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %144 = "arith.andi"(%142, %143) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%136, %123, %144) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.cmpi'(0x555d5bea12b0) {
  %139 = "arith.cmpi"(%29, %138) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'arith.cmpi -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::arith::CmpIOp>"
    ** Insert  : 'arith.cmpi'(0x555d5beded70)
    ** Replace : 'arith.cmpi'(0x555d5bea12b0)
"{anonymous}::GenericOpPattern<mlir::arith::CmpIOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'arith.cmpi'(0x555d5beded70) {
      %139 = "arith.cmpi"(%28, %137) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.yield' op must be the last operation in the parent block
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %146 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %147 = "builtin.unrealized_conversion_cast"(%146) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %148 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %149 = "builtin.unrealized_conversion_cast"(%148) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %150 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %151 = "builtin.unrealized_conversion_cast"(%150) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %152 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %153 = "arith.subi"(%arg8, %152) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %154 = "tt.splat"(%153) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %155 = "tt.splat"(%153) : (i32) -> tensor<1x32xi32>
    %156 = "arith.cmpi"(%36, %154) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %157 = "arith.cmpi"(%37, %155) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %158 = "tt.broadcast"(%156) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %159 = "tt.broadcast"(%157) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %160 = "arith.andi"(%83, %158) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %161 = "arith.andi"(%84, %159) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %162 = "tt.load"(%149, %160, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %163 = "tt.load"(<<UNKNOWN SSA VALUE>>, %161, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %164 = "tt.splat"(%153) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %165 = "tt.splat"(%153) : (i32) -> tensor<32x1xi32>
    %166 = "arith.cmpi"(%51, %164) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %167 = "arith.cmpi"(%52, %165) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %168 = "tt.broadcast"(%166) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %169 = "builtin.unrealized_conversion_cast"(%168) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %170 = "tt.broadcast"(%167) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %171 = "arith.andi"(%169, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %172 = "arith.andi"(%170, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %173 = "tt.load"(%147, %171, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %174 = "tt.load"(<<UNKNOWN SSA VALUE>>, %172, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %175 = "triton_gpu.convert_layout"(%162) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %176 = "triton_gpu.convert_layout"(%173) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %177 = "triton_gpu.convert_layout"(%151) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %178 = "tt.dot"(%175, %176, %177) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %179 = "builtin.unrealized_conversion_cast"(%178) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %180 = "tt.dot"(%163, %174, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %181 = "tt.addptr"(%149, %7) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %182 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %183 = "tt.addptr"(%147, %92) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %184 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%179, %181, %183) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> ()
    "scf.yield"(%180, %182, %184) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %97 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %98 = "arith.cmpi"(%24, %96) <{predicate = 2 : i64}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %99 = "arith.cmpi"(%25, %97) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %100 = "tt.load"(%74, %98, %1) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %101 = "tt.load"(%75, %99, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %102 = "arith.sitofp"(%arg4) : (i32) -> f32
  %103 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %104 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32>
  %105 = "arith.mulf"(%94#0, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %106 = "arith.mulf"(%95#0, %104) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %107 = "arith.sitofp"(%arg5) : (i32) -> f16
  %108 = "tt.splat"(%107) : (f16) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %109 = "tt.splat"(%107) : (f16) -> tensor<32xf16>
  %110 = "arith.mulf"(%100, %108) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %111 = "arith.mulf"(%101, %109) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %112 = "triton_gpu.convert_layout"(%110) : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %113 = "tt.expand_dims"(%112) <{axis = 0 : i32}> : (tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %114 = "builtin.unrealized_conversion_cast"(%113) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %115 = "tt.expand_dims"(%111) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %116 = "arith.extf"(%114) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %117 = "arith.extf"(%115) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %118 = "tt.broadcast"(%116) : (tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %119 = "tt.broadcast"(%117) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %120 = "arith.addf"(%105, %118) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %121 = "arith.addf"(%106, %119) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %122 = "arith.truncf"(%120) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %123 = "arith.truncf"(%121) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %124 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %125 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %126 = "arith.muli"(%124, %28) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %127 = "arith.muli"(%125, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %128 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %129 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %130 = "tt.addptr"(%128, %126) : (tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %131 = "tt.addptr"(%129, %127) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %132 = "tt.broadcast"(%130) : (tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %133 = "builtin.unrealized_conversion_cast"(%132) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %134 = "tt.broadcast"(%131) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %135 = "tt.addptr"(%133, %64) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %136 = "tt.addptr"(%134, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %137 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %138 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %139 = "arith.cmpi"(%28, %137) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %140 = "arith.cmpi"(%29, %138) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %141 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %142 = "arith.cmpi"(%60, %141) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %143 = "tt.broadcast"(%140) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %144 = "tt.broadcast"(%142) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %145 = "arith.andi"(%143, %144) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%136, %123, %145) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.splat'(0x555d5bea13a0) {
  %141 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.splat -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::triton::SplatOp>"
    ** Insert  : 'tt.splat'(0x555d5bede1b0)
    ** Replace : 'tt.splat'(0x555d5bea13a0)
"{anonymous}::GenericOpPattern<mlir::triton::SplatOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.splat'(0x555d5bede1b0) {
      %141 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.yield' op must be the last operation in the parent block
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %147 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %148 = "builtin.unrealized_conversion_cast"(%147) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %149 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %150 = "builtin.unrealized_conversion_cast"(%149) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %151 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %152 = "builtin.unrealized_conversion_cast"(%151) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %153 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %154 = "arith.subi"(%arg8, %153) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %155 = "tt.splat"(%154) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %156 = "tt.splat"(%154) : (i32) -> tensor<1x32xi32>
    %157 = "arith.cmpi"(%36, %155) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %158 = "arith.cmpi"(%37, %156) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %159 = "tt.broadcast"(%157) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %160 = "tt.broadcast"(%158) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %161 = "arith.andi"(%83, %159) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %162 = "arith.andi"(%84, %160) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %163 = "tt.load"(%150, %161, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %164 = "tt.load"(<<UNKNOWN SSA VALUE>>, %162, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %165 = "tt.splat"(%154) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %166 = "tt.splat"(%154) : (i32) -> tensor<32x1xi32>
    %167 = "arith.cmpi"(%51, %165) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %168 = "arith.cmpi"(%52, %166) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %169 = "tt.broadcast"(%167) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %170 = "builtin.unrealized_conversion_cast"(%169) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %171 = "tt.broadcast"(%168) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %172 = "arith.andi"(%170, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %173 = "arith.andi"(%171, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %174 = "tt.load"(%148, %172, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %175 = "tt.load"(<<UNKNOWN SSA VALUE>>, %173, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %176 = "triton_gpu.convert_layout"(%163) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %177 = "triton_gpu.convert_layout"(%174) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %178 = "triton_gpu.convert_layout"(%152) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %179 = "tt.dot"(%176, %177, %178) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %180 = "builtin.unrealized_conversion_cast"(%179) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %181 = "tt.dot"(%164, %175, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %182 = "tt.addptr"(%150, %7) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %183 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %184 = "tt.addptr"(%148, %92) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %185 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%180, %182, %184) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> ()
    "scf.yield"(%181, %183, %185) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %97 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %98 = "arith.cmpi"(%24, %96) <{predicate = 2 : i64}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %99 = "arith.cmpi"(%25, %97) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %100 = "tt.load"(%74, %98, %1) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %101 = "tt.load"(%75, %99, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %102 = "arith.sitofp"(%arg4) : (i32) -> f32
  %103 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %104 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32>
  %105 = "arith.mulf"(%94#0, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %106 = "arith.mulf"(%95#0, %104) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %107 = "arith.sitofp"(%arg5) : (i32) -> f16
  %108 = "tt.splat"(%107) : (f16) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %109 = "tt.splat"(%107) : (f16) -> tensor<32xf16>
  %110 = "arith.mulf"(%100, %108) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %111 = "arith.mulf"(%101, %109) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %112 = "triton_gpu.convert_layout"(%110) : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %113 = "tt.expand_dims"(%112) <{axis = 0 : i32}> : (tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %114 = "builtin.unrealized_conversion_cast"(%113) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %115 = "tt.expand_dims"(%111) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %116 = "arith.extf"(%114) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %117 = "arith.extf"(%115) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %118 = "tt.broadcast"(%116) : (tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %119 = "tt.broadcast"(%117) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %120 = "arith.addf"(%105, %118) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %121 = "arith.addf"(%106, %119) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %122 = "arith.truncf"(%120) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %123 = "arith.truncf"(%121) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %124 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %125 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %126 = "arith.muli"(%124, %28) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %127 = "arith.muli"(%125, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %128 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %129 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %130 = "tt.addptr"(%128, %126) : (tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %131 = "tt.addptr"(%129, %127) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %132 = "tt.broadcast"(%130) : (tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %133 = "builtin.unrealized_conversion_cast"(%132) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %134 = "tt.broadcast"(%131) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %135 = "tt.addptr"(%133, %64) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %136 = "tt.addptr"(%134, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %137 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %138 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %139 = "arith.cmpi"(%28, %137) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %140 = "arith.cmpi"(%29, %138) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %141 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %142 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %143 = "arith.cmpi"(%60, %142) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %144 = "tt.broadcast"(%140) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %145 = "tt.broadcast"(%143) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %146 = "arith.andi"(%144, %145) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%136, %123, %146) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.cmpi'(0x555d5bea14b0) {
  %143 = "arith.cmpi"(%60, %142) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'arith.cmpi -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::arith::CmpIOp>"
    ** Insert  : 'arith.cmpi'(0x555d5bee2360)
    ** Replace : 'arith.cmpi'(0x555d5bea14b0)
"{anonymous}::GenericOpPattern<mlir::arith::CmpIOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'arith.cmpi'(0x555d5bee2360) {
      %143 = "arith.cmpi"(%59, %141) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.yield' op must be the last operation in the parent block
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %148 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %149 = "builtin.unrealized_conversion_cast"(%148) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %150 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %151 = "builtin.unrealized_conversion_cast"(%150) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %152 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %153 = "builtin.unrealized_conversion_cast"(%152) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %154 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %155 = "arith.subi"(%arg8, %154) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %156 = "tt.splat"(%155) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %157 = "tt.splat"(%155) : (i32) -> tensor<1x32xi32>
    %158 = "arith.cmpi"(%36, %156) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %159 = "arith.cmpi"(%37, %157) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %160 = "tt.broadcast"(%158) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %161 = "tt.broadcast"(%159) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %162 = "arith.andi"(%83, %160) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %163 = "arith.andi"(%84, %161) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %164 = "tt.load"(%151, %162, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %165 = "tt.load"(<<UNKNOWN SSA VALUE>>, %163, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %166 = "tt.splat"(%155) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %167 = "tt.splat"(%155) : (i32) -> tensor<32x1xi32>
    %168 = "arith.cmpi"(%51, %166) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %169 = "arith.cmpi"(%52, %167) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %170 = "tt.broadcast"(%168) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %171 = "builtin.unrealized_conversion_cast"(%170) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %172 = "tt.broadcast"(%169) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %173 = "arith.andi"(%171, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %174 = "arith.andi"(%172, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %175 = "tt.load"(%149, %173, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %176 = "tt.load"(<<UNKNOWN SSA VALUE>>, %174, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %177 = "triton_gpu.convert_layout"(%164) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %178 = "triton_gpu.convert_layout"(%175) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %179 = "triton_gpu.convert_layout"(%153) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %180 = "tt.dot"(%177, %178, %179) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %181 = "builtin.unrealized_conversion_cast"(%180) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %182 = "tt.dot"(%165, %176, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %183 = "tt.addptr"(%151, %7) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %184 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %185 = "tt.addptr"(%149, %92) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %186 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%181, %183, %185) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> ()
    "scf.yield"(%182, %184, %186) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %97 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %98 = "arith.cmpi"(%24, %96) <{predicate = 2 : i64}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %99 = "arith.cmpi"(%25, %97) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %100 = "tt.load"(%74, %98, %1) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %101 = "tt.load"(%75, %99, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %102 = "arith.sitofp"(%arg4) : (i32) -> f32
  %103 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %104 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32>
  %105 = "arith.mulf"(%94#0, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %106 = "arith.mulf"(%95#0, %104) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %107 = "arith.sitofp"(%arg5) : (i32) -> f16
  %108 = "tt.splat"(%107) : (f16) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %109 = "tt.splat"(%107) : (f16) -> tensor<32xf16>
  %110 = "arith.mulf"(%100, %108) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %111 = "arith.mulf"(%101, %109) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %112 = "triton_gpu.convert_layout"(%110) : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %113 = "tt.expand_dims"(%112) <{axis = 0 : i32}> : (tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %114 = "builtin.unrealized_conversion_cast"(%113) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %115 = "tt.expand_dims"(%111) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %116 = "arith.extf"(%114) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %117 = "arith.extf"(%115) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %118 = "tt.broadcast"(%116) : (tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %119 = "tt.broadcast"(%117) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %120 = "arith.addf"(%105, %118) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %121 = "arith.addf"(%106, %119) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %122 = "arith.truncf"(%120) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %123 = "arith.truncf"(%121) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %124 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %125 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %126 = "arith.muli"(%124, %28) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %127 = "arith.muli"(%125, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %128 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %129 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %130 = "tt.addptr"(%128, %126) : (tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %131 = "tt.addptr"(%129, %127) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %132 = "tt.broadcast"(%130) : (tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %133 = "builtin.unrealized_conversion_cast"(%132) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %134 = "tt.broadcast"(%131) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %135 = "tt.addptr"(%133, %64) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %136 = "tt.addptr"(%134, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %137 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %138 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %139 = "arith.cmpi"(%28, %137) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %140 = "arith.cmpi"(%29, %138) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %141 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %142 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %143 = "arith.cmpi"(%59, %141) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %144 = "arith.cmpi"(%60, %142) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %145 = "tt.broadcast"(%140) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %146 = "tt.broadcast"(%144) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %147 = "arith.andi"(%145, %146) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%136, %123, %147) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.broadcast'(0x555d5bea15a0) {
  %145 = "tt.broadcast"(%140) : (tensor<32x1xi1>) -> tensor<32x32xi1>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.broadcast -> ()' {
Trying to match "{anonymous}::TritonBroadcastPattern"
    ** Insert  : 'tt.broadcast'(0x555d5bedc910)
    ** Replace : 'tt.broadcast'(0x555d5bea15a0)
"{anonymous}::TritonBroadcastPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.broadcast'(0x555d5bedc910) {
      %145 = "tt.broadcast"(%139) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.yield' op must be the last operation in the parent block
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %149 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %150 = "builtin.unrealized_conversion_cast"(%149) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %151 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %152 = "builtin.unrealized_conversion_cast"(%151) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %153 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %154 = "builtin.unrealized_conversion_cast"(%153) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %155 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %156 = "arith.subi"(%arg8, %155) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %157 = "tt.splat"(%156) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %158 = "tt.splat"(%156) : (i32) -> tensor<1x32xi32>
    %159 = "arith.cmpi"(%36, %157) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %160 = "arith.cmpi"(%37, %158) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %161 = "tt.broadcast"(%159) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %162 = "tt.broadcast"(%160) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %163 = "arith.andi"(%83, %161) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %164 = "arith.andi"(%84, %162) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %165 = "tt.load"(%152, %163, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %166 = "tt.load"(<<UNKNOWN SSA VALUE>>, %164, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %167 = "tt.splat"(%156) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %168 = "tt.splat"(%156) : (i32) -> tensor<32x1xi32>
    %169 = "arith.cmpi"(%51, %167) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %170 = "arith.cmpi"(%52, %168) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %171 = "tt.broadcast"(%169) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %172 = "builtin.unrealized_conversion_cast"(%171) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %173 = "tt.broadcast"(%170) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %174 = "arith.andi"(%172, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %175 = "arith.andi"(%173, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %176 = "tt.load"(%150, %174, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %177 = "tt.load"(<<UNKNOWN SSA VALUE>>, %175, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %178 = "triton_gpu.convert_layout"(%165) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %179 = "triton_gpu.convert_layout"(%176) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %180 = "triton_gpu.convert_layout"(%154) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %181 = "tt.dot"(%178, %179, %180) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %182 = "builtin.unrealized_conversion_cast"(%181) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %183 = "tt.dot"(%166, %177, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %184 = "tt.addptr"(%152, %7) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %185 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %186 = "tt.addptr"(%150, %92) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %187 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%182, %184, %186) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> ()
    "scf.yield"(%183, %185, %187) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %97 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %98 = "arith.cmpi"(%24, %96) <{predicate = 2 : i64}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %99 = "arith.cmpi"(%25, %97) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %100 = "tt.load"(%74, %98, %1) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %101 = "tt.load"(%75, %99, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %102 = "arith.sitofp"(%arg4) : (i32) -> f32
  %103 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %104 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32>
  %105 = "arith.mulf"(%94#0, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %106 = "arith.mulf"(%95#0, %104) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %107 = "arith.sitofp"(%arg5) : (i32) -> f16
  %108 = "tt.splat"(%107) : (f16) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %109 = "tt.splat"(%107) : (f16) -> tensor<32xf16>
  %110 = "arith.mulf"(%100, %108) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %111 = "arith.mulf"(%101, %109) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %112 = "triton_gpu.convert_layout"(%110) : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %113 = "tt.expand_dims"(%112) <{axis = 0 : i32}> : (tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %114 = "builtin.unrealized_conversion_cast"(%113) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %115 = "tt.expand_dims"(%111) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %116 = "arith.extf"(%114) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %117 = "arith.extf"(%115) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %118 = "tt.broadcast"(%116) : (tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %119 = "tt.broadcast"(%117) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %120 = "arith.addf"(%105, %118) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %121 = "arith.addf"(%106, %119) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %122 = "arith.truncf"(%120) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %123 = "arith.truncf"(%121) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %124 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %125 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %126 = "arith.muli"(%124, %28) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %127 = "arith.muli"(%125, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %128 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %129 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %130 = "tt.addptr"(%128, %126) : (tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %131 = "tt.addptr"(%129, %127) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %132 = "tt.broadcast"(%130) : (tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %133 = "builtin.unrealized_conversion_cast"(%132) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %134 = "tt.broadcast"(%131) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %135 = "tt.addptr"(%133, %64) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %136 = "tt.addptr"(%134, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %137 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %138 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %139 = "arith.cmpi"(%28, %137) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %140 = "arith.cmpi"(%29, %138) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %141 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %142 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %143 = "arith.cmpi"(%59, %141) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %144 = "arith.cmpi"(%60, %142) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %145 = "tt.broadcast"(%139) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %146 = "tt.broadcast"(%140) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %147 = "tt.broadcast"(%144) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %148 = "arith.andi"(%146, %147) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%136, %123, %148) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.broadcast'(0x555d5bea1690) {
  %147 = "tt.broadcast"(%144) : (tensor<1x32xi1>) -> tensor<32x32xi1>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.broadcast -> ()' {
Trying to match "{anonymous}::TritonBroadcastPattern"
    ** Insert  : 'tt.broadcast'(0x555d5bee2420)
    ** Replace : 'tt.broadcast'(0x555d5bea1690)
"{anonymous}::TritonBroadcastPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.broadcast'(0x555d5bee2420) {
      %147 = "tt.broadcast"(%143) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.yield' op must be the last operation in the parent block
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %150 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %151 = "builtin.unrealized_conversion_cast"(%150) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %152 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %153 = "builtin.unrealized_conversion_cast"(%152) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %154 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %155 = "builtin.unrealized_conversion_cast"(%154) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %156 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %157 = "arith.subi"(%arg8, %156) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %158 = "tt.splat"(%157) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %159 = "tt.splat"(%157) : (i32) -> tensor<1x32xi32>
    %160 = "arith.cmpi"(%36, %158) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %161 = "arith.cmpi"(%37, %159) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %162 = "tt.broadcast"(%160) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %163 = "tt.broadcast"(%161) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %164 = "arith.andi"(%83, %162) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %165 = "arith.andi"(%84, %163) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %166 = "tt.load"(%153, %164, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %167 = "tt.load"(<<UNKNOWN SSA VALUE>>, %165, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %168 = "tt.splat"(%157) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %169 = "tt.splat"(%157) : (i32) -> tensor<32x1xi32>
    %170 = "arith.cmpi"(%51, %168) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %171 = "arith.cmpi"(%52, %169) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %172 = "tt.broadcast"(%170) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %173 = "builtin.unrealized_conversion_cast"(%172) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %174 = "tt.broadcast"(%171) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %175 = "arith.andi"(%173, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %176 = "arith.andi"(%174, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %177 = "tt.load"(%151, %175, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %178 = "tt.load"(<<UNKNOWN SSA VALUE>>, %176, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %179 = "triton_gpu.convert_layout"(%166) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %180 = "triton_gpu.convert_layout"(%177) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %181 = "triton_gpu.convert_layout"(%155) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %182 = "tt.dot"(%179, %180, %181) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %183 = "builtin.unrealized_conversion_cast"(%182) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %184 = "tt.dot"(%167, %178, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %185 = "tt.addptr"(%153, %7) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %186 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %187 = "tt.addptr"(%151, %92) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %188 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%183, %185, %187) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> ()
    "scf.yield"(%184, %186, %188) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %97 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %98 = "arith.cmpi"(%24, %96) <{predicate = 2 : i64}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %99 = "arith.cmpi"(%25, %97) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %100 = "tt.load"(%74, %98, %1) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %101 = "tt.load"(%75, %99, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %102 = "arith.sitofp"(%arg4) : (i32) -> f32
  %103 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %104 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32>
  %105 = "arith.mulf"(%94#0, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %106 = "arith.mulf"(%95#0, %104) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %107 = "arith.sitofp"(%arg5) : (i32) -> f16
  %108 = "tt.splat"(%107) : (f16) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %109 = "tt.splat"(%107) : (f16) -> tensor<32xf16>
  %110 = "arith.mulf"(%100, %108) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %111 = "arith.mulf"(%101, %109) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %112 = "triton_gpu.convert_layout"(%110) : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %113 = "tt.expand_dims"(%112) <{axis = 0 : i32}> : (tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %114 = "builtin.unrealized_conversion_cast"(%113) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %115 = "tt.expand_dims"(%111) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %116 = "arith.extf"(%114) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %117 = "arith.extf"(%115) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %118 = "tt.broadcast"(%116) : (tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %119 = "tt.broadcast"(%117) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %120 = "arith.addf"(%105, %118) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %121 = "arith.addf"(%106, %119) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %122 = "arith.truncf"(%120) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %123 = "arith.truncf"(%121) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %124 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %125 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %126 = "arith.muli"(%124, %28) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %127 = "arith.muli"(%125, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %128 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %129 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %130 = "tt.addptr"(%128, %126) : (tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %131 = "tt.addptr"(%129, %127) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %132 = "tt.broadcast"(%130) : (tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %133 = "builtin.unrealized_conversion_cast"(%132) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %134 = "tt.broadcast"(%131) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %135 = "tt.addptr"(%133, %64) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %136 = "tt.addptr"(%134, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %137 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %138 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %139 = "arith.cmpi"(%28, %137) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %140 = "arith.cmpi"(%29, %138) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %141 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %142 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %143 = "arith.cmpi"(%59, %141) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %144 = "arith.cmpi"(%60, %142) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %145 = "tt.broadcast"(%139) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %146 = "tt.broadcast"(%140) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %147 = "tt.broadcast"(%143) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %148 = "tt.broadcast"(%144) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %149 = "arith.andi"(%146, %148) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%136, %123, %149) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'arith.andi'(0x555d5bea1780) {
  %149 = "arith.andi"(%146, %148) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'arith.andi -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::arith::AndIOp>"
    ** Insert  : 'arith.andi'(0x555d5bee05a0)
    ** Replace : 'arith.andi'(0x555d5bea1780)
"{anonymous}::GenericOpPattern<mlir::arith::AndIOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'arith.andi'(0x555d5bee05a0) {
      %150 = "arith.andi"(%146, %148) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.yield' op must be the last operation in the parent block
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %152 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %153 = "builtin.unrealized_conversion_cast"(%152) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %154 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %155 = "builtin.unrealized_conversion_cast"(%154) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %156 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %157 = "builtin.unrealized_conversion_cast"(%156) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %158 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %159 = "arith.subi"(%arg8, %158) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %160 = "tt.splat"(%159) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %161 = "tt.splat"(%159) : (i32) -> tensor<1x32xi32>
    %162 = "arith.cmpi"(%36, %160) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %163 = "arith.cmpi"(%37, %161) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %164 = "tt.broadcast"(%162) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %165 = "tt.broadcast"(%163) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %166 = "arith.andi"(%83, %164) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %167 = "arith.andi"(%84, %165) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %168 = "tt.load"(%155, %166, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %169 = "tt.load"(<<UNKNOWN SSA VALUE>>, %167, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %170 = "tt.splat"(%159) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %171 = "tt.splat"(%159) : (i32) -> tensor<32x1xi32>
    %172 = "arith.cmpi"(%51, %170) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %173 = "arith.cmpi"(%52, %171) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %174 = "tt.broadcast"(%172) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %175 = "builtin.unrealized_conversion_cast"(%174) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %176 = "tt.broadcast"(%173) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %177 = "arith.andi"(%175, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %178 = "arith.andi"(%176, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %179 = "tt.load"(%153, %177, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %180 = "tt.load"(<<UNKNOWN SSA VALUE>>, %178, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %181 = "triton_gpu.convert_layout"(%168) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %182 = "triton_gpu.convert_layout"(%179) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %183 = "triton_gpu.convert_layout"(%157) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %184 = "tt.dot"(%181, %182, %183) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %185 = "builtin.unrealized_conversion_cast"(%184) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %186 = "tt.dot"(%169, %180, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %187 = "tt.addptr"(%155, %7) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %188 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %189 = "tt.addptr"(%153, %92) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %190 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%185, %187, %189) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> ()
    "scf.yield"(%186, %188, %190) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %97 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %98 = "arith.cmpi"(%24, %96) <{predicate = 2 : i64}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %99 = "arith.cmpi"(%25, %97) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %100 = "tt.load"(%74, %98, %1) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %101 = "tt.load"(%75, %99, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %102 = "arith.sitofp"(%arg4) : (i32) -> f32
  %103 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %104 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32>
  %105 = "arith.mulf"(%94#0, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %106 = "arith.mulf"(%95#0, %104) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %107 = "arith.sitofp"(%arg5) : (i32) -> f16
  %108 = "tt.splat"(%107) : (f16) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %109 = "tt.splat"(%107) : (f16) -> tensor<32xf16>
  %110 = "arith.mulf"(%100, %108) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %111 = "arith.mulf"(%101, %109) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %112 = "triton_gpu.convert_layout"(%110) : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %113 = "tt.expand_dims"(%112) <{axis = 0 : i32}> : (tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %114 = "builtin.unrealized_conversion_cast"(%113) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %115 = "tt.expand_dims"(%111) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %116 = "arith.extf"(%114) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %117 = "arith.extf"(%115) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %118 = "tt.broadcast"(%116) : (tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %119 = "tt.broadcast"(%117) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %120 = "arith.addf"(%105, %118) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %121 = "arith.addf"(%106, %119) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %122 = "arith.truncf"(%120) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %123 = "arith.truncf"(%121) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %124 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %125 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %126 = "arith.muli"(%124, %28) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %127 = "arith.muli"(%125, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %128 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %129 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %130 = "tt.addptr"(%128, %126) : (tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %131 = "tt.addptr"(%129, %127) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %132 = "tt.broadcast"(%130) : (tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %133 = "builtin.unrealized_conversion_cast"(%132) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %134 = "tt.broadcast"(%131) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %135 = "tt.addptr"(%133, %64) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %136 = "tt.addptr"(%134, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %137 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %138 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %139 = "arith.cmpi"(%28, %137) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %140 = "arith.cmpi"(%29, %138) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %141 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %142 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %143 = "arith.cmpi"(%59, %141) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %144 = "arith.cmpi"(%60, %142) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %145 = "tt.broadcast"(%139) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %146 = "builtin.unrealized_conversion_cast"(%145) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %147 = "tt.broadcast"(%140) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %148 = "tt.broadcast"(%143) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %149 = "tt.broadcast"(%144) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %150 = "arith.andi"(%146, %148) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %151 = "arith.andi"(%147, %149) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%136, %123, %151) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.store'(0x555d5be922f0) {
  "tt.store"(%136, %123, %151) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'tt.store -> ()' {
Trying to match "{anonymous}::GenericOpPattern<mlir::triton::StoreOp>"
ImplicitTypeIDRegistry::lookupOrInsert(mlir::triton::detail::StoreOpGenericAdaptorBase::Properties)
    ** Insert  : 'tt.store'(0x555d5bed0f10)
    ** Replace : 'tt.store'(0x555d5be922f0)
"{anonymous}::GenericOpPattern<mlir::triton::StoreOp>" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'tt.store'(0x555d5bed0f10) {
      "tt.store"(%135, %122, %150) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> ()

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'scf.yield' op must be the last operation in the parent block
mlir-asm-printer: 'tt.func' failed to verify and will be printed in generic form
"tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = (!tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, !tt.ptr<f16>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "addmm_kernel", sym_visibility = "public"}> ({
^bb0(%arg0: !tt.ptr<f16>, %arg1: !tt.ptr<f16>, %arg2: !tt.ptr<f16>, %arg3: !tt.ptr<f16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 31 : i32}> : () -> i32
  %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>}> : () -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32xf16>}> : () -> tensor<32xf16>
  %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %4 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf16>}> : () -> tensor<32x32xf16>
  %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
  %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
  %7 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %8 = "arith.constant"() <{value = dense<32> : tensor<32x32xi32>}> : () -> tensor<32x32xi32>
  %9 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>}> : () -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %10 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<32x32xf32>}> : () -> tensor<32x32xf32>
  %11 = "arith.constant"() <{value = 32 : i32}> : () -> i32
  %12 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
  %13 = "tt.get_program_id"() <{axis = 1 : i32}> : () -> i32
  %14 = "arith.muli"(%12, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %15 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %16 = "tt.make_range"() <{end = 32 : i32, start = 0 : i32}> : () -> tensor<32xi32>
  %17 = "tt.splat"(%14) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %18 = "tt.splat"(%14) : (i32) -> tensor<32xi32>
  %19 = "arith.addi"(%17, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %20 = "arith.addi"(%18, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %21 = "arith.muli"(%13, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.splat"(%21) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %23 = "tt.splat"(%21) : (i32) -> tensor<32xi32>
  %24 = "arith.addi"(%22, %15) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %25 = "arith.addi"(%23, %16) <{overflowFlags = #arith.overflow<none>}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi32>
  %26 = "triton_gpu.convert_layout"(%19) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %27 = "tt.expand_dims"(%26) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %28 = "builtin.unrealized_conversion_cast"(%27) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %29 = "tt.expand_dims"(%20) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %30 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %31 = "tt.splat"(%arg9) : (i32) -> tensor<32x1xi32>
  %32 = "arith.muli"(%28, %30) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %33 = "arith.muli"(%29, %31) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %34 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %35 = "tt.expand_dims"(%34) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %36 = "builtin.unrealized_conversion_cast"(%35) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %37 = "tt.expand_dims"(%16) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %38 = "tt.broadcast"(%32) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %39 = "builtin.unrealized_conversion_cast"(%38) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %40 = "tt.broadcast"(%33) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %41 = "tt.broadcast"(%36) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %42 = "tt.broadcast"(%37) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %43 = "arith.addi"(%39, %41) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %44 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %45 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %46 = "tt.splat"(%arg0) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %47 = "tt.addptr"(%45, %43) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %48 = "tt.addptr"(%46, %44) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %49 = "triton_gpu.convert_layout"(%15) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
  %50 = "tt.expand_dims"(%49) <{axis = 1 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
  %51 = "builtin.unrealized_conversion_cast"(%50) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %52 = "tt.expand_dims"(%16) <{axis = 1 : i32}> : (tensor<32xi32>) -> tensor<32x1xi32>
  %53 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %54 = "tt.splat"(%arg10) : (i32) -> tensor<32x1xi32>
  %55 = "arith.muli"(%51, %53) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %56 = "arith.muli"(%52, %54) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %57 = "triton_gpu.convert_layout"(%24) : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %58 = "tt.expand_dims"(%57) <{axis = 0 : i32}> : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %59 = "builtin.unrealized_conversion_cast"(%58) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %60 = "tt.expand_dims"(%25) <{axis = 0 : i32}> : (tensor<32xi32>) -> tensor<1x32xi32>
  %61 = "tt.broadcast"(%55) : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %62 = "builtin.unrealized_conversion_cast"(%61) : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %63 = "tt.broadcast"(%56) : (tensor<32x1xi32>) -> tensor<32x32xi32>
  %64 = "tt.broadcast"(%59) : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %65 = "tt.broadcast"(%60) : (tensor<1x32xi32>) -> tensor<32x32xi32>
  %66 = "arith.addi"(%62, %64) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %67 = "arith.addi"(%63, %65) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x32xi32>, tensor<32x32xi32>) -> tensor<32x32xi32>
  %68 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %69 = "tt.splat"(%arg1) : (!tt.ptr<f16>) -> tensor<32x32x!tt.ptr<f16>>
  %70 = "tt.addptr"(%68, %66) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %71 = "tt.addptr"(%69, %67) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %72 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %73 = "tt.splat"(%arg2) : (!tt.ptr<f16>) -> tensor<32x!tt.ptr<f16>>
  %74 = "tt.addptr"(%72, %24) : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %75 = "tt.addptr"(%73, %25) : (tensor<32x!tt.ptr<f16>>, tensor<32xi32>) -> tensor<32x!tt.ptr<f16>>
  %76 = "arith.addi"(%arg8, %0) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %77 = "arith.divsi"(%76, %11) : (i32, i32) -> i32
  %78 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %79 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %80 = "arith.cmpi"(%28, %78) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %81 = "arith.cmpi"(%29, %79) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %82 = "tt.broadcast"(%80) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %83 = "builtin.unrealized_conversion_cast"(%82) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %84 = "tt.broadcast"(%81) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %85 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %86 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %87 = "arith.cmpi"(%59, %85) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %88 = "arith.cmpi"(%60, %86) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %89 = "tt.broadcast"(%87) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %90 = "tt.broadcast"(%88) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %91 = "arith.muli"(%arg10, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %92 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %93 = "tt.splat"(%91) : (i32) -> tensor<32x32xi32>
  %94:3 = "scf.for"(%6, %77, %5, %9, %47, %70) ({
  ^bb0(%arg12: i32, %arg13: tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg14: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, %arg15: tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>):
    %152 = "builtin.unrealized_conversion_cast"(%arg15) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %153 = "builtin.unrealized_conversion_cast"(%152) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %154 = "builtin.unrealized_conversion_cast"(%arg14) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>>
    %155 = "builtin.unrealized_conversion_cast"(%154) : (tensor<32x32x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %156 = "builtin.unrealized_conversion_cast"(%arg13) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32>
    %157 = "builtin.unrealized_conversion_cast"(%156) : (tensor<32x32xf32>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %158 = "arith.muli"(<<UNKNOWN SSA VALUE>>, %11) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %159 = "arith.subi"(%arg8, %158) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %160 = "tt.splat"(%159) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %161 = "tt.splat"(%159) : (i32) -> tensor<1x32xi32>
    %162 = "arith.cmpi"(%36, %160) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %163 = "arith.cmpi"(%37, %161) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
    %164 = "tt.broadcast"(%162) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %165 = "tt.broadcast"(%163) : (tensor<1x32xi1>) -> tensor<32x32xi1>
    %166 = "arith.andi"(%83, %164) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %167 = "arith.andi"(%84, %165) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %168 = "tt.load"(%155, %166, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %169 = "tt.load"(<<UNKNOWN SSA VALUE>>, %167, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %170 = "tt.splat"(%159) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %171 = "tt.splat"(%159) : (i32) -> tensor<32x1xi32>
    %172 = "arith.cmpi"(%51, %170) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %173 = "arith.cmpi"(%52, %171) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
    %174 = "tt.broadcast"(%172) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %175 = "builtin.unrealized_conversion_cast"(%174) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %176 = "tt.broadcast"(%173) : (tensor<32x1xi1>) -> tensor<32x32xi1>
    %177 = "arith.andi"(%175, %89) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %178 = "arith.andi"(%176, %90) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
    %179 = "tt.load"(%153, %177, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %180 = "tt.load"(<<UNKNOWN SSA VALUE>>, %178, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi1>, tensor<32x32xf16>) -> tensor<32x32xf16>
    %181 = "triton_gpu.convert_layout"(%168) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %182 = "triton_gpu.convert_layout"(%179) : (tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %183 = "triton_gpu.convert_layout"(%157) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %184 = "tt.dot"(%181, %182, %183) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %185 = "builtin.unrealized_conversion_cast"(%184) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %186 = "tt.dot"(%169, %180, <<UNKNOWN SSA VALUE>>) <{inputPrecision = 2 : i32, maxNumImpreciseAcc = 0 : i32}> : (tensor<32x32xf16>, tensor<32x32xf16>, tensor<32x32xf32>) -> tensor<32x32xf32>
    %187 = "tt.addptr"(%155, %7) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %188 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %8) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    %189 = "tt.addptr"(%153, %92) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %190 = "tt.addptr"(<<UNKNOWN SSA VALUE>>, %93) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
    "scf.yield"(%185, %187, %189) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> ()
    "scf.yield"(%186, %188, %190) : (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> ()
  }) : (i32, i32, i32, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>)
  %95:3 = "scf.for"(%6, %77, %5, %10, %48, %71) ({
  }) : (i32, i32, i32, tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>) -> (tensor<32x32xf32>, tensor<32x32x!tt.ptr<f16>>, tensor<32x32x!tt.ptr<f16>>)
  %96 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %97 = "tt.splat"(%arg7) : (i32) -> tensor<32xi32>
  %98 = "arith.cmpi"(%24, %96) <{predicate = 2 : i64}> : (tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi32, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %99 = "arith.cmpi"(%25, %97) <{predicate = 2 : i64}> : (tensor<32xi32>, tensor<32xi32>) -> tensor<32xi1>
  %100 = "tt.load"(%74, %98, %1) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xi1, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %101 = "tt.load"(%75, %99, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<32x!tt.ptr<f16>>, tensor<32xi1>, tensor<32xf16>) -> tensor<32xf16>
  %102 = "arith.sitofp"(%arg4) : (i32) -> f32
  %103 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %104 = "tt.splat"(%102) : (f32) -> tensor<32x32xf32>
  %105 = "arith.mulf"(%94#0, %103) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %106 = "arith.mulf"(%95#0, %104) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %107 = "arith.sitofp"(%arg5) : (i32) -> f16
  %108 = "tt.splat"(%107) : (f16) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %109 = "tt.splat"(%107) : (f16) -> tensor<32xf16>
  %110 = "arith.mulf"(%100, %108) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
  %111 = "arith.mulf"(%101, %109) <{fastmath = #arith.fastmath<none>}> : (tensor<32xf16>, tensor<32xf16>) -> tensor<32xf16>
  %112 = "triton_gpu.convert_layout"(%110) : (tensor<32xf16, #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>) -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>
  %113 = "tt.expand_dims"(%112) <{axis = 0 : i32}> : (tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>
  %114 = "builtin.unrealized_conversion_cast"(%113) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>>) -> tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %115 = "tt.expand_dims"(%111) <{axis = 0 : i32}> : (tensor<32xf16>) -> tensor<1x32xf16>
  %116 = "arith.extf"(%114) : (tensor<1x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %117 = "arith.extf"(%115) : (tensor<1x32xf16>) -> tensor<1x32xf32>
  %118 = "tt.broadcast"(%116) : (tensor<1x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %119 = "tt.broadcast"(%117) : (tensor<1x32xf32>) -> tensor<32x32xf32>
  %120 = "arith.addf"(%105, %118) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %121 = "arith.addf"(%106, %119) <{fastmath = #arith.fastmath<none>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
  %122 = "arith.truncf"(%120) : (tensor<32x32xf32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %123 = "arith.truncf"(%121) : (tensor<32x32xf32>) -> tensor<32x32xf16>
  %124 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %125 = "tt.splat"(%arg11) : (i32) -> tensor<32x1xi32>
  %126 = "arith.muli"(%124, %28) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %127 = "arith.muli"(%125, %29) <{overflowFlags = #arith.overflow<none>}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi32>
  %128 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %129 = "tt.splat"(%arg3) : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>>
  %130 = "tt.addptr"(%128, %126) : (tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %131 = "tt.addptr"(%129, %127) : (tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32>) -> tensor<32x1x!tt.ptr<f16>>
  %132 = "tt.broadcast"(%130) : (tensor<32x1x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %133 = "builtin.unrealized_conversion_cast"(%132) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %134 = "tt.broadcast"(%131) : (tensor<32x1x!tt.ptr<f16>>) -> tensor<32x32x!tt.ptr<f16>>
  %135 = "tt.addptr"(%133, %64) : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %136 = "tt.addptr"(%134, %65) : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32>) -> tensor<32x32x!tt.ptr<f16>>
  %137 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %138 = "tt.splat"(%arg6) : (i32) -> tensor<32x1xi32>
  %139 = "arith.cmpi"(%28, %137) <{predicate = 2 : i64}> : (tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %140 = "arith.cmpi"(%29, %138) <{predicate = 2 : i64}> : (tensor<32x1xi32>, tensor<32x1xi32>) -> tensor<32x1xi1>
  %141 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %142 = "tt.splat"(%arg7) : (i32) -> tensor<1x32xi32>
  %143 = "arith.cmpi"(%59, %141) <{predicate = 2 : i64}> : (tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<1x32xi32, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %144 = "arith.cmpi"(%60, %142) <{predicate = 2 : i64}> : (tensor<1x32xi32>, tensor<1x32xi32>) -> tensor<1x32xi1>
  %145 = "tt.broadcast"(%139) : (tensor<32x1xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %146 = "builtin.unrealized_conversion_cast"(%145) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %147 = "tt.broadcast"(%140) : (tensor<32x1xi1>) -> tensor<32x32xi1>
  %148 = "tt.broadcast"(%143) : (tensor<1x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %149 = "tt.broadcast"(%144) : (tensor<1x32xi1>) -> tensor<32x32xi1>
  %150 = "arith.andi"(%146, %148) : (tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>
  %151 = "arith.andi"(%147, %149) : (tensor<32x32xi1>, tensor<32x32xi1>) -> tensor<32x32xi1>
  "tt.store"(%135, %122, %150) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xf16, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi1, #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>) -> ()
  "tt.store"(%136, %123, %151) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x32x!tt.ptr<f16>>, tensor<32x32xf16>, tensor<32x32xi1>) -> ()
  "tt.return"() : () -> ()
}) {noinline = false} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tt.return'(0x555d5bde9770) {
  "tt.return"() : () -> ()

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::PreservedAnalyses::AllAnalysesType)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DataLayoutSpecInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::StorageUserTrait::IsMutable<mlir::TypeID::get<mlir::detail::StorageUserTrait::IsMutable>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::triton::gpu::TritonGPU_AttrTrait::Trait<mlir::TypeID::get<mlir::triton::gpu::TritonGPU_AttrTrait::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::triton::gpu::DistributedEncodingTrait::Trait<mlir::TypeID::get<mlir::triton::gpu::DistributedEncodingTrait::Trait>()::Empty>)
#blocked = #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>
#blocked1 = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>
#blocked3 = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked4 = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>
#blocked5 = #triton_gpu.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
module attributes {"triton_gpu.num-ctas" = 1 : i32, "triton_gpu.num-warps" = 4 : i32, triton_gpu.target = "cuda", "triton_gpu.threads-per-warp" = 32 : i32} {
  tt.func public @addmm_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
    %c31_i32 = arith.constant 31 : i32
    %cst = arith.constant dense<0.000000e+00> : tensor<32xf16, #blocked>
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf16, #blocked1>
    %c1_i32 = arith.constant 1 : i32
    %c0_i32 = arith.constant 0 : i32
    %cst_1 = arith.constant dense<32> : tensor<32x32xi32, #blocked1>
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #blocked1>
    %c32_i32 = arith.constant 32 : i32
    %0 = tt.get_program_id x : i32
    %1 = tt.get_program_id y : i32
    %2 = arith.muli %0, %c32_i32 : i32
    %3 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #blocked>
    %4 = tt.splat %2 : i32 -> tensor<32xi32, #blocked>
    %5 = arith.addi %4, %3 : tensor<32xi32, #blocked>
    %6 = arith.muli %1, %c32_i32 : i32
    %7 = tt.splat %6 : i32 -> tensor<32xi32, #blocked>
    %8 = arith.addi %7, %3 : tensor<32xi32, #blocked>
    %9 = triton_gpu.convert_layout %5 : tensor<32xi32, #blocked> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>>
    %10 = tt.expand_dims %9 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2>
    %11 = triton_gpu.convert_layout %10 : tensor<32x1xi32, #blocked2> -> tensor<32x1xi32, #blocked3>
    %12 = tt.splat %arg9 : i32 -> tensor<32x1xi32, #blocked3>
    %13 = arith.muli %11, %12 : tensor<32x1xi32, #blocked3>
    %14 = triton_gpu.convert_layout %3 : tensor<32xi32, #blocked> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #blocked4}>>
    %15 = tt.expand_dims %14 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #blocked4}>> -> tensor<1x32xi32, #blocked4>
    %16 = triton_gpu.convert_layout %15 : tensor<1x32xi32, #blocked4> -> tensor<1x32xi32, #blocked1>
    %17 = tt.broadcast %13 : tensor<32x1xi32, #blocked3> -> tensor<32x32xi32, #blocked3>
    %18 = triton_gpu.convert_layout %17 : tensor<32x32xi32, #blocked3> -> tensor<32x32xi32, #blocked1>
    %19 = tt.broadcast %16 : tensor<1x32xi32, #blocked1> -> tensor<32x32xi32, #blocked1>
    %20 = arith.addi %18, %19 : tensor<32x32xi32, #blocked1>
    %21 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #blocked1>
    %22 = tt.addptr %21, %20 : tensor<32x32x!tt.ptr<f16>, #blocked1>, tensor<32x32xi32, #blocked1>
    %23 = triton_gpu.convert_layout %3 : tensor<32xi32, #blocked> -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>>
    %24 = tt.expand_dims %23 {axis = 1 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2>
    %25 = triton_gpu.convert_layout %24 : tensor<32x1xi32, #blocked2> -> tensor<32x1xi32, #blocked3>
    %26 = tt.splat %arg10 : i32 -> tensor<32x1xi32, #blocked3>
    %27 = arith.muli %25, %26 : tensor<32x1xi32, #blocked3>
    %28 = triton_gpu.convert_layout %8 : tensor<32xi32, #blocked> -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #blocked4}>>
    %29 = tt.expand_dims %28 {axis = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #blocked4}>> -> tensor<1x32xi32, #blocked4>
    %30 = triton_gpu.convert_layout %29 : tensor<1x32xi32, #blocked4> -> tensor<1x32xi32, #blocked1>
    %31 = tt.broadcast %27 : tensor<32x1xi32, #blocked3> -> tensor<32x32xi32, #blocked3>
    %32 = triton_gpu.convert_layout %31 : tensor<32x32xi32, #blocked3> -> tensor<32x32xi32, #blocked1>
    %33 = tt.broadcast %30 : tensor<1x32xi32, #blocked1> -> tensor<32x32xi32, #blocked1>
    %34 = arith.addi %32, %33 : tensor<32x32xi32, #blocked1>
    %35 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<32x32x!tt.ptr<f16>, #blocked1>
    %36 = tt.addptr %35, %34 : tensor<32x32x!tt.ptr<f16>, #blocked1>, tensor<32x32xi32, #blocked1>
    %37 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x!tt.ptr<f16>, #blocked>
    %38 = tt.addptr %37, %8 : tensor<32x!tt.ptr<f16>, #blocked>, tensor<32xi32, #blocked>
    %39 = arith.addi %arg8, %c31_i32 : i32
    %40 = arith.divsi %39, %c32_i32 : i32
    %41 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked3>
    %42 = arith.cmpi slt, %11, %41 : tensor<32x1xi32, #blocked3>
    %43 = tt.broadcast %42 : tensor<32x1xi1, #blocked3> -> tensor<32x32xi1, #blocked3>
    %44 = triton_gpu.convert_layout %43 : tensor<32x32xi1, #blocked3> -> tensor<32x32xi1, #blocked1>
    %45 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #blocked1>
    %46 = arith.cmpi slt, %30, %45 : tensor<1x32xi32, #blocked1>
    %47 = tt.broadcast %46 : tensor<1x32xi1, #blocked1> -> tensor<32x32xi1, #blocked1>
    %48 = arith.muli %arg10, %c32_i32 : i32
    %49 = tt.splat %48 : i32 -> tensor<32x32xi32, #blocked1>
    %50:3 = scf.for %arg12 = %c0_i32 to %40 step %c1_i32 iter_args(%arg13 = %cst_2, %arg14 = %22, %arg15 = %36) -> (tensor<32x32xf32, #blocked1>, tensor<32x32x!tt.ptr<f16>, #blocked1>, tensor<32x32x!tt.ptr<f16>, #blocked1>)  : i32 {
      %82 = arith.muli %arg12, %c32_i32 : i32
      %83 = arith.subi %arg8, %82 : i32
      %84 = tt.splat %83 : i32 -> tensor<1x32xi32, #blocked1>
      %85 = arith.cmpi slt, %16, %84 : tensor<1x32xi32, #blocked1>
      %86 = tt.broadcast %85 : tensor<1x32xi1, #blocked1> -> tensor<32x32xi1, #blocked1>
      %87 = arith.andi %44, %86 : tensor<32x32xi1, #blocked1>
      %88 = tt.load %arg14, %87, %cst_0 : tensor<32x32x!tt.ptr<f16>, #blocked1>
      %89 = tt.splat %83 : i32 -> tensor<32x1xi32, #blocked3>
      %90 = arith.cmpi slt, %25, %89 : tensor<32x1xi32, #blocked3>
      %91 = tt.broadcast %90 : tensor<32x1xi1, #blocked3> -> tensor<32x32xi1, #blocked3>
      %92 = triton_gpu.convert_layout %91 : tensor<32x32xi1, #blocked3> -> tensor<32x32xi1, #blocked1>
      %93 = arith.andi %92, %47 : tensor<32x32xi1, #blocked1>
      %94 = tt.load %arg15, %93, %cst_0 : tensor<32x32x!tt.ptr<f16>, #blocked1>
      %95 = triton_gpu.convert_layout %88 : tensor<32x32xf16, #blocked1> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #blocked5}>>
      %96 = triton_gpu.convert_layout %94 : tensor<32x32xf16, #blocked1> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #blocked5}>>
      %97 = triton_gpu.convert_layout %arg13 : tensor<32x32xf32, #blocked1> -> tensor<32x32xf32, #blocked5>
      %98 = tt.dot %95, %96, %97 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #blocked5}>> * tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #blocked5}>> -> tensor<32x32xf32, #blocked5>
      %99 = triton_gpu.convert_layout %98 : tensor<32x32xf32, #blocked5> -> tensor<32x32xf32, #blocked1>
      %100 = tt.addptr %arg14, %cst_1 : tensor<32x32x!tt.ptr<f16>, #blocked1>, tensor<32x32xi32, #blocked1>
      %101 = tt.addptr %arg15, %49 : tensor<32x32x!tt.ptr<f16>, #blocked1>, tensor<32x32xi32, #blocked1>
      scf.yield %99, %100, %101 : tensor<32x32xf32, #blocked1>, tensor<32x32x!tt.ptr<f16>, #blocked1>, tensor<32x32x!tt.ptr<f16>, #blocked1>
    }
    %51 = tt.splat %arg7 : i32 -> tensor<32xi32, #blocked>
    %52 = arith.cmpi slt, %8, %51 : tensor<32xi32, #blocked>
    %53 = tt.load %38, %52, %cst : tensor<32x!tt.ptr<f16>, #blocked>
    %54 = arith.sitofp %arg4 : i32 to f32
    %55 = tt.splat %54 : f32 -> tensor<32x32xf32, #blocked1>
    %56 = arith.mulf %50#0, %55 : tensor<32x32xf32, #blocked1>
    %57 = arith.sitofp %arg5 : i32 to f16
    %58 = tt.splat %57 : f16 -> tensor<32xf16, #blocked>
    %59 = arith.mulf %53, %58 : tensor<32xf16, #blocked>
    %60 = triton_gpu.convert_layout %59 : tensor<32xf16, #blocked> -> tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #blocked4}>>
    %61 = tt.expand_dims %60 {axis = 0 : i32} : tensor<32xf16, #triton_gpu.slice<{dim = 0, parent = #blocked4}>> -> tensor<1x32xf16, #blocked4>
    %62 = triton_gpu.convert_layout %61 : tensor<1x32xf16, #blocked4> -> tensor<1x32xf16, #blocked1>
    %63 = arith.extf %62 : tensor<1x32xf16, #blocked1> to tensor<1x32xf32, #blocked1>
    %64 = tt.broadcast %63 : tensor<1x32xf32, #blocked1> -> tensor<32x32xf32, #blocked1>
    %65 = arith.addf %56, %64 : tensor<32x32xf32, #blocked1>
    %66 = arith.truncf %65 : tensor<32x32xf32, #blocked1> to tensor<32x32xf16, #blocked1>
    %67 = tt.splat %arg11 : i32 -> tensor<32x1xi32, #blocked3>
    %68 = arith.muli %67, %11 : tensor<32x1xi32, #blocked3>
    %69 = tt.splat %arg3 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked3>
    %70 = tt.addptr %69, %68 : tensor<32x1x!tt.ptr<f16>, #blocked3>, tensor<32x1xi32, #blocked3>
    %71 = tt.broadcast %70 : tensor<32x1x!tt.ptr<f16>, #blocked3> -> tensor<32x32x!tt.ptr<f16>, #blocked3>
    %72 = triton_gpu.convert_layout %71 : tensor<32x32x!tt.ptr<f16>, #blocked3> -> tensor<32x32x!tt.ptr<f16>, #blocked1>
    %73 = tt.addptr %72, %33 : tensor<32x32x!tt.ptr<f16>, #blocked1>, tensor<32x32xi32, #blocked1>
    %74 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked3>
    %75 = arith.cmpi slt, %11, %74 : tensor<32x1xi32, #blocked3>
    %76 = tt.splat %arg7 : i32 -> tensor<1x32xi32, #blocked1>
    %77 = arith.cmpi slt, %30, %76 : tensor<1x32xi32, #blocked1>
    %78 = tt.broadcast %75 : tensor<32x1xi1, #blocked3> -> tensor<32x32xi1, #blocked3>
    %79 = triton_gpu.convert_layout %78 : tensor<32x32xi1, #blocked3> -> tensor<32x32xi1, #blocked1>
    %80 = tt.broadcast %77 : tensor<1x32xi1, #blocked1> -> tensor<32x32xi1, #blocked1>
    %81 = arith.andi %79, %80 : tensor<32x32xi1, #blocked1>
    tt.store %73, %66, %81 : tensor<32x32x!tt.ptr<f16>, #blocked1>
    tt.return
  }
}

